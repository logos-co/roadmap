{"acid/index":{"title":"Comms Roadmap Overview","links":["acid/milestones-overview","tags/acid-updates"],"tags":["overview"],"content":"Welcome to the Comms Roadmap Overview\n\nMilestones\nweekly updates\n"},"acid/milestones-overview":{"title":"Comms Milestones Overview","links":[],"tags":["milestones"],"content":"\nComms Roadmap\nComms Projects\nComms planner deadlines\n"},"acid/monthly-reports/2023-aug":{"title":"2023-aug","links":[],"tags":[],"content":"Acid Monthly Report - August 2023 §\nWeek of August 2, 2023 §\nComms §\n\nStatus app relaunch comms campaign plan in progress, targeting launch on August 31.\nLogos comms + growth plan post-launch to be determined.\nHiring: Split the role for content studio to attract top-level talent.\n\nCopy §\n\nUpdating old documentation like CC guide to reflect broader scope of BUs.\nBrand guidelines and modes of presentation in process.\nWikipedia entry on network states and virtual states is live.\n\nDigital Comms §\n\nLogos Discord completed.\nCodex Discord to be completed.\nLPE rollout plan in progress, to be ready by end of week.\nOverarching BU plan to be ready in the next couple of weeks.\n\nStudio §\n\nStarted execution of LPE for new requirements, aiming for end of month completion.\nHiring: Looking for 3 positions, mainly focusing on developer side.\n\nPodcast §\n\nPodcast timelines being set, currently in production.\nFirst HiO episode in the works, to be ready in 2 weeks.\n\nEvents §\n\nGlobal strategy paper for wider comms plan in progress.\nTemplate for processes and executions when preparing events.\nNetwork State event moved to November, exploring synergies with ETH Lisbon / Staking Summit.\nSeoul Q4 hackathon in the works, needs bounty planning.\n\nWeek of August 9, 2023 §\nTop Level Priorities §\n\nLogos Growth Plan\nStatus Relaunch\nLaunch of LPE\nPodcasts (Target: One podcast out every week)\nHiring: TD studio and DC studio roles\n\nMovement Building §\n\nLogos collective comms plan skeleton ready, to be applied for all BUs.\nDiscord Server update on various views.\nStatus relaunch comms plan ready for input.\n\nTD Studio §\n\nFull focus on LPE, on track for end of August launch.\nReview of options for more diverse content landscape.\nEpisodes page proposals and players in progress.\n\nCopy §\n\nContent creation for LPE and podcast launches.\nStatus launch content requirements pending.\nOrganization of doc sites review.\n\nPodcast §\n\nFirst interview with XMTP edited and ready.\nLSP preparing 2 months of content for launch.\n3 episodes recorded for HIO, motion graphics in progress.\n\nDC Studio §\n\nBrand guidelines for HiO ready.\nLogos State branding assets in development.\nPresentation templates being updated.\n\nEvents §\n\nNetwork State event planned for November in Istanbul.\nHackathon in Seoul scheduled for Q1 2024.\nGlobal event strategy written and in review.\n\nCRM &amp; Marketing Tool §\n\nFeedback collection from stakeholders and users.\nPM implementation to be planned (approximately 3 months).\nLPE KPI: Collecting email addresses of relevant people.\n\nWeek of August 29, 2023 §\nComms §\n\nLPE &amp; Podcast near completion, pending content review.\nStatus app comms campaign aligned with John and Status team.\nDigital designer joining the Content team soon.\nTownhall planned with Dmitry and Santiago discussing Codex + Logos culture.\n\nTech and Design §\n\nLPE ready for soft launch on 30/08, followed by stress testing and debugging.\nWiki codebase to be ready soon, with deployment and kick-off meeting planned.\n\nCopy §\n\nLPE content nearing completion, pending review.\nDocumentation sites cleanup in progress.\nStatus comms campaign articles in planning and drafting stages.\n\nPodcast §\n\nRelease plan being solidified and reviewed.\nReview process set up and open for feedback.\n\nContent §\n\nTownhall decks in preparation for next week.\nLPE content images being vetted to establish a consistent style.\n\nEvents §\n\nGlobal event strategy to be launched post-review by end of next week.\nNetwork State Event planning in progress, including speaker selection and venue shortlisting.\nETH Rome sponsorship confirmed, with Jarrad speaking.\nParalelni Polis event planned for late September.\nSeoul hackathon planning for February 2024 begun.\n\nMovement Building §\n\nComms plans for LPE, Status, and Logos Community on track.\nLogos community structure being developed to guide engagement and leadership.\nLPE launch plan under review with approved budget for paid ads.\nBU Plans nearly complete, pending review.\n"},"acid/updates/2023-08-02":{"title":"2023-08-02 Acid weekly","links":[],"tags":["acid-updates"],"content":"Leads roundup - acid §\nAl / Comms\n\nStatus app relaunch comms campaign plan in the works. Approx. date for launch 31.08.\nLogos comms + growth plan post launch is next up TBD.\nWill be waiting for specs for data room, raise etc.\nHires: split the role for content studio to be more realistic in getting top level talent.\n\nMatt  / Copy\n\nInitiative updating old documentation like CC guide to reflect broader scope of BUs\nBrand guidelines/ modes of presentation are in process\nWikipedia entry on network states and virtual states is live on\n\nEddy / Digital Comms\n\nLogos Discord will be completed by EOD.\nCodex Discord will be done tomorrow.\nLPE rollout plan, currently working on it, will be ready EOW\nPodcast rollout needs some\nOverarching BU plan will be ready in next couple of weeks as things on top have taken priority.\n\nAmir / Studio\n\nStarted execution of LPE for new requirements, broken down in smaller deliveries. Looking to have it working and live by EOM.\nHires: still looking for 3 positions with main focus on developer side.\n\nJonny / Podcast\n\nPodcast timelines are being set. In production right now. Nick delivered graphics for HiO but we need a full pack.\nFirst HiO episode is in the works. Will be ready in 2 weeks to fit in the rollout of the LPE.\n\nLouisa / Events\n\nGlobal strategy paper for wider comms plan.\nTemplate for processes and executions when preparing events.\nDecision made with Carl to move Network State event to November in satellite of other events. Looking into ETH Lisbon / Staking Summit etc.\nSeoul Q4 hackathon is already in the works. Needs bounty planning.\n"},"acid/updates/2023-08-09":{"title":"2023-08-09 Acid weekly","links":[],"tags":["acid-updates"],"content":"Top level priorities: §\nLogos Growth Plan\nStatus Relaunch\nLaunch of LPE\nPodcasts (Target: Every week one podcast out)\nHiring: TD studio and DC studio roles\nMovement Building: §\n\nLogos collective comms plan skeleton ready - will be applied for all BUs as next step\nGoal is to have plan + overview to set realistic KPIs and expectations\nDiscord Server update on various views\nStatus relaunch comms plan is ready for input from John et al.\nReach out to BUs for needs and deliverables\n\nTD Studio §\nFull focus on LPE:\n\nOn track, target of end of august\nreview of options, more diverse landscape of content\nEpisodes page proposals\nPlayers in progress\nrefactoring from prev code base\nstructure of content ready in GDrive\n\nCopy §\n\nContent around LPE\nContent for podcast launches\nStatus launch - content requirements to receive\nOrganization of doc sites review\nTBD what type of content and how the generation workflows will look like\n\nPodcast §\n\nGood state in editing and producing the shows\nFirst interview edited end to end with XMTP is ready. 2 weeks with social assets and all included.\nLSP is looking at having 2 months of content ready to launch with the sessions that have been recorded.\n3 recorded for HIO, motion graphics in progress\nFirst E2E podcast ready in 2 weeks for LPE\nLSP is looking at having 2 months of content ready to launch with the sessions that have been recorded.\n\nDC Studio §\n\nBrand guidelines for HiO are ready and set. Thanks Shmeda!\nLogos State branding assets are being developed\nPresentation templates update\n\nEvents §\n\nNetwork State event probably in Istanbul in November re: Devconnect will confirm shortly.\nProgram elements and speakers are top priority\nHackathon in Seoul in Q1 2024 - late Febuary probably\nJarrad will be speaking at HCPP and EthRome\nGlobal event strategy written and in review\nLou presented social media and event KPIs on Paris event\n\nCRM &amp; Marketing tool §\n\nGet feedback from stakeholders and users\nPM implementation to be planned (+- 3 month time TBD) with working group\nLPE KPI: Collecting email addresses of relevant people\nCareful on how we manage and use data, important for BizDev\nCareful on which segments of the project to manage using the CRM as it can be very off brand\n"},"acid/updates/2023-08-29":{"title":"2023-08-29 Comms weekly","links":[],"tags":["acid-updates"],"content":"Leads roundup - acid §\nAl - Comms §\n\nLPE &amp; Podcast are almost there. Content needs to be polished and reviewed by Carl and Jarrad. Might have an impact on the deadline but we start testing phase tomorrow.\nPlan for marketing and promotion of the podcast needs a bit more work. Teasers for Snowden will be released. Next episode drops next week.\nStatus app comms campaign. We are aligned with John and Status team. Needs pre-launch work for content and pending some items and confirmations from John.\nDigital designer will be joining us soon for Content team. We are still looking for a Motion designer.\nTownhall: Dmitry and Santiago will be talking re: Codex + Logos culture.\n\nAmir - Tech and Design §\n\nLPE is ready. Content is being populated. Soft launch is 30/08. Then stress test, debug, etc.\nNotion page is up and running for listing errors, bugs and feedback. Amir will move to GitHub https://www.notion.so/f9fef49cc74c46b19ceb9c14a2003062?v=3eb563f28fc448bd836d16da1272d620&amp;pvs=4\nWiki: codebase will be ready in a day or two, then once infra team deploys we have kick off meeting for structure, content etc. Then design team can redesign based on what we need. Timeframe: end of September\n\nMatt - Copy §\n\nContent from the LPE is getting there, pending review as mentioned above.\nCleaning up the documentation sites etc.\nStatus comms campaign is coming so articles in planning will be drafted and\n\nChristian - Podcast §\n\nPodcast release plan is being solidified and reviewed https://docs.google.com/document/d/1ppSb_Fkdw3iirwzlEgTvYpkq3n00ds4Xz5KE3mgqA-E/edit?usp=sharing\nReview process is set up and open for feedback.\n\nNick - Content §\n\nDecks for townhall are coming and will be ready for next week.\nImages for LPE content is being vetted. We are looking to establish a style for the first article to set the tone for the following. This is holding it back a bit but once it is set we can move it from there.\n\nLouisa - Events §\n\nBy the end of next week we will launch global event strategy post-review. Includes templates and structures for the future.\nNetwork State Event needs to lock down the potential event speakers, how to communicate with them and basically get a review. Nimbus and Waku and Codex will be there. We need to fix the program and agree on it. Venues shortlisted by the end of the week.\n8 agencies have been briefed as event organisers. Needs to be locked and set by end of week.\nETH Rome, Logos and Waku are sponsoring and Jarrad is talking. Paralelni Polis is happening late September. Working on the details to hit production deadlines.\nBeginning work on hacakthon in Seoul end of February 2024.\n\nMovement Building - Santiago §\n\nComms plans LPE, Status and Logos Community plans are on good track. Carl reviewed and asked for 90 day plans plus timelines.\nLogos community structure is being developed to guide people through an engagement/leadership ladder that serves our purpose. First community coming in will be our testing phase pre-growth.\nLPE launch plan is being reviewed and has a budget verbally approved to push via paid ads. Focus mostly on Snowden on episode as a roundabout way to support awareness for Logos.\nBU Plans, pretty much done, will send them to Al asap for review.\n"},"acid/updates/2023-09-21":{"title":"2023-09-18 Acid Update","links":[],"tags":["acid-updates"],"content":"Overview/Priorities §\n\nAl departure\n\nShort term - We need to stabilise, Al brought a lot of value, we may have to step up a little bit, will meet with Carl and Jarrad weekly.\nLong term - positive changes internally, open culture, open feedback, etc.\nTownhalls - Christian will be point of contact. With Santiago to support. The idea is plan 3-6 months in advance.\nComms strategy - Adjusting it to be more strategic and concise. with focus on Brand Awareness &amp; BU Needs, measuring Impact &amp; clear timeline.\nVirtual office - Available for anyone to join Santiago and Ned to discuss, ask questions, hangout.\nTo team leads: please implement feedback mechanisms that are safe for people. Open up first about shortcomings and promote healthy criticism and exchange. Copy the After Action Review model if necessary for each project delivery and a regular one at your discretion. We want to be better together and trust each other. It is a marker of a successful organisation.\n\n\n\nAmir - Tech &amp; Design §\n\nImprovements on LPE. RSS feed, Discord bot integration, X threads can be previewed\nIntegration of Odoo for email client is with infra.\nLogos System Design (LSD) is being optimised.\n\nMatt / Sterlin - Copy §\n\nPlethora of words to the LPE. Focus there. Make sure the content looks and feels good. Sterlin feels writing looks good in relation with other similar projects.\nMatt and Sterlin are working on the Status blog posts for the upcoming launch.\nAmelia is working on the BU updates.\nRick is the social media master, making really good progress on setting up a solid base and communication with the BUs in regards to their needs.\n\nNick - Digital Content Studio §\n\nNew meeting with Jarrad to get his involvement in the day to day things, he has clarity re: guests, shifting content and style. Objective is to have conversations that inform our thinking about network states, governance, etc. Cater content for Jarrad to build his skill as a speaker and host.\nProduction value is an important improvement point.\nLooking for more people to join as motion designer for video help.\nSwag for ETH Rome needs feedback but is on it’s way and on time.\nPodcast: we have a solid buffer of interviews for HiO and Logos that allows us to have time for strategic changes.\nPodcast: New stream/recording subscription needs to be approved by someone else to move forward.\n\nSantiago - Movement Building §\n\nComms strategies - overall, as a master guideline, we should be creating a movement around network states and not a network state, as a key player and a thought leader. From people developing privacy tech, charter cities, etc. To invest all our resources to creating spaces (physical x digital) for the different parties.\nJarrad: We want authentic organic interaction and conversations like a learning community.\nNick feedback : To approach which conversations/guests are more appropriately placed in which formats, because production time need to be mindful (podcast, twitter space, etc.)\nLPE launch awaits Comms strategy realignment.\n\nLouisa - Events §\n\nHolding back on global guidelines and event strategy once comms strategy is in place.\nJarrad is speaking at POW and HCCP. Decks coming ASAP.\nETH Rome: investing in bounties, smaller meetups are coming. We need booth, merch, swag design this week. Railgun collab with Waku.\nIstanbul: Just some alignment needed re: names and others. Vac, Nimbus and Waku will be there, think about how to overlay design work.\n"},"acid/updates/2023-10-03":{"title":"2023-10-10 Comms weekly","links":[],"tags":["acid-updates"],"content":"Overview/Priorities §\n\nComments from the BUs about blockers and miscommunications - Reevaluation of our comms strategy: BUs are responsible for DevRel, BD, and technical content. We’re responsible for QC of outgoing content (wordsmiths, video editing, and packaging) and non-technical content. This will be communicated with them and consolidated along with the strategy asap.\nNew Mantra: Brand awareness and Learning Communities, which are both measurable by proxy. This means we focus more on performance and growth KPIs and reporting these clearly to C/J.\nWith clear success metrics in place + costs and resources used we can finally focus on optimise our efforts and use it as a way to guide conversations about prioritising requests. This includes things like revisiting the creation of swag for each event etc.\nNew champions model for each BU. https://miro.com/app/board/uXjVPOFj6t8=/. We have an account manager/ implement, test it and iterate as soon as possible\n\nAmir - Tech &amp; Design §\n\nLogos System Design new version (design) is done. Development continue with Joao. Will move on to documentation.\nLPE project is done. Optimising the scoring system for the search pending a lot of content. V1 is officially done. Renamed to Network State Press\nIhor working on sketches and directing of Institute of Free Tech. Will share soon.\nBDP - brand design portal, we designed and managed the dev before but now on hold. For now focus on Brand Guidelines in Docusauraus for BUs.\n\nNick - Digital Content Studio §\n\nPresentations, swag work with Veronika &amp; Video for events.\nJonny has presented a few options for the podcast\n\nChristian - Podcast §\n\nOpen to doing Twitter spaces, in another category to keep it more streamlined and controlled. He wants interactive discussions, open quesitons, brainstorming etc.\nCurrently QC of Snowden\nNo new interviews, just doing checks of Ameen, Baylina  and Assange. Will have it ready\nJarrad will present the townhall\n\nMatt - Copy §\n\nStatus articles - Sterlin and Matt.\nBU Docs sites - Amelia. - good to go.\nMode of presentation guidelines (part of brand guidelines) for BUs - by Matt.\nDevelp site for Nimbus - Rick\nIFT landing page - Rick\nCollectively, series of articles about beginner’s guide to Network States.\n\nSantiago - Movement Building §\n\nFocusing on brand awareness and growth - we will set up reporting structures for Carl and Jarrad that are numbers based in relation to cost effectiveness.\nOdoo Email tool is with infra - configuration needed of the external SMTP server.\nFinding a PR moments for the raise.\nNext week and a half will be focused on updating the Logos server to have a proper onboarding strategy to optimise for a learning community experience. Will meet with Eddy and Jen to do this. Jen is currently updated all the all the Discord servers.\n\nLouisa - Events §\n\nPOW and HCCP done - challenge not enough brand awareness\nMetrics and dashboards to get a clear impact on KPIs related to events.\n\nJ&amp;F - Project Management §\n\nAssessment for workspace, work/information flow and dashboard optimization intra and inter teams and projects.\nOrganize around BUs and content pipelines\nTools assessment\n"},"acid/updates/2023-10-17":{"title":"2023-10-25 Comms weekly","links":[],"tags":["acid-updates"],"content":"ACID ROUND UP - OCT. 17\nOverview/Priorities\n\nWorkflows / Champions model: Reporting structure necessary.\nReporting to C+J: ClickUp dashboards.\nBrand Guidelines: In process of improvements.\nIstanbul NSF event cancelled. Will find more opportunities in first half of 2024.\n\nTech &amp; Design\n\nLSD finetuning.\nNomos team requested executable code inside documentation website.\nDocumentation for Docusaurus site. Every BU can deploy their own documentation\nIntegrating the Logos job listings on IFT website - working with JB and Flo.\nNo integrated requirement checklist for what the roadmap should be for all the org. It is not clear if this is one project or several. Different reporting structures per BU makes this complex. Focus on task / “bounty” list\nFinish up guidelines pages\n\nDigital Content Studio\n\nAna (new visual designer) joined last week. Helping on branding designs.\nPodcast templates for cutout animations are good to go. Match options for outputs.\nTwitter Spaces has an overlap with podcast pipeline. Jarrad also wants a easy going convo type setup for his own thinking and this is a bit. Needs to sync with MF.\nMatt and Nick sign off on LPE Article Headers/Social images\n\nPodcast\n\nQuality control got version of Jordi Baylina episode with new graph. Will be ready soon.\nSnowden episode needs a change in the graph at the beginning and  needs date change when we know it will launch\n\nCopy\n\nDoc sites are all live except for Waku - pending some small changes.\nNimbus websites might be getting close to launch.\nCarl asked for a beginner series for the network state concept, including a call to action that makes it easy for them to get to the beginner friendly content.\nIFT copy is in Carl’s hands and we are waiting for review.\n3 tech one pagers for Matt and the fundraising team are done.\n\nMovement Building\n\nTwitter Spaces idea for each BU is being discussed internally. Ideas to use  https://docs.google.com/document/d/1yOPPsZqKzf6__zuCsFYRsDDkk-lYX—vjRoz6e7OYK4/edit\nWorking on events stuff and postponing Network State Forum event for next year\nWe are running and testing ads on promoting our Twitter Spaces and have pivoted to growing our brand following online to lead into a big event. Potentially hackathon around the all hands meeting etc.\nPR company: onboarding is happening, they are asking good questions there\nStatus: Launch the community campaign. John wants to launch Nov 1.\nPaid Twitter Ads: Carl asked to run test ad. 2k for Logos space tweet. so far, 800k impressions. 125 followers gained so far. We will use this for benchmarking.\nNSP: held up as Jarrad is reviewing content and Carl is pending.\nWaku: feedback from Rome, mentioned that people come to them what is Waku/Status/Logos and how does everything fit. They don’t have a clear answer. We are fixing this.\nTalking to Lou re: events, we can approach Waku marketing as short term campaigns initially November-December. Will propose an awareness campaign to see what can be done with existing resources.\n\nEvents\n\nDifferent scenarios for Istanbul. Looking at whether we co-sponsor EthGlobal Istanbul.\nWaku will be doing EthGlobal India. EthGlobal Istanbul too expensive (40k) for Waku alone so we might co-sponsor.\nSpeaking to EthDenver for next year + an Africa strategy for Waku.\nSet up and manage events and KPIs and reporting in Click Up via forms that external people to the comms team can fill in.\nWe need a proper lead time for activation campaigns to maximise participation, social awareness etc. This is in planning.\nVideo footage from EthCC Paris event still unedited. If there are requests, we can edit it for that purpose.\nWriting a brief for event managers\n\nProject Management\n\nWorkflows reviews and optimizations based on strategy, goals and champions model\nPM and reporting set-up in ClickUp\n"},"acid/updates/2023-10-24":{"title":"2023-10-25 Comms weekly","links":[],"tags":["acid-updates"],"content":"Overview/Priorities\n\nWe are on the right track re: reporting, champions model and outputs. Full update here: https://doc.clickup.com/9009185920/p/h/8cfuh40-13894/965f96f62ea5053\n\nTech &amp; Design\n\nIFT website desktop version almost ready\nLogos Brand Guidelines are being updated\nDocusauraus updates - workshop for BUs to enable them to do content updates\nJobs will be added to every BU website and IFT\n\nDigital Content Studio\n\nContent guidelines in the works, summarising everything and putting it all together to make it functional.\nSwag and presentations are coming in according to plan - nothing of note.\nJonny working on proposal for NPS UX/structure in Figma based on conversation with nick and Amir yesterday\n\nPodcast\n\nPulling together detailed rollout doc with assets and exact copy for Al to send to Snowden and Assange for approvals and coordination.\nGet Stella out - audio quality is much better than Snowden’s so it’s good to go.\n\nCopy\n\nIFT is ready and getting published by EOW.\nNo news for copy re: NSP. Soft launch projected for this week for NSP.\nBeginner friendly piece by Rick for NSP is in production.\nEvent promotion for Logos EthGlobal Pragma presence.\nSocial buffer for Logos is set and ready. In depth threads re: philosophy and connection with each part of the tech stack.\n\nMovement Building\n\nLogos Discord structure: https://docs.google.com/document/d/1N0vgj7GIHllJ9YI912WdMetSEELMBzuWbRKl8NXjXCA/edit#heading=h.ebfdikfy2j9v\nLogos Forum gets traffic due to paid ads, please pay attention and move discussions there as much as is natural.\nFeedback from Jarrad: we need to focus on creating shareable cultural artifacts. For example, transcribing Twitter spaces into forums. Lazar suggested using the radical _anarchy salon content too.\nSoft launch of NSP will happen this end of week. Next week we go with main launch.\nTwitter paid ads were running on space. Report is complete and ready to be shared.\nGrowth strategy with Logos paid ads and Network state paid ads will be completed soon and shared with all.\nLegal: long story short is they will ask to have the least possible changes to the privacy policy but changes we asked for should be ready to be implemented.\n\nEvents\n\nWaku will be the main brand at ETHGlobal Istanbul to avoid confusion and to optimise\nLogos will be present at Pragma - we maximise brand awareness and want to test\nWider event marketing campaign needs to be clear. Distinct posts, tracking impact.\nDashboard on ClickUp for KPIs is in the works. Focus on optimising event attendance vs cost and resources.\n2024 is in the works. Africa events outline for Waku, ETH Denver already contacted.\n\nProject Management\n\nSetting up workspace, PM and reporting in click up with teams and get audit with Clickup experts. Onboarding next week.\n"},"codex/milestones/index":{"title":"Codex Milestones Overview","links":[],"tags":["milestones","codex"],"content":"Milestones §\n\nCodex Testnet\n\n\nTechnical Milestones §\n\nClient\n\nMerkelizing block data\nBlock discovery and retrieval\nDistributed Client Testing\nAsync Disc Access &amp; Threading Support\n\n\nMarketplace\n\nL2\nReservations and Slot Management\nMilestone Sales\n\n\nRemote Auditing\n\nImplement Poseidon2\nRefine Proving System\n\n\nData Availability Sampling (DAS)\n\nDHT Simulations\n\n\nInfra\n\nKubernetes Configuration and Management\nContinuous Testing and Labeling\nCI/CD and Synchronization\nMonitoring and Metrics\n\n\n\nOther Resources §\n\nZenhub Tracker - deprecated\nMiro Tracker\nGithub Projects Milestone Definitions\n"},"codex/monthly-reports/2023-aug":{"title":"2023-aug","links":[],"tags":[],"content":"Codex Monthly Report - August 2023 §\nClient §\nMilestone: Merkelizing block data §\n\nInitial design writeup completed: https://github.com/codex-storage/codex-research/blob/master/design/metadata-overhead.md\nInitial Merkle Tree implementation: https://github.com/codex-storage/nim-codex/pull/504\nWork on persisting/serializing Merkle Tree\nStoring and retrieving data using merkle trees: https://github.com/codex-storage/nim-codex/pull/541\nCoders for merkle trees: https://github.com/codex-storage/nim-codex/pull/519\nRefine merkle tree construction: https://github.com/codex-storage/nim-codex/pull/516\n\nMilestone: Block discovery and retrieval §\n\nInitial work breakdown and milestones: https://docs.google.com/document/d/1hnYWLvFDgqIYN8Vf9Nf5MZw04L2Lxc9VxaCXmp9Jb3Y/edit\nInitial analysis of block discovery: https://rpubs.com/giuliano_mega/1067876\nInitial block discovery simulator: https://gmega.shinyapps.io/block-discovery-sim/\nContinued analysis and review of peer sampling papers\nStarted work on simulations based on the analysis\n\nMilestone: Distributed Client Testing §\n\nExtensive work on log collection/analysis and monitoring\nTesting and debugging Codex in continuous testing environment\nMajor effort to stabilize the Codex client through continuous automated testing\n\nMilestone: Async Disc Access &amp; Threading support §\n\nTests on sharing thread data with refc\nAddressed errorVariable and thread safety issues\nPrototype proxy IO threadpool in progress\n\nMarketplace §\nMilestone: L2 §\n\nTaiko L2 integration mostly completed, waiting on related fixes\n\nMilestone: Reservations and slot management §\n\nExtensive work on slot reservation and queuing\n\nMilestone: Marketplace Sales §\n\nCleanup and refactoring of state machine\nAdded support for loading node’s slots during Sale’s module start\n\nRemote auditing §\nMilestone: Implement Poseidon2 §\n\nFirst pass at an implementation by Balazs\n\nMilestone: Refine proving system §\n\nExtensive thinking around storage proofs and proving systems\n\nDAS (Data Availability Sampling) §\nMilestone: DHT simulations §\n\nImplementing a DHT in Python for the DAS simulator\nImplemented logical error-rates and delays to interactions between DHT clients\n\nInfra §\nMilestone: Kubernetes Configuration and Management §\n\nMoved Dist-Tests cluster to OVH and defined naming conventions\nConfigured Ingress Controller for Kibana/Grafana\nCreated documentation for Kubernetes management\nConfigured Dist/Continuous-Tests Pods logs shipping\n\nMilestone: Continuous Testing and Labeling §\n\nImplemented and configured Dist-Tests labeling\nSet up logs shipping based on labels\nImproved Docker workflows and added ‘latest’ tag\n\nMilestone: CI/CD and Synchronization §\n\nSet up synchronization by codex-storage\nConfigured Codex Storage and Demo CI/CD environments\n\nMilestone: Monitoring and Metrics §\n\nInstalled Node exporter and Prometheus in Dist-Tests cluster\nUpdated Grafana Dashboard\nImplemented automated metrics scraping\n\nNotable Achievements §\n\nSignificant progress in Merkelizing block data, improving the foundation for the proving system\nAdvancements in block discovery and retrieval, including simulation work\nMajor improvements in distributed client testing and stability\nSuccessful integration with Taiko L2, expanding the project’s capabilities\nContinued development of DHT simulations for Data Availability Sampling\n\nChallenges and Next Steps §\n\nContinue refining the Merkle tree implementation and integration\nFurther develop and optimize the block discovery and retrieval processes\nEnhance the continuous testing environment for improved client stability\nComplete the Taiko L2 integration and address any remaining issues\nAdvance the DHT simulations and DAS implementation\nContinue improving infrastructure, monitoring, and CI/CD processes\n"},"codex/monthly-reports/2023-oct":{"title":"2023 October Codex Monthly Report","links":["codex/updates/2023-10-23"],"tags":["monthly-report","codex"],"content":"Executive Summary §\nIn the first half of the month, the team had an Offsite which focused on concretizing solutions around the MVP and planning out the required work to deliver the MVP by the end of the year.\nAll work after the offsite this month has been focused on the tasked out work that was planned during the offsite.\nThe Ethereum Foundation collaboration on Data Availability Sampling is coming to an end, all of the work associated with it was summed up here.\nKey Updates §\nPersonnel §\nA new job role was put up for a Technical Business Development Lead for Codex. This work will be dedicated to establishing and maintaining relationships with business partners interacting with the Codex Network. As the MVP and testnet get closer to launch, it is expected that these core relationships will need to be forged and cultivated.\n\nlots of upskilling and training new CCs (all people on client &lt; 4 months old).\n\nMilestones §\nThere was only one weekly update this month so it can be referenced for milestone updates, the link is down below.\nThe Ethereum Foundation collaboration on Data Availability Sampling is coming to an end, all of the work associated with it was summed up here. A subsequent report will be created that looks at the pros and cons of the engagement to inform both other Logos projects and future similar Codex engagements.\n\nfat trimmed that wasn’t required for MVP (maybe get a list of these things).\n\nPerceived Changes in Project Risk §\nThe project maintains its track to deliver the Codex MVP by the end of the year. The offsite that took place mapped out the specific work to be done, and who is tasked to do it within the team.\nmore confident that it will be delivered on time based on scope of work and current team makeup and planning from off-site\nthere is no expected delay to delivering the MVP and testnet by the end of the year. and debugging infra for monitoring failures with testnet.\nFuture Plans §\nInsight §\nThe Codex roadmap has yet to be ported over to this website, but now that the offsite is complete and the roadmap is more concrete, that transition should happen quickly within the next month.\nThis should allow us to ramp up the automated monitoring and create development activity dashboards. It is hoped that we have a development dashboard established by next month and a section within the monthly report that describes quantitative measurements of project development.\nProject §\nall focus is on current MVP and associated testnet\ncurrent MVP is minimum marketplace integrated with client and proving scheme. Proving scheme needs coding out and plugged into client. Need client itself to reflect recent changes in merkelization and block transfer.\nget testnet up and running, internal (logos/status) dogfooding for this year’s MVP, then to build monitoring and participation metrics over next year to prep for mainnet launch.\nSources and Useful Links §\nWeekly Reports\n\n2023-10-23\n"},"codex/monthly-reports/2023-sept":{"title":"2023 September Codex Monthly Report","links":["codex/updates/2023-09-15","content/codex/updates/2023-09-29"],"tags":["monthly-report","codex"],"content":"Executive Summary §\nSeptember updates for the Codex project were main focused on the ongoing research and analysis of the proofing schemes and their impact on the overall architecture and network economy.\nKey Updates §\nPersonnel §\nA new Business Development (BD) job description was posted and candidates are currently being interviewed. This role is expected to help facilitate strategy around the much needed partnerships for Codex and liaise with the other BD related resources we have within Logos to ensure efficient communications.\nMilestones §\nThe Codex team is broken up into 5 sections, and the weekly reports give details on how each of them have performed. Currently the Milestone definitions are not in line with this reporting process and will be worked on in the subsequent month. The teams are broken up into the following sections:\n\nClient\nInfra\nMarketplace\nResearch\nDAS\n\nBelow is summary of key updates to these sections over the month of September 2023\nClient §\nThe client continues to push towards Milestone 1.3: Codex v1.0 - Katana, which is slotted to be completed by the end of the year. Significant work has been done on merkelization which is required in order to integrate the proving system, and can be followed in this working branch.\nThe Block Exchange protocol got some attention and refinement. Notes on the associated thoughts can be found in these two writeups:\n\nBlock Discovery Problem\nCodex Swarm Overlays\n\nIn an effort to focus on the critical development path, this work is paused in lieu of attention on the distributed systems testing work.\nProgress was made on the ability for Codex to manage asynchronous and threaded disk IO. In the process of doing this work, a bug within Nim’s SharedPtr was discovered and fixed.\nInfra §\nA Grafana and Kibana instance were deployed in order to facilitate the various testing being done.\nMarketplace §\nIn order to alleviate a concurrency issue with Data Availabilities in the contract, a Reservation System has been proposed and worked on. This removes the previous constraint that current downloads was limited by the number of Availabilities.\nResearch §\nThe Codex Whitepaper v0.1 was drafted and scheduled for release in October 2023. It is currently under review and improving based on feedback.\nThere has been a large discussion this month around Erasure Coding (EC) for sampling. An analysiswas performed which looked at the various effects Erasure Coding schemes have on the sampling process and associated data guarantees. A quote of the conclusion on parameter choices is below:\n\n\n                  \n                  Quote \n                  \n                \n\nwe cannot have a small slot size, because that would mean too many proofs by a node (≈ 1 Tb seems to be a minimum)\nwe cannot have a too small block size, because the Merkle tree of the commitments will take too much space (say a minimum of 1024 bytes)\nwe cannot have a too big “checked sample” size, because we cannot do proofs for large amount of data (say a maximum of 65536 bytes)\nwe cannot have too much sampling checks per slot, because we cannot do proofs for many samples (depends on the block size and SNARK tech)\nwe probably want as big N, K parameters as possible, but actual implementations have limit\n\n\nA short review of the Interleaving Schemes for Multidimensional Cluster Errors was performed here and some general notes on Erasure Coding as it pertains to Codex was written up here. Much of these thoughts is being captured in the Erasure Coding Proofing document here. The conclusion section (at time of writing) is copied here for convenience:\n\n\n                  \n                  Quote \n                  \n                \nIt is likely that with the current state of the art in SNARK design and erasure coding implementations we can only support slot sizes up to 4GB. There are two design directions that allow an increase of slot size. One is to extend or implement an erasure coding implementation to use a larger field size. The other is to use existing erasure coding implementation in a multi-dimensional setting.\nTwo concrete options are:\n\nErasure code with a field size that allows for 2^28 shards. Check 20 shards per proof. For 1TB this leads to shards of 4KB. This means the SNARK needs to hash 80KB plus the Merkle paths for a storage proof. Requires custom implementation of Reed-Solomon, and requires at least 1 GB of memory while performing erasure coding.\nErasure code with a field size of 2^16 in two dimensions. Check 160 shards per proof. For 1TB this leads to a shards of 256 bytes. This means that the SNARK needs to hash 40KB plus the Merkle paths for a storage proof. We can use the leopard library for erasure coding and keep memory requirements for erasure coding to a negligable level.\n\n\nIt appears as though the team is preferring to go with the multi-dimensional approach to EC.\nDAS §\nWork continues on the DAS research in coordination with the Ethereum Foundation (EF). As a result of SBC, a blog post was written by the EF that discussed a forward thinking proposal for PeerDAS - a simpler DAS approach using battle-tested p2p components which the team has contributed to (referenced inside). Conversations of relevancy continue.\nA Codex Blog post was published discussing two by-products of the DAS research: the characterization of big block diffusion latency on the existing Ethereum Mainnet and the existence of big organic blocks on Ethereum Mainnet and its implications. The conclusion is quoted below:\n\n\n                  \n                  Quote \n                  \n                \nWe have discovered a large number of big blocks (&gt;250 KB) that occur organically every day in the Ethereum Mainnet. We have measured the propagation time of those blocks in three different world regions and compared their latency based on geographical location as well as block size. We have analysed how these propagation differences are reflected in the five CL clients separately, as they have different ways of reporting blocks. The empirical results measured in Ethereum Mainnet and presented in this work give us the first clear idea of how block propagation times might look when EIP-4844 is deployed, and 1 MB blocks become the standard and not the exception.\nIn the future, we plan to continue with these block propagation measurements and monitor the behaviour of big blocks in the Ethereum network. Additionally, we want to help different CL clients harmonise their event recording and publication systems in order to be able to compare CL clients between them.\n\nDiscussions with Felix Lange began around some fixes for Discv5.\nOther §\nA Codex YouTube channel has been setup and many tutorial videos and conference talks were uploaded. Go like and subscribe!\nPerceived Changes in Project Risk §\nIn an effort to meet the MVP launch by the end of the year, significant resources have been diverted to engineering efforts. Jessie has taken on more responsibility in the administration and project management duties while Dmitriy has started to focus more on the research and engineering needs\nThe ongoing research around the Data Availability Proof system still has potential to have drastic changes to the overall architecture of the system and associated resource costs of the various participants within the Codex Network. It is unclear how “locked in” parts of the system are that are included in the MVP launch.\nFuture Plans §\nInsight §\nBecause of the mismatch of weekly updates with Milestone definitions, it is difficult to assess the impact of any given update. Next month should have all milestone definitions within this site and a reporting structure that is more intuitively associated with it. It has been noted that the current structure makes it difficult to track cross-team work which the changes next month hope to fix.\nA Logos Collaborations section will be included next month to highlight differences in alignment with the Logos Collective as well as cross project collaboration updates.\nThe reporting process has missed a lot of work around the network simulation and modeling of Codex, which we expect to be corrected by next month by previously mentioned actions.\nDepending on the uptake and viability of the Waku reporting process to other projects, then a myriad of quantitative measures will be included in the next monthly report.\nProject §\nNEED INPUT HERE\nSources and Useful Links §\n\nZenhub tracker - mapping of milestones -&gt; epics -&gt; issues\nMay 2023 - Codex Project Status Report - list of risks and details on the milestones\n\nWeekly Reports\n\n2023-09-15\n2023-09-29\n"},"codex/overview":{"title":"Codex Roadmap Overview","links":["codex/monthly-reports/2023-sept","codex/milestones/","tags/codex-updates"],"tags":["overview"],"content":"Welcome to the Codex Roadmap Overview\n\n2023 September Report\n2o24 Milestones\nweekly updates\n"},"codex/updates/2023-07-21":{"title":"2023-07-21 Codex weekly","links":[],"tags":["codex-updates"],"content":"Codex update 07/12/2023 to 07/21/2023 §\nOverall we continue working in various directions, distributed testing, marketplace, p2p client, research, etc…\nOur main milestone is to have a fully functional testnet with the marketplace and durability guarantees deployed by end of year. A lot of grunt work is being done to make that possible. Progress is steady, but there are lots of stabilization and testing &amp; infra related work going on.\nWe’re also onboarding several new members to the team (4 to be precise), this will ultimately accelerate our progress, but it requires some upfront investment from some of the more experienced team members.\nDevOps/Infrastructure: §\n\nAdopted nim-codex Docker builds for Dist Tests.\nOrdered Dedicated node on Hetzner.\nConfigured Hetzner StorageBox for local backup on Dedicated server.\nConfigured new Logs shipper and Grafana in Dist-Tests cluster.\nCreated Geth and Prometheus Docker images for Dist-Tests.\nCreated a separate codex-contracts-eth Docker image for Dist-Tests.\nSet up Ingress Controller in Dist-Tests cluster.\n\nTesting: §\n\nSet up deployer to gather metrics.\nDebugging and identifying potential deadlock in the Codex client.\nAdded metrics, built image, and ran tests.\nUpdated dist-test log for Kibana compatibility.\nRan dist-tests on a new master image.\nDebugging continuous tests.\n\nDevelopment: §\n\nWorked on codex-dht nimble updates and fixing key format issue.\nUpdated CI and split Windows CI tests to run on two CI machines.\nContinued updating dependencies in codex-dht.\nFixed decoding large manifests (PR #479).\nExplored the existing implementation of NAT Traversal techniques in nim-libp2p.\n\nResearch §\n\nExploring additional directions for remote verification techniques and the interplay of different encoding approaches and cryptographic primitives\n\nhttps://eprint.iacr.org/2021/1500.pdf\nhttps://dankradfeist.de/ethereum/2021/06/18/pcs-multiproofs.html\nhttps://eprint.iacr.org/2021/1544.pdf\n\n\nOnboarding Balázs as our ZK researcher/engineer\nContinued research in DAS related topics\n\nRunning simulation on newly setup infrastructure\n\n\nDevised a new direction to reduce metadata overhead and enable remote verification https://github.com/codex-storage/codex-research/blob/master/design/metadata-overhead.md\nLooked into NAT Traversal (issue #166).\n\nCross-functional (Combination of DevOps/Testing/Development): §\n\nFixed discovery related issues.\nPlanned Codex Demo update for the Logos event and prepared environment for the demo.\nDescribed requirements for Dist Tests logs format.\nConfigured new Logs shipper and Grafana in Dist-Tests cluster.\nDist Tests logs adoption requirements - Updated log format for Kibana compatibility.\nHetzner Dedicated server was configured.\nSet up Hetzner StorageBox for local backup on Dedicated server.\nConfigured new Logs shipper in Dist-Tests cluster.\nSetup Grafana in Dist-Tests cluster.\nCreated a separate codex-contracts-eth Docker image for Dist-Tests.\nSetup Ingress Controller in Dist-Tests cluster.\n\n\nConversations §\n\nzk_id — 07/24/2023 11:59 AM\n\n\nWe’ve explored VDI for rollups ourselves in the last week, curious to know your thoughts\n\n\ndryajov — 07/25/2023 1:28 PM\n\n\nIt depends on what you mean, from a high level (A)VID is probably the closest thing to DAS in academic research, in fact DAS is probably either a subset or a superset of VID, so it’s definitely worth digging into. But I’m not sure what exactly you’re interested in, in the context of rollups…\n\n\n\nzk_id — 07/25/2023 3:28 PM\nThe part of the rollups seems to be the base for choosing proofs that scale linearly with the amount of nodes (which makes it impractical for large numbers of nodes). The protocol is very simple, and would only need to instead provide constant proofs with the Kate commitments (at the cost of large computational resources is my understanding). This was at least the rationale that I get from reading the paper and the conversation with Bunz, one of the founders of the Espresso shared sequencer (which is where I found the first reference to this paper). I guess my main open question is why would you do the sampling if you can do VID in the context of blockchains as well. With the proofs of dispersal on-chain, you wouldn’t need to do that for the agreement of the dispersal. You still would need the sampling for the light clients though, of course.\n\n\ndryajov — 07/25/2023 8:31 PM\n\nI guess my main open question is why would you do the sampling if you can do VID in the context of blockchains as well. With the proofs of dispersal on-chain, you wouldn’t need to do that for the agreement of the dispersal.\n\nYeah, great question. What follows is strictly IMO, as I haven’t seen this formally contrasted anywhere, so my reasoning can be wrong in subtle ways.\n\n(A)VID - dispersing and storing data in a verifiable manner\nSampling - verifying already dispersed data\n\ntl;dr Sampling allows light nodes to protect against dishonest majority attacks. In other words, a light node cannot be tricked to follow an incorrect chain by a dishonest validator majority that withholds data. More details are here - https://dankradfeist.de/ethereum/2019/12/20/data-availability-checks.html ------------- First, DAS implies (A)VID, as there is an initial phase where data is distributed to some subset of nodes. Moreover, these nodes, usually the validators, attest that they received the data and that it is correct. If a majority of validators accepts, then the block is considered correct, otherwise it is rejected. This is the verifiable dispersal part. But what if the majority of validators are dishonest? Can you prevent them from tricking the rest of the network from following the chain?\nDankrad Feist\nData availability checks\nPrimer on data availability checks\n\n\n[8:31 PM]\nDealing with dishonest majorities §\nThis is easy if all the data is downloaded by all nodes all the time, but we’re trying to avoid just that. But lets assume, for the sake of the argument, that there are full nodes in the network that download all the data and are able to construct fraud proofs for missing data, can this mitigate the problem? It turns out that it can’t, because proving data (un)availability isn’t a directly attributable fault - in other words, you can observe/detect it but there is no way you can prove it to the rest of the network reliably. More details here https://github.com/ethereum/research/wiki/A-note-on-data-availability-and-erasure-coding So, if there isn’t much that can be done by detecting that a block isn’t available, what good is it for? Well nodes can still avoid following the unavailable chain and thus be tricked by a dishonest majority. However, simply attesting that data has been publishing is not enough to prevent a dishonest majority from attacking the network. (edited)\n\n\ndryajov — 07/25/2023 9:06 PM\nTo complement, the relevant quote from https://github.com/ethereum/research/wiki/A-note-on-data-availability-and-erasure-coding, is:\n\nHere, fraud proofs are not a solution, because not publishing data is not a uniquely attributable fault - in any scheme where a node (“fisherman”) has the ability to “raise the alarm” about some piece of data not being available, if the publisher then publishes the remaining data, all nodes who were not paying attention to that specific piece of data at that exact time cannot determine whether it was the publisher that was maliciously withholding data or whether it was the fisherman that was maliciously making a false alarm.\n\nThe relevant quote from from https://dankradfeist.de/ethereum/2019/12/20/data-availability-checks.html, is:\n\nThere is one gap in the solution of using fraud proofs to protect light clients from incorrect state transitions: What if a consensus supermajority has signed a block header, but will not publish some of the data (in particular, it could be fraudulent transactions that they will publish later to trick someone into accepting printed/stolen money)? Honest full nodes, obviously, will not follow this chain, as they can’t download the data. But light clients will not know that the data is not available since they don’t try to download the data, only the header. So we are in a situation where the honest full nodes know that something fishy is going on, but they have no means of alerting the light clients, as they are missing the piece of data that might be needed to create a fraud proof.\n\nBoth articles are a bit old, but the intuitions still hold.\n\n\nJuly 26, 2023\n\n\nzk_id — 07/26/2023 10:42 AM\nThanks a ton @dryajov ! We are on the same page. TBH it took me a while to get to this point, as it’s not an intuitive problem at first. The relationship between the VID and the DAS, and what each is for is crucial for us, btw. Your writing here and your references give us the confidence that we understand the problem and are equipped to evaluate the different solutions. Deeply appreciate that you took the time to write this, and is very valuable.\n\n\n[10:45 AM]\nThe dishonest majority is critical scenario for Nomos (essential part of the whole sovereignty narrative), and generally not considered by most blockchain designs\n\n\nzk_id\nThanks a ton @dryajov ! We are on the same page. TBH it took me a while to get to this point, as it’s not an intuitive problem at first. The relationship between the VID and the DAS, and what each is for is crucial for us, btw. Your writing here and your references give us the confidence that we understand the problem and are equipped to evaluate the different solutions. Deeply appreciate that you took the time to write this, and is very valuable.\ndryajov — 07/26/2023 4:42 PM §\nGreat! Glad to help anytime\n\n\nzk_id\nThe dishonest majority is critical scenario for Nomos (essential part of the whole sovereignty narrative), and generally not considered by most blockchain designs\ndryajov — 07/26/2023 4:43 PM\nYes, I’d argue it is crucial in a network with distributed validation, where all nodes are either fully light or partially light nodes.\n\n\n[4:46 PM]\nBtw, there is probably more we can share/compare notes on in this problem space, we’re looking at similar things, perhaps from a slightly different perspective in Codex’s case, but the work done on DAS with the EF directly is probably very relevant for you as well\n\n\nJuly 27, 2023\n\n\nzk_id — 07/27/2023 3:05 AM\nI would love to. Do you have those notes somewhere?\n\n\nzk_id — 07/27/2023 4:01 AM\nall the links you have, anything, would be useful\n\n\nzk_id\nI would love to. Do you have those notes somewhere?\ndryajov — 07/27/2023 4:50 PM\nA bit scattered all over the place, mainly from @Leobago and @cskiraly @cskiraly has a draft paper somewhere\n\n\nJuly 28, 2023\n\n\nzk_id — 07/28/2023 5:47 AM\nWould love to see anything that is possible\n\n\n[5:47 AM]\nOur setting is much simpler, but any progress that you make (specifically in the computational cost of the polynomial commitments or alternative proofs) would be really useful for us\n\n\nzk_id\nOur setting is much simpler, but any progress that you make (specifically in the computational cost of the polynomial commitments or alternative proofs) would be really useful for us\ndryajov — 07/28/2023 4:07 PM\nYes, we’re also working in this direction as this is crucial for us as well. There should be some result coming soon(tm), now that @bkomuves is helping us with this part.\n\n\nzk_id\nOur setting is much simpler, but any progress that you make (specifically in the computational cost of the polynomial commitments or alternative proofs) would be really useful for us\nbkomuves — 07/28/2023 4:44 PM\nmy current view (it’s changing pretty often :) is that there is tension between:\n\ncommitment cost\nproof cost\nand verification cost\n\nthe holy grail which is the best for all of them doesn’t seem to exist. Hence, you have to make tradeoffs, and it depends on your specific use case what you should optimize for, or what balance you aim for. we plan to find some points in this 3 dimensional space which are hopefully close to the optimal surface, and in parallel to that figure out what balance to aim for, and then choose a solution based on that (and also based on what’s possible, there are external restrictions)\n\n\nJuly 29, 2023\n\n\nbkomuves\nmy current view (it’s changing pretty often :) is that there is tension between: \n\ncommitment cost\nproof cost\nand verification cost\n\n the holy grail which is the best for all of them doesn’t seem to exist. Hence, you have to make tradeoffs, and it depends on your specific use case what you should optimize for, or what balance you aim for. we plan to find some points in this 3 dimensional space which are hopefully close to the optimal surface, and in parallel to that figure out what balance to aim for, and then choose a solution based on that (and also based on what’s possible, there are external restrictions)\nzk_id — 07/29/2023 4:23 AM\nI agree. That’s also my understanding (although surely much more superficial).\n\n\n[4:24 AM]\nThere is also the dimension of computation vs size cost\n\n\n[4:25 AM]\nie the VID scheme (of the paper that kickstarted this conversation) has all the properties we need, but it scales n^2 in message complexity which makes it lose the properties we are looking for after 1k nodes. We need to scale confortably to 10k nodes.\n\n\n[4:29 AM]\nSo we are at the moment most likely to use KZG commitments with a 2d RS polynomial. Basically just copy Ethereum. Reason is:\n\nOur rollups/EZ leader will generate this, and those are beefier machines than the Base Layer. The base layer nodes just need to verify and sign the EC fragments and return them to complete the VID protocol (and then run consensus on the aggregated signed proofs).\nIf we ever decide to change the design for the VID dispersal to be done by Base Layer leaders (in a multileader fashion), it can be distributed (rows/columns can be reconstructed and proven separately). I don’t think we will pursue this, but we will have to if this scheme doesn’t scale with the first option.\n\n\n\nAugust 1, 2023\n\n\ndryajov\nA bit scattered all over the place, mainly from @Leobago and @cskiraly @cskiraly has a draft paper somewhere\nLeobago — 08/01/2023 1:13 PM\nNote much public write-ups yet. You can find some content here:\n\n\nhttps://blog.codex.storage/data-availability-sampling/\n\n\nhttps://github.com/codex-storage/das-research\n\n\n\n\nWe also have a few Jupiter notebooks but they are not public yet. As soon as that content is out we can let you know \nCodex Storage Blog\nData Availability Sampling\nThe Codex team is busy building a new web3 decentralized storage platform with the latest advances in erasure coding and verification systems. Part of the challenge of deploying decentralized storage infrastructure is to guarantee that the data that has been stored and is available for retrieval from the beginning until\nGitHub\nGitHub - codex-storage/das-research: This repository hosts all the …\nThis repository hosts all the research on DAS for the collaboration between Codex and the EF. - GitHub - codex-storage/das-research: This repository hosts all the research on DAS for the collabora…\n\n\n\n\nzk_id\nSo we are at the moment most likely to use KZG commitments with a 2d RS polynomial. Basically just copy Ethereum. Reason is: \n\nOur rollups/EZ leader will generate this, and those are beefier machines than the Base Layer. The base layer nodes just need to verify and sign the EC fragments and return them to complete the VID protocol (and then run consensus on the aggregated signed proofs).\nIf we ever decide to change the design for the VID dispersal to be done by Base Layer leaders (in a multileader fashion), it can be distributed (rows/columns can be reconstructed and proven separately). I don’t think we will pursue this, but we will have to if this scheme doesn’t scale with the first option.\n\ndryajov — 08/01/2023 1:55 PM\nThis might interest you as well - https://blog.subspace.network/combining-kzg-and-erasure-coding-fc903dc78f1a\nMedium\nCombining KZG and erasure coding\nThe Hitchhiker’s Guide to Subspace  — Episode II\n\n\n\n\n[1:56 PM]\nThis is a great analysis of the current state of the art in structure of data + commitment and the interplay. I would also recoment reading the first article of the series which it also links to\n\n\nzk_id — 08/01/2023 3:04 PM\nThanks @dryajov @Leobago ! Much appreciated!\n\n\n[3:05 PM]\nVery glad that we can discuss these things with you. Maybe I have some specific questions once I finish reading a huge pile of pending docs that I’m tackling starting today…\n\n\nzk_id — 08/01/2023 6:34 PM\n@Leobago @dryajov I was playing with the DAS simulator. It seems the results are a bunch of XML. Is there a way so I visualize the results?\n\n\nzk_id\n@Leobago @dryajov I was playing with the DAS simulator. It seems the results are a bunch of XML. Is there a way so I visualize the results?\nLeobago — 08/01/2023 6:36 PM\nYes, checkout the visual branch and make sure to enable plotting in the config file, it should produce a bunch of figures \n\n\n[6:37 PM]\nYou might find also some bugs here and there on that branch \n\n\nzk_id — 08/01/2023 7:44 PM\nThanks!\n\n"},"codex/updates/2023-08-01":{"title":"2023-08-01 Codex weekly","links":[],"tags":["codex-updates"],"content":"Codex update Aug 1st §\nClient §\nMilestone: Merkelizing block data §\n\nInitial design writeup https://github.com/codex-storage/codex-research/blob/master/design/metadata-overhead.md\n\nWork break down and review for Ben and Tomasz (epic coming up)\nThis is required to integrate the proving system\n\n\n\nMilestone: Block discovery and retrieval §\n\nSome initial work break down and milestones here - https://docs.google.com/document/d/1hnYWLvFDgqIYN8Vf9Nf5MZw04L2Lxc9VxaCXmp9Jb3Y/edit\n\nInitial analysis of block discovery - https://rpubs.com/giuliano_mega/1067876\nInitial block discovery simulator - https://gmega.shinyapps.io/block-discovery-sim/\n\n\n\nMilestone: Distributed Client Testing §\n\nLots of work around log collection/analysis and monitoring\n\nDetails here https://github.com/codex-storage/cs-codex-dist-tests/pull/41\n\n\n\nMarketplace §\nMilestone: L2 §\n\nTaiko L2 integration\n\nThis is a first try of running against an L2\nMostly done, waiting on related fixes to land before merge - https://github.com/codex-storage/nim-codex/pull/483\n\n\n\nMilestone: Reservations and slot management §\n\nLots of work around slot reservation and queuing https://github.com/codex-storage/nim-codex/pull/455\n\nRemote auditing §\nMilestone: Implement Poseidon2 §\n\nFirst pass at an implementation by Balazs\n\nprivate repo, but can give access if anyone is interested\n\n\n\nMilestone: Refine proving system §\n\nLost of thinking around storage proofs and proving systems\n\nprivate repo, but can give access if anyone is interested\n\n\n\nDAS §\nMilestone: DHT simulations §\n\nImplementing a DHT in Python for the DAS simulator.\nImplemented logical error-rates and delays to interactions between DHT clients.\n"},"codex/updates/2023-08-11":{"title":"2023-08-11 Codex weekly","links":[],"tags":["codex-updates"],"content":"Codex update August 11 §\n\nClient §\nMilestone: Merkelizing block data §\n\nInitial Merkle Tree implementation - https://github.com/codex-storage/nim-codex/pull/504\nWork on persisting/serializing Merkle Tree is underway, PR upcoming\n\nMilestone: Block discovery and retrieval §\n\nContinued analysis of block discovery and retrieval - https://hackmd.io/_KOAm8kNQamMx-lkQvw-Iw?both=#fn5\n\nReviewing papers on peers sampling and related topics\n\nWormhole Peer Sampling paper\nSmoothcache\n\n\n\n\nStarting work on simulations based on the above work\n\nMilestone: Distributed Client Testing §\n\nContinuing working on log collection/analysis and monitoring\n\nDetails here https://github.com/codex-storage/cs-codex-dist-tests/pull/41\nMore related issues/PRs:\n\nhttps://github.com/codex-storage/infra-codex/pull/20\nhttps://github.com/codex-storage/infra-codex/pull/20\n\n\n\n\nTesting and debugging Condex in continuous testing environment\n\nDebugging continuous tests cs-codex-dist-tests/pull/44\npod labeling cs-codex-dist-tests/issues/39\n\n\n\n\nInfra §\nMilestone: Kubernetes Configuration and Management §\n\nMove Dist-Tests cluster to OVH and define naming conventions\nConfigure Ingress Controller for Kibana/Grafana\nCreate documentation for Kubernetes management\nConfigure Dist/Continuous-Tests Pods logs shipping\n\nMilestone: Continuous Testing and Labeling §\n\nWatch the Continuous tests demo\nImplement and configure Dist-Tests labeling\nSet up logs shipping based on labels\nImprove Docker workflows and add ‘latest’ tag\n\nMilestone: CI/CD and Synchronization §\n\nSet up synchronization by codex-storage\nConfigure Codex Storage and Demo CI/CD environments\n\n\nMarketplace §\nMilestone: L2 §\n\nTaiko L2 integration\n\nDone but merge is blocked by a few issues - https://github.com/codex-storage/nim-codex/pull/483\n\n\n\nMilestone: Marketplace Sales §\n\nLots of cleanup and refactoring\n\nFinished refactoring state machine PR link\nAdded support for loading node’s slots during Sale’s module start link\n\n\n\n\nDAS §\nMilestone: DHT simulations §\n\nImplementing a DHT in Python for the DAS simulator - https://github.com/cortze/py-dht.\n\nNOTE: Several people are/where out during the last few weeks, so some milestones are paused until they are back"},"codex/updates/2023-08-31":{"title":"2023-08-31 Codex weekly","links":[],"tags":["codex-updates"],"content":"Codex Update August 21-31 §\nClient §\nMilestone: Block Merkelization §\n\nStoring and retrieving data using merkle trees\nCoders for merkle trees\nRefine merkle tree construction\n\nMilestone: Block Exchange protocol refinements and simulations §\n\nTracker simulation implementation\nBlock exchange protocol thoughts\n\nhttps://hackmd.io/ydT3AiliS8q2vdixBUXvCQ\n\n\nFollow swarmsim repo for updates\n\nMilestone: Async Disc Access &amp; Threading support §\n\nTests on sharing thread data with refc\nerrorVariable and thread safety\n\nFix error binding in without statement on multiple threads\n\n\nWIP: Prototype proxy IO threadpool\n\nMilestone: Client stability and debugging §\n\nMajor effort to stabilize the Codex client through continuous automated testing\n\nStart discovery after announce address is updated\nStart discovery after announce address is updated\nRetrieve empty blocks\n\n\n\nInfra §\nMilestone: Monitoring and Metrics §\n\nInstall Node exporter and Prometheus in Dist-Tests cluster\nGrafana Dashboard updates\nAutomated metrics scraping\n"},"codex/updates/2023-09-15":{"title":"2023-09-15 Codex weekly","links":[],"tags":["codex-updates"],"content":"Client §\nMilestone: Block Merkelization §\n\nContinuing work on merkelization\n\nStoring and retrieving data using merkle trees\nCoders for merkle trees\nRefine merkle tree construction\n\n\n\nMilestone: Block Exchange protocol refinements and simulations §\n\nTracker simulation implementation\nBlock exchange protocol thoughts\n\nhttps://rpubs.com/giuliano_mega/1067876\nhttps://rpubs.com/giuliano_mega/1082104\n\n\nFollow swarmsim repo for updates\n\nMilestone: Async Disc Access &amp; Threading support §\n\nWork on IO threads support\n\nhttps://github.com/codex-storage/nim-datastore/pulls\nSome early integration here - https://github.com/codex-storage/nim-codex/pull/552\n\nBased mostly on https://github.com/codex-storage/nim-codex/pull/545 and prev work by @elcritch\n\n\n\n\n\nMilestone: Client stability and debugging §\n\nMajor effort to stabilize the Codex client through continuous automated testing\n\nInfra §\nMilestone: Monitoring and Metrics §\n\nInstall Node exporter and Prometheus in Dist-Tests cluster\nGrafana Dashboard updates - waiting for public DNS to be setup\nAutomated metrics scraping - waiting for public DNS to be setup\n\nMarketplace §\nMilestone: Availabilities and Reservations §\n\nWork ongoing in\n\nhttps://github.com/codex-storage/nim-ethers\nhttps://github.com/codex-storage/codex-contracts-eth\nhttps://github.com/codex-storage/nim-codex\n\n\nSome recent PRs\n\nhttps://github.com/codex-storage/nim-ethers/pull/54\nhttps://github.com/codex-storage/nim-codex/pull/535\n\n\n\nResearch §\nMilestone: Publications §\n\nWhite paper - https://docs.google.com/document/d/1LCy23m90IHf32aUVhRT4r4772w1BfVcSLaJ0z9VTw9A/edit#heading=h.qs3bayckj5u4\nVarious publications incoming from Csaba\n\nDAS §\nMilestone: DAS Design §\n\nOngoing discussions around - https://ethresear.ch/t/peerdas-a-simpler-das-approach-using-battle-tested-p2p-components/16541\n\nMilestone: Measurments and simulations §\n\nWork continues on simulating various aspects of the DHT in https://github.com/cortze/py-dht\nCsaba discussed/suggested fixes for Discv5 with Felix Lange\n"},"codex/updates/2023-09-29":{"title":"2023-09-29 Codex weekly","links":[],"tags":["codex-updates"],"content":"Client §\nMilestone: Block Merkelization §\n\nMerkelization current working branch\n\nhttps://github.com/codex-storage/nim-codex/tree/sending-blocks-with-proofs-over-the-network\n\n\n\nMilestone: Block Exchange protocol refinements and simulations §\n\nNot much done on it this past couple of weeks, progress can be tracked here when it resumes\n\nhttps://github.com/codex-storage/swarmsim\n\n\n\nMilestone: Async Disc Access &amp; Threading support §\n\nWork on IO threads support\n\nAll related PRs are here https://github.com/codex-storage/nim-datastore/pulls\n\nWe now have a clear idea of how to implement and integrate it - https://github.com/codex-storage/nim-codex/pull/552\n\n\nfound a leak in Nim’s SharedPtr https://github.com/nim-lang/threading/issues/45 and fix  https://github.com/nim-lang/threading/pull/46\n\n\n\nMilestone: Client stability and debugging §\n\nMajor effort to stabilize the Codex client through continuous automated testing\n\nMost team members are working on this on and off, testing is ongoing\n\n\n\nInfra §\n\nInstalled cert-manager in Dist-Tests cluster\nImplemented External OAUTH Authentication for Grafana/Kibana (need to adjust internal authentication)\nExposed Grafana and Kibana\nLosing the logs during Continuous Tests run\n\nResearch §\nMilestone: Publications §\n\nWhite paper ongoing - https://docs.google.com/document/d/1LCy23m90IHf32aUVhRT4r4772w1BfVcSLaJ0z9VTw9A/edit#heading=h.qs3bayckj5u4\n\nMilestone: Sampling for storage proofs §\n\nLarge discussion around erasure coding for sampling\n\nhttps://github.com/codex-storage/zk-research-artifacts/blob/master/sampling/sampling.pdf\nhttps://hackmd.io/DxJzAuTZROulBhPWqScmCg?view\nhttps://github.com/codex-storage/codex-research/pull/184\nhttps://hackmd.io/kxSF8wjPS3arDFcqFJrNDw\n\n\n\nDAS §\nMilestone: DAS Design §\n\nOngoing discussions around - https://ethresear.ch/t/peerdas-a-simpler-das-approach-using-battle-tested-p2p-components/16541\nspace-DAS (don’t have link), a proposal to use spacefilling curves for sample placement\n\nMilestone: Measurements and simulations §\n\nWork continues on simulating various aspects of the DHT in https://github.com/cortze/py-dht\n"},"codex/updates/2023-10-23":{"title":"2023-10-25 Codex weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Oct 2 - 23 §\n\nWe had a teamwide offsite in Crete from October 6th to the 12th, during which we were able to discuss and come up with concrete solutions around several important pieces of the project aspects such as the proving system and the contract start interactions, as well as plan out outstanding work for our upcoming testnet launch at the end of the year. The meeting was very productive and it helped align the team around the current and future outstanding work in order to hit our big end of year milestone.\n\nClient §\nMilestone: Block Merkelization §\n\nMerkelization concrete PR in review\n\nhttps://github.com/codex-storage/nim-codex/pull/566\n\n\n\nMilestone: Block Exchange protocol refinements and simulations §\n\nSome results were presented during the offsite\n\nhttps://rpubs.com/giuliano_mega/codex-swarms\n\n\n\nMilestone: Async Disc Access &amp; Threading support §\n\nWork on IO threads support (not much progress due to offsite, will be picked up asap)\n\nAll related PRs are here https://github.com/codex-storage/nim-datastore/pulls\n\nWe now how a clear idea of how to implement and integrated it - https://github.com/codex-storage/nim-codex/pull/552\n\n\n\n\n\nMilestone: Sampling and Storage Proofs §\n\nWork on storage proofs is ongoing under https://github.com/codex-storage/zk-research-artifacts/tree/master/storage_proofs\n\nA circom implementation is being worked on in https://github.com/codex-storage/zk-research-artifacts/tree/master/storage_proofs/MVP/circuit\nReference/testing implementation to consume the circuits is done here https://github.com/codex-storage/zk-research-artifacts/tree/master/storage_proofs/MVP/reference\n\n\nAnalysis of the sampling strategies are available here https://github.com/codex-storage/zk-research-artifacts/tree/master/sampling\n\nMilestone: Client stability and debugging §\n\nMajor effort to stabilize the Codex client through continuous automated testing\n\nWork on better log analysis is being done here https://github.com/gmega/logtools\nRunning several load tests with ˜100 nodes using the dist testing framework https://github.com/codex-storage/cs-codex-dist-tests\n\n\n\nInfra §\n\nInvestigating and fixing issues related to Elasticsearch logshipping\n\nInstall Loki in Dist-Tests cluster\nFix Vector errors related to the Kubernetes logs shipping\nConfigure Vector to ship Dist/Continuous-Tests logs to Loki\n\n\n\nResearch §\nMilestone: Publications §\n\nWhite paper ongoing - https://docs.google.com/document/d/1LCy23m90IHf32aUVhRT4r4772w1BfVcSLaJ0z9VTw9A/edit#heading=h.qs3bayckj5u4\n\nDAS §\nMilestone DAS §\n\nOur current engagement with the EF is coming to an end a summary of the work done has been collected here\n\nhttps://hackmd.io/TYqF-wj2SIWwpS2F_PhWzg\n\n\n"},"codex/updates/2023-11-03":{"title":"2023-11-03 Codex weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Oct 24th - Nov 3rd §\n\nThe team is working towards deploying a beta testnet by the end of the year, and most work is centered around finishing all the required functionality for that.\n\nClient §\nEpic: Block Merkelization §\n\nMerkelization concrete PR in review\n\nhttps://github.com/codex-storage/nim-codex/pull/566\n\nUnifying the flows\nMaking treeCid to be the same as treeRoot\nStoring proofs in key/value storage\n\n\n\n\n\nEpic: Wiring the Proving System §\n\nWork on storage proofs is ongoing in https://github.com/codex-storage/codex-storage-proofs-circuits\nWork on Poseidon2 is being done in - https://github.com/codex-storage/nim-poseidon2\n\nEpic: Improve Client Stability §\n\nExplored using CI flow for cloud-based benchmark harness, settled on Packer for image scripts Packer scripts - private repo\nSimple logging filtering/merging tool: logtools\nMicrobenchmark of Sql backend in two separate VMs\nRan remaining benchmarks, summary at Benchmark Summary\nExploring behavior of nim-datastore and sqlite\nContinued working on a “quick-and-dirty” test setup, managed to get it working\nQuick PoC for a codex net deployed with Terraform on VMs: Terraform main.tf\nAsync Profiling\n\nMarketplace §\nEpic: End-to-end Testing §\n\nFurther work on multinode integration testing\n\nprevent stuck transactions by async locking nonce sequencing (+ estimate gas)\nOn transaction failure, fetch revert reason with replayed transaction \nSupport logging to file\n[fix] Ensure AsyncLock is released in case of exception \n\n\nfeat: ensure block expiry\n\nInfra §\n\nCreated Testnet Kubernetes cluster 56\nDeployed Testnet cluster basic components 57\nConfigured DNS name for Testnet cluster 76\nCreated Service Accounts in Testnet cluster 77\nChecked CORS issue on Codex Demo 79\nConfigured TCP/UDP port forwarding for Testnet deployment 80\n"},"codex/updates/2023-11-10":{"title":"2023-11-10 Codex weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Nov 6th - Nov 10th §\n\nThe team is working towards deploying a beta testnet by the end of the year, and most work is centered around finishing all the required functionality for that.\n\nClient §\nEpic: Block Merkelization §\n\nMerkelization concrete PR in review - mostly ready for merging\n\nhttps://github.com/codex-storage/nim-codex/pull/566\n\n\nWorking on nim-datasotre to support atomic updates\n\nhttps://github.com/codex-storage/nim-datastore/pull/58\n\n\n\nEpic: Wiring the Proving System §\n\nMerged conversion from field elements into bytes in nim-poseidon2\n\nhttps://github.com/codex-storage/nim-poseidon2/pull/6\n\n\nAdded streaming API for Balazs’s sponge in nim-poseidon2\n\nhttps://github.com/codex-storage/nim-poseidon2/pull/9\n\n\nFixed merkle root construction for odd number of elements in nim-poseidon2\n\nhttps://github.com/codex-storage/nim-poseidon2/pull/8\n\n\n2D erasure coding WIP\n\nhttps://github.com/codex-storage/nim-codex/pull/608\n\n\n\nEpic: Improve Client Stability §\n\nAsync profiling (it might actualy work)\n\nhttps://github.com/codex-storage/nim-codex/pull/600\nPrometheus metrics collector completed with tests\n\n\n\nMarketplace §\nEpic: End-to-end Testing §\n\nAddressed access issues within the marketplacesuite template, pinpointing a problem with a provider declared in ethertest and overcoming the challenge through deep template layer analysis.\nDiscussions about improving the repostore maintenance module, specifically the method for returning bytes to Availabilities.\nOptimizing multinode integration tests, streamlining the process to enhance efficiency and performance.\nIntegration test for the proving loop in the sales state module that was previously causing hang-ups, ensuring smoother operation.\nProgressed towards a cleaner integration test structure with the creation of a draft PR, setting the stage for more structured testing and deployment.\n\nInfra §\n\nConfigure TCP/UDP port forwarding for Testnet deployment 80\nOrganize Grafana Dashboards 82\nConfigure Continuous Tests automation 69\nRun Continuous Tests and check metrics\nOrganize Grafana Dashboards\nConfigure Continuous Tests automation enhancement\nUpdate Vector config\nConfigure TCP/UDP port forwarding for Testnet deployment\n"},"codex/updates/2024-01-22":{"title":"2024-01-22 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Dec 15th - Jan 22th §\n\nThe Codex team is currently wrapping up the demo for the Q1/Q2 public testnet release. An internal testnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\n\nOngoing and new lines of research and development will soon begin in preparation for the next version of Codex that will be used for the mainnet release.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe different teams have actively moving on various fronts. The following are their team updates to various ongoing Epics.\nClient §\nEpic: Wiring the Proving System §\n\nCompleted:\n\nWire Sampler to SlotBuilder\nExports fromBytes from the library\nConvert from 32 bytes\n\n\nOngoing:\n\nDataset expiry\nUpdate DataSampler to match updated SlotBuilder\nInvestigate: way to run codex tests through valgrind or similar tool\nIntegrate DataSampler in Marketplace callbacks\n\n\n\nEpic: Improve Client Stability §\n\nCompleted:\n\nUpdate to Chronos V4\nAdd exception handling for Chronos V4\nCompiler PR to Chronos V4 bugs\n\n\nOngoing:\n\nCodex CI improvements\nTrack down segfault issue after rebase of Chronos V4 PR\n\n\n\nMarketplace §\nEpic: End-to-end Testing §\n\nCompleted:\n\nAdd working testnet starter\nUpdates to Codex frontend include:\n\nAdd node storage information\nUpload page updates periodically\nChange error messages to appear below input area instead of an alert\n\n\nFinish the Github Workflow to compile, build and setup the circuit with included generated proof for testing\nInitial work on integration of the verifier into smart-contract suite, with passing storage proof tests\nRebase nim-ethers to the latest version, 0.7.1\nRebase create logging proxy had symbol resolution errors, created PR for nim-poseidon2 to resolve and complete rebase\nRebase multinode integration test refactor, had to remove upraises annotations from some callbacks in the tests\nRefactor add MarketError, refactoring ethers error handling, reviewing verifier integration in codex-contracts-eth\nComplete Github Workflow for testing, worked on integration of verifier into smart-contract suit.\nReleased 0.10.13 with improvements, released asynctest 0.5.0,\n\n\nOngoing:\n\nContinue work on Solidity verifier\n\n\n\nInfra §\n\nCompleted:\n\nResolve issues on docs.codex.storage\nAdd documentation about DNS names and convention\nCheck download speed for codex-storage-proofs-circuits\nSwitch from AWS Windows instance to Hetzner\n\n\nOngoing:\n\nDeploy a site to store circuit ceremony files\nDeploy Codex Storage nodes in Testnet cluster\n\n\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n\n\nCompleted:\n\nDebug Groth16 implementation, discovered local bug in [constantine], made a CLI interface (+other improvements) for the Groth16 prover\nResearch and solve puzzles for ZK hack IV kickoff\nPlay with binary field used in the new Binius proof system\nCatchup with recent research (https://zkmesh.substack.com/p/zkmesh-dec-2023-recap)\nExplore Nova-Scotia, discussed hash padding\nUpdate Merkle tree proposal document\nExplore Ascon hash as a possible replacement for SHA256\n\n\nOngoing:\n\nPoC Ascon hash implementation in circom (not competitive with other hashes, at least not in circom)\nThink about how to implement SHA256 proofs\nMore learning about lookups and folding\nStart working out the details of an idea about how to do efficient proofs of computations on bits (eg. range checks, classical hash functions)\n\n\n"},"codex/updates/2024-01-29":{"title":"2024-01-29 Codex Weekly","links":[""],"tags":["codex-updates"],"content":"Codex Update Jan 22nd - Jan 29th §\n\nThe Codex team continues to make progress with various initiatives to wrap up the demo for the Q1/Q2 public testnet release. An internal testnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\n\nOngoing and new lines of research and development will soon begin in preparation for the next version of Codex that will be used for the mainnet release.. Here are the updates from different team members and their ongoing work.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe different teams have actively moving on various fronts. The following are their team updates to various ongoing Epics.\nClient §\nEpic: Nim Improvements §\n\nCompleted:\n\nFiled Atlas issue to restore handling forked repos\nFiled Atlas issue for handling “vendoring” style setups\n\n\nOngoing:\n\nReview Atlas graph updates and contribute\n\n\n\nEpic: Wiring the Proving System §\n\nCompleted:\nOngoing:\n\nDataset expiry\nUpdate DataSampler to match updated SlotBuilder\nInvestigate: way to run codex tests through valgrind or similar tool\nIntegrate DataSampler in Marketplace callbacks\n\n\n\nEpic: Improve Client Stability §\n\nCompleted:\nOngoing:\n\nContibue rebasing of unmerged Chronos V4 PR and build improvements PR + fixes to initial idea on builds\nContinue work on asynctest branch\nBug-fixing to track down the “file sizes differ” bug\nOther bugs to be fixed\n\n\n\nMarketplace §\nEpic: End-to-end Testing §\n\nCompleted:\n\nFix tests and replcae GPL licensed ZK verifier w/ MIT version that take JSON output from Circom in contract\nAdd formatting check to CI in codex-contracts-eth repo\nRebase Marketplace integration test refactor with erasure coding changes\n\n\n\nOngoing:\n\nPersistent Availabilities\n\nDesign Plan\n\n\nAdd duration to Codex frontend\nAdded a calendar for the expiry of creating ROSC’s\nWork to add ceremony files to Codex\n\nCeremony file distribution\nAdd Ceremony file hash to Marketplace’s Contract configuration\nAdd support to retrieve Ceremony file hash from Contract’s configuration\nAdd support for Ceremony file hash download from S3\n\n\nContinue work on updating nim-ethers to support JSON-RPC breaking changes and pulling out utils/json to its own library\n\n\n\nInfra §\n\nCompleted:\n\nDeploy a site to store circuit ceremony files\nAutomate Codex ceremony files upload to Cloudflare R2 using GitHub Actions\n\n\nOngoing:\n\nCreate Codex Helm chart\nDeploy Codex Storage nodes in Testnet cluster\n\n\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n\n\nCompleted:\n\nImplement G2 curves (so most building blocks are now in place in my algebra backend to be able to experiment\nReview work from Hashcloak collaboration for zk backend benchmarking test suite\n\n\nOngoing:\n\nNew proof system design proposal\n\n\n"},"codex/updates/2024-02-05":{"title":"2024-02-05 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Jan 29nd - Feb 5th §\n\nThe Codex team continues to make progress with various initiatives to wrap up the demo for the Q1/Q2 public testnet release. An internal testnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\nOngoing and new lines of research and development will soon begin in preparation for the next version of Codex that will be used for the mainnet release.. Here are the updates from different team members and their ongoing work.\nDevelopment is currently broken into three distinct teams:\n\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe different teams have actively moving on various fronts. The following are their team updates to various ongoing Epics.\nClient §\nEpic: Nim Improvements §\nCompleted:\n\nFiled issue for adding Atlas / non-Nimble support for packages\nStart working on Atlas command changes\n\nOngoing:\n\nCreate a repo as a place to start implementing some core async-threading tools for Chronos like worker pool &amp; disk io on top of the ThreadSignalPtr primitive\n\nplans to support refc &amp; orc\n\n\n\nEpic: Wiring the Proving System §\nCompleted:\n\nWrapped ark-circom in a C FFI via:\n\nnim-circom-compat and\ncircom-compat-ffi\n\n\n\nOngoing:\n\nIntegration of codex-storage-proofs-circuits with a PR in nim-codex\n\nEpic: Improve Client Stability §\nCompleted:\n\nUpdated profiler branch for debugging\nPorted the profiler to Chronos V4\nWrote separate test runner for two client test to try to figure out the origin of a file size bug which magically disappeared\n\nOngoing:\n\nFinish work to take down draft flag from PR Expiry per dataset\nWrite tests for PR Safe block deletion (with ref count)\nLook into the CI/docker packaging/local build tooling for Waku and Nimbus as part of build improvements PR\nChronos V4 branch\nPinned versions for Chronos and json-rpc\n\nMarketplace §\nEpic: End-to-end Testing §\nCompleted:\n\nRebased multinode integration test refactor which had two failing tests due to the erasure coding changes\nRebased Marketplace integration test suite\nAdded support for Result types using formatIt for logging proxy\nFinished the verifier contract\nDeployed a dummy verifier on local networks for testing\nFinished updates to nim-ethers, all tests passing, including in Nim v2\nFixed an issue in the nim-ethers json-rpc update\n\nDerived Signers could not access the derived getAddress and sendTransaction when their async raises were updated with SignerError\n\n\n\nOngoing:\n\nContinue work on updating nim-ethers to support json-rpc breaking changes\nContinue work on supporting json-rpc breaking changes and pulling out utils/json to its own lib\nIntegrate contract changes into nim-codex\nLook into removing waitFor in integration tests\nReview and clean up nim-ethers changes\n\nTry to figure out a cleaner way to handle exceptions instead of catching all CatchableErrors\n\n\nStart tweaking the nim-json api to normalize both serialize and deserialize pragmas, with modes: OptOut, OptIn, and Strict\nWIP on adding PATCH call for Availabilities\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n\nCompleted:\n\nFrobenius endomorphism &amp; pairing implementation\nReview the Solidity Groth16 verifier\n\nOngoing:\n\nDAS simulator improvements to cover more diffusion models\nStart DAS sample query mechanism design\nProof recursion ideation\n"},"codex/updates/2024-02-12":{"title":"2024-02-12 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Feb 6th - Feb 12th §\n\nThe Codex team continues to make progress with various initiatives to wrap up the demo for the Q1/Q2 public testnet release. An internal testnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\nOngoing and new lines of research and development will soon begin in preparation for the next version of Codex that will be used for the mainnet release.. Here are the updates from different team members and their ongoing work.\nDevelopment is currently broken into three distinct teams:\n\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe different teams have actively moving on various fronts. The following are their team updates to various ongoing Epics.\nClient, Testing and Infrastructure §\nEpic: Nim Improvements §\nCompleted:\n\nAdd Nim-matrix workflow to run on merge queue\nChanges to build improvements proposal so default version for the compiler is now represented as special version repo_version which can be accessed locally and in CI\n\nOngoing:\n\nNim memory profiler\n\nEpic: Wiring the Proving System §\nCompleted:\n\nIntegrated zk verifier into nim-codex\n\nOngoing:\n\nStarted reviewing the Circom circuit\n\nEpic: Improve Client Stability §\nCompleted:\n\nTwo PRs for testing framework (one PR #93, and one PR #94)\n\nOngoing:\n\nRun Continuous-Test outside of the cluster to reproduce ‘file size issue’\n\nEpic: Infra §\nCompleted:\nOngoing:\n\nCreate Codex Helm chart\nDeploy Codex Storage nodes in Testnet cluster #115\nTracking down the timeout issues in Codex\nUpdates to logtools\n\nNow understand what deploy IDs and test runs are (4 min video here);\n\n\nWorked on the block flow tracker\n\nMarketplace §\nEpic: End-to-end Testing §\nCompleted:\n\nFixed decoding issue in nim-ethers\nWorkaround for that same decoding issue\n\nCan’t use the fix from nim-ethers yet, Codex is still on old version of chronos\n\n\nPublished nim-serde\n\nFinalized nim-serde api: now has two main pragmas, serialize and deserialize, that can be applied at the object-level or field-level:\nEach can set key (valid at field-level), ignore  (valid at field-level), and mode (valid at object-level)\n\nmode can be one of:\n\nOptOut\nOptIn\nStrict\n\n\n\n\nMany more tests for the nim-serde lib — serialize OptIn, OptOut, Strict and deserialize OptIn, OptOut, Strict\nAdded a comprehensive README to nim-serde\nAdded CI to serde, with branch protection rules on master\nAdded support for deserializing seq[byte]\n\n\nUpdated nim-ethers json-rpc and chronos upgrade PR to use nim-serde instead of the json util. Created the PR https://github.com/codex-storage/nim-ethers/pull/64\n\nOngoing:\n\nWIP on finishing the Availabilities API endpoints tweaks\nTried to integrate nim-serde in nim-codex, but running into symbol clashes with parseJson, so changed parseJson to JsonNode.parse, still needs to be integrated into nim-codex\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n\nCompleted:\nOngoing:\n\nMore work on the algebra backend (pairings, APIs)\nWork towards an independent Groth16 prover (so that we can debug the Nim one) - an initial version of that seems to work now\n"},"codex/updates/2024-02-19":{"title":"2024-02-19 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Feb 13th - Feb 19th §\n\nThe Codex team continues to make progress with various initiatives to wrap up the demo for the Q1/Q2 public testnet release. An internal testnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\nOngoing and new lines of research and development will soon begin in preparation for the next version of Codex that will be used for the mainnet release.. Here are the updates from different team members and their ongoing work.\nDevelopment is currently broken into three distinct teams:\n\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe different teams have actively moving on various fronts. The following are their team updates to various ongoing Epics.\nClient §\nEpic: Nim Improvements §\nCompleted:\n\nInitial PR up for Apatheia async-threading\nOngoing:\nStarted implementing an async-threading API\n\nEpic: Wiring the Proving System §\nCompleted:\nOngoing:\n\nCode review of the circom circuit\nProgress on prover integration\nDetermine why different amounts of data were being downloaded for different slot indices (and failing to release reservations due to be larger than the slotSize)\nGetting integration tests PR #662 into shape for merging\n\nIntegration tests were generally not using the right ec params (num nodes, dataset size, tolerance)\nAfter EC params were corrected, some of the tests were not working due to the recent async clock.now update\n\nCreated a revert PR for the async clock.now PR\n\n\n\n\n\nEpic: Improve Client Stability §\nCompleted:\nOngoing:\n\nStarted work on delegating expensive computations to a separate thread\nReviewing changes made to Apatheia\nStarted integrating apaethia into nim-codex\nRebasing two large PRs against latest master:\n\nSafe block deletion (with ref count)\nExpiry per dataset\n\n\n\nTesting §\nCompleted:\nOngoing:\n\nContinue work to track down the timeout issues in Codex\n\nDid a bunch of updates to logtools, which now understand what deploy IDs and test runs are (4 min video here);\n\n\nWorked on the block flow tracker in tandem with the logtools\n\nNot cancelling pending WantHave’s and under the right conditions this makes the peer implode\n\n\nMade some changes and opened PRs for test framework (one normal, and one tiny PR);\nMade changes to the build improvements proposal, so that the default version for the compiler is now represented as special version repo_version which can be accessed locally and in CI\n\nFor now this is hidden in this commit; started treating those PRs as low priority\n\n\nIsolated the Codex issue to a working hypothesis of failed cancel messages\n\nSmaller-scale test validation of above issue\nLearned how to actually slow down traffic on a given port\n\nIn the end that was not the issue, the issue being instead that peers need to create libp2p connections so they pop into each other’s PeerCtxStore\n\n\n\n\nPut together failing test for the cancellation issue\n\nGoes into testblockexc.nim\nNeed to provide a fix\n\n\n\nInfrastructure §\nCompleted:\n\nAdjust workflows for changelog generation #5\nFix Docker entrypoint NAT helper variables #706\n\nOngoing:\n\nCreate Codex Helm chart #58\nDeploy Codex Storage nodes in Testnet cluster #115\n\nMarketplace §\nEpic: End-to-end Testing §\nCompleted:\n\nUpdated nim-ethers pull request to integrate serde\nRebased integration test refactor\nNim-serde changelog workflow in CI\nFinished moving nim-codex json util to serde\n\nOngoing:\n\nSee Epic: Wiring the Proving System\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n\nCompleted:\n\nFirst working version of the Haskell Groth16 prover\n\nWork towards an independent Groth16 prover (so that we can debug the Nim one) - an initial version of that seems to work now\n\n\nReviewed improvements to the circuit\n\nOngoing:\n\nMore work on the algebra backend (pairings, APIs)\nStarted writing down some musings about aggregation (WIP)\nFound the bug in the Circom zkey usage preventing valid proof verification\n"},"codex/updates/2024-02-26":{"title":"2024-02-26 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Feb 20th - Feb 26th §\n\nThe Codex team continues to make progress with various initiatives to wrap up the demo for the Q1/Q2 public testnet release. An internal testnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\nOngoing and new lines of research and development will soon begin in preparation for the next version of Codex that will be used for the mainnet release.. Here are the updates from different team members and their ongoing work.\nDevelopment is currently broken into three distinct teams:\n\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe different teams have actively moving on various fronts. The following are their team updates to various ongoing Epics.\nClient, Testing and Infrastructure §\nCompleted:\nOngoing:\n\nCodex team members heading to attend ETH Denver\n\nEpic: Nim Improvements §\nCompleted:\nOngoing:\nEpic: Wiring the Proving System §\nCompleted:\nOngoing:\nEpic: Improve Client Stability §\nCompleted:\nOngoing:\nMarketplace §\nEpic: End-to-end Testing §\nCompleted:\n\nFinished PR for availabilities update endpoints\n\nRan into very weird bug in one of these:\n\nChronos server implementation, Presto or Nim’s HTTPClient\nCould not debug and decided to rather move from HTTP 204 response to 200 one\n\n\nCreated reproduction repo\nLogged the issue in Presto repo\n\n\nDebugged non-working Dist. testing contracts\n\nOngoing:\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n\nCompleted:\n\nhelped with figuring out the Ethereum elliptic curve conventions\ngave an elliptic curve talk at the local university; slides for the interested\nfound the second bug in the Nim Groth16 prover (in Constantine again)\n\nOngoing:\n\nstarted thinking about the small / dynamic data problem\n"},"codex/updates/2024-03-04":{"title":"2024-03-04 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Feb 27th - Mar 4th §\n\nThe Codex team continues to make progress with various initiatives to wrap up the demo for the Q1/Q2 public testnet release. An internal testnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\nOngoing and new lines of research and development will soon begin in preparation for the next version of Codex that will be used for the mainnet release.. Here are the updates from different team members and their ongoing work.\nDevelopment is currently broken into three distinct teams:\n\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe different teams have actively moving on various fronts. The following are their team updates to various ongoing Epics.\nClient, Testing and Infrastructure §\nCompleted:\n\nCodex team members attended ETH Denver\nOngoing:\n\nEpic: Nim Improvements §\nCompleted:\nOngoing:\n\nStarted a PR to fix Atlas after SAT integration\nFinishing basic fixes PR in Atlas\nextracted the profiler into its own library\n\nretained only the instrumentation modifications in our Chronos V4 branch\nafter we merge V4 into Codex (blocked by a bunch of issues), start a discussion with the Chronos folks to try to get the instrumentation part in\n\n\n\nEpic: Wiring the Proving System §\nCompleted:\nOngoing:\n\nCeremony file setup\n\nEpic: Improve Client Stability §\nCompleted:\nOngoing:\n\ntracked a Codex bug during a V4 merge which turned out to be a compiler bug\n\nwith consequences to Chronos\nbug resolution handled by Nim compiler team after being flagged as “showstopper”\n\n\n\nMarketplace §\nEpic: End-to-end Testing §\nCompleted:\n\nAdd IsSyncing to nim-ethers\nAdd sync check to codex startup\nIn-flight flag for outgoing blocks\n\nDiscord role rewards based on on-chain state and events\n\nPartially tested, requires fixed marketplace-dist-test\n\n\n\n\nUpdated and merged: fix for block-retransmit issue\nDebug isSync (nim-ethers update) and update to testnet-starter\n\nOngoing:\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n\nCompleted:\n\nNim Groth16 prover finally appears to work correctly (though with the current workaround it also became significantly slower)\nMulti-threading support in the Nim Groth16 prover\n\nOngoing:\n\nThinking about using FRI commitment for storage proofs\n\nHash based, includes RS, outsourceable, easy to prove large/r data sets\n\n\nThinking about using KZG as updateable commitment\n\nWith efficient proofs for small/updateable data sets\n\n\nDebugging the multithreading bug in the prover\nchecking out new research\nSpeed up the “binary circuit” proposal by a factor of ~2x\nThinking about a (supposedly fast) dedicated SHA256 proof protocol, and how to implement it\n"},"codex/updates/2024-03-11":{"title":"2024-03-11 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Mar 5th - Mar 11th §\n\nThe Codex team continues to make progress with various initiatives to wrap up the demo for the Q1/Q2 public testnet release. An internal testnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\nOngoing and new lines of research and development will soon begin in preparation for the next version of Codex that will be used for the mainnet release.. Here are the updates from different team members and their ongoing work.\nDevelopment is currently broken into three distinct teams:\n\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe different teams have actively moving on various fronts. The following are their team updates to various ongoing Epics.\nClient, Testing and Infrastructure §\nEpic: Multithreading §\nCompleted:\n\nMarked PR as ready - scheduling erasure encoding and decoding on a thread pool\n\nOngoing:\n\nStarted work on scheduling prover computation on a thread pool\n\nEpic: Wiring the Proving System §\nCompleted:\nOngoing:\n\nMarked PR as ready - scheduling erasure encoding and decoding on a thread pool\nStarted work on scheduling prover computation on a thread pool\n\nEpic: Improve Client Stability §\nCompleted\n\nReasoning on why the profiler works the way it does\nClosed bug: fixes double lookups when block does not exist\n\nOngoing:\n\nSome triaging of bugs in the Codex repo, still some way to go\n\nMarketplace §\nEpic: End-to-end Testing §\nCompleted:\nOngoing:\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n\nCompleted:\n\nEthResearch post on sampling techniques (https://ethresear.ch/t/lossydas-lossy-incremental-and-diagonal-sampling-for-data-availability/18963)\nLogos X space with Leo and Danny\nMinor refactor the proof circuit PR\n\nOngoing:\n\nDAS simulator (https://github.com/codex-storage/das-research) paper prep (calls + work)\nShadow based P2P emulator for DAS (https://github.com/cskiraly/dst-gossipsub-test-node/tree/FullDAS)\nLooked into how circom handles custom gates (tldr: it’s easy to abuse for our own purposes, but snarkjs doesn’t implement anything)\nStarted working on prototyping stuff for the new proof system\n"},"codex/updates/2024-03-18":{"title":"2024-03-18 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Mar 12th - Mar 18th §\n\nThe Codex team continues to make progress with various initiatives to wrap up the demo for the Q1/Q2 public testnet release. An internal testnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\nOngoing and new lines of research and development will soon begin in preparation for the next version of Codex that will be used for the mainnet release.. Here are the updates from different team members and their ongoing work.\nDevelopment is currently broken into three distinct teams:\n\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe different teams have actively moving on various fronts. The following are their team updates to various ongoing Epics.\nClient, Testing and Infrastructure §\nClient §\nCompleted\n\nMarked PR as ready - scheduling erasure encoding and decoding on a thread pool https://github.com/codex-storage/nim-codex/pull/716\nPut together reasoning on why the profiler works the way it does;\nClosed a bug re: double lookups when block does not exist;\n\nOngoing\n\nStarted a PR to fix Atlas after SAT integration\nFinishing basic fixes PR in Atlas https://github.com/nim-lang/atlas/pull/120\nStarted work on scheduling prover computation on a thread pool\nFixing comments and rebasing large PRs:\nhttps://github.com/codex-storage/nim-codex/pull/631\nhttps://github.com/codex-storage/nim-codex/pull/678\nWork on Frontend\n\nImplemented dropdown list for expiry input\nStarted working on caching node information for displayed information\n\n\nSome triaging of bugs in the Codex repo, still some way to go;\n\nInfrastructure §\nCompleted\n\n✅ Install VictoriaMetrics in Testnet cluster #130\n✅ Adjust number of nodes in Testnet cluster #136\n✅ Redeploy Testnet cluster components #138\n✅ Install ELK in Testnet cluster #135\n\nOngoing\n\n�️ Install Oauth2 proxy in Testnet cluster #141\n�️ Deploy Testnet cluster components #57\n\nMarketplace §\nCompleted\n\nDiscussions about ceremony files retrival\nPR Reviews:\n\nhttps://github.com/codex-storage/codex-storage-proofs-circuits/pull/7\nhttps://github.com/codex-storage/codex-contracts-eth/pull/83\nhttps://github.com/codex-storage/nim-codex/pull/730\n\n\n\nOngoing\n\nWIP on merging https://github.com/codex-storage/nim-codex/pull/692\nWIP on persistant availabilities\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nEthResearch post on sampling techniques (https://ethresear.ch/t/lossydas-lossy-incremental-and-diagonal-sampling-for-data-availability/18963)\nDAS simulator (https://github.com/codex-storage/das-research) paper prep (calls + work)\nShadow based P2P emulator for DAS (https://github.com/cskiraly/dst-gossipsub-test-node/tree/FullDAS)\nLooked into how circom handles custom gates (tldr: it’s easy to abuse for our own purposes, but snarkjs doesn’t implement anything)\nMinor refactor the proof circuit PR\n\nOngoing\n\nStarted working on prototyping for the new proof system\n"},"codex/updates/2024-03-25":{"title":"2024-03-25 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Mar 19th - Mar 25th §\n\nThe Codex team continues to make progress with various initiatives to wrap up the demo for the Q1/Q2 public testnet release. An internal testnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\nOngoing and new lines of research and development will soon begin in preparation for the next version of Codex that will be used for the mainnet release.. Here are the updates from different team members and their ongoing work.\nDevelopment is currently broken into three distinct teams:\n\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe different teams have actively moving on various fronts. The following are their team updates to various ongoing Epics.\nClient, Testing and Infrastructure §\nClient §\nCompleted\n\nVarious fixes for prover-verifier integration\n\nhttps://github.com/codex-storage/nim-codex/pull/702\n\n\nSplit prover-verifier integration into several PRs and merged them into master\n\nhttps://github.com/codex-storage/nim-codex/pull/702#issuecomment-1986256598\\\n\n\n\nOngoing\n\nSyncing up with testnet owners to help think through our use cases and whether or not we have gaps in our QA/testing plan;\nPut together a small tutorial on deploying contracts on a local Geth network with some code.\n\nTesting §\nCompleted\n\nFixed proof generation is dist-test environment\nFixed crash in dist-test env related to blockchain inspection\nBring up-to-date continuous tests (enable transient-node and marketplace test scenarios)\nOngoing\nWhy do proofs with EC params 1-0 fail?\nNode response to fill-slot call is unreliable in geth env\nWrap up discord-reward bot\n\nInfrastructure §\nCompleted\n\n✅ Install Oauth2 proxy in Testnet cluster #141\n✅ Deploy Testnet cluster components #57\n✅ Install Vector in Testnet cluster #144\n✅ Configure monitoring in Testnet cluster #147\n✅ Send Codex and Geth Bootstrap nodes logs and metrics to the Testnet cluster #148\n\nOngoing\n\n�️ Configure Grafana dashboards for Testnet resources #154\n�️ Add Release workflow for Codex #749\n\nMarketplace §\nCompleted\n\nnim-ethers\n\nSupport Solidity’s custom errors\n\nhttps://github.com/codex-storage/nim-ethers/pull/69\n\n\nUpdate dependencies\n\nhttps://github.com/codex-storage/nim-ethers/pull/70\n\n\nFix flaky test\n\nhttps://github.com/codex-storage/nim-ethers/pull/71\n\n\nMerged fix for Solidity getters\n\nhttps://github.com/codex-storage/nim-ethers/pull/63\n\n\n\n\ncodex-contracts-eth:\n\nFinished verifier refactor:\n\nhttps://github.com/codex-storage/codex-contracts-eth/pull/83\n\n\n\n\ncodex-storage-proofs-circuits:\n\nMerged code review PR:\n\nhttps://github.com/codex-storage/codex-storage-proofs-circuits/pull/5\n\n\n\n\nquestionable:\n\nWorked out a way to handle generic Results in without statements:\n\nhttps://github.com/codex-storage/questionable/pull/59\n\n\n\n\n\nOngoing\n\nSee previous week\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nwrote an initial draft notes about Plonk; github (WIP)\n\nOngoing\n\nworking towards implementing a Plonkish prover with custom accelerator gadgets, so that we can test proof system ideas\nrealized that proof system idea has a botleneck; may still speed up Poseidon hashing, but the new botleneck is much worse for binary circuits like SHA256. To make the latter practical needs new ideas.\n"},"codex/updates/2024-04-01":{"title":"2024-04-01 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Mar 26th - Apr 1st §\n\nThe Codex team continues to make progress with various initiatives to wrap up the demo for the Q1/Q2 public testnet release. An internal testnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\nOngoing and new lines of research and development will soon begin in preparation for the next version of Codex that will be used for the mainnet release.. Here are the updates from different team members and their ongoing work.\nDevelopment is currently broken into three distinct teams:\n\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe different teams have actively moving on various fronts. The following are their team updates to various ongoing Epics.\nClient, Testing and Infrastructure §\nClient §\nCompleted\n\nCreated task for NAT traversal and gathered various info for it https://github.com/codex-storage/nim-codex/issues/753\nFinished work on scheduling erasure coding on a thread pool https://github.com/codex-storage/nim-codex/pull/716\n\nOngoing\n\nWorking on scheduling prover computation on a thread pool, draft PR in progress\nAddressing comments for large PRs\nhttps://github.com/codex-storage/nim-codex/pull/631\nhttps://github.com/codex-storage/nim-codex/pull/678\n\nTesting §\nCompleted\n\nDocumented issue for running Codex integration tests on certain macOS configurations https://github.com/codex-storage/codex-contracts-eth/issues/95\n\nInfrastructure §\nCompleted\n\nNone\n\nOngoing\n\n�   Install Fluent Bit to get Testnet Kubernetes events\n�   Adjust Vector config\n�   Deploy ethereum web wallet for Testnet\n�   Run Public RPC node on Testnet\n�   Add more Codex Storage nodes\n�   Use multi-stage builds for Rewarder #101\n�   codex-testnet-starter updates\n�️   Configure Grafana dashboards for Testnet resources #154\n�️   Add Release workflow for Codex #749\n\nNim Tooling §\nCompleted\n\nAdd recursion limit for SAT (packaging) https://github.com/nim-lang/sat/pull/3\nDisable stacktrace on SAT solver to avoid stackoverflows in debug builds https://github.com/nim-lang/sat/pull/5#event-12262613353\nWrote up draft for Nimble Caching RFC https://hackmd.io/@elcritch/rJ4VrExJR\n\nMarketplace §\nCompleted\n\nRevisit design of https://github.com/codex-storage/nim-codex/issues/467\nReview https://github.com/codex-storage/nim-codex/pull/692\nReview https://github.com/codex-storage/nim-codex/pull/678, many reviews and ongoing discussion\nReview https://github.com/codex-storage/nim-codex/pull/730\nChore to remove no longer used compilation flag: https://github.com/codex-storage/nim-codex/pull/741\nTried to understand why an integration was indeterminately failing in CI and locally, thought was very difficult to reproduce\nMerged https://github.com/codex-storage/nim-codex/pull/704, which had the integration test failure. Re-running the failed test in CI was enough to get it to merge, but indicates there is an issue with this test\nRebased and merged MarketError PR: https://github.com/codex-storage/nim-codex/pull/670\nUpdated pausing slot queue design PR: https://github.com/codex-storage/codex-research/pull/188/\nRe-reviewed feat[marketplace]: add slot queue pausing PR #752 in Codex and started review of Expiry per dataset PR #678\nAdded protection branch rule for nim-ethers in Codex\nReviewed PRs #757, #752, #760, #69, and #70 in Codex\nReviewed comments for the Availability Patch PR and Pausing Queue PR in Codex\n\nOngoing\n\nDiscussed with team plans to improve integration tests: what they should cover, parallelism, and whether or not some could be replaced with unit tests. Also discussed some open issues and PR comments.\nContinued work on implementation of slot queue pausing. Most implementation in, need to add tests: https://github.com/codex-storage/nim-codex/tree/feat/marketplace/slot-queue-improvements\nWorked on updating a macro for Optionalize to add the serialize pragma annotation on the type. Tried to get the macro to read existing serialize annotations on the type and fields first but was taking too long, so moved on\nDiscussions about release branches, proof circuit assets, and versioning\nDiscussed Optionalize() macro and serialize pragma\nDiscussed the parallelism of integration tests\nProgress on Persistent Availabilities implementation\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nNone\n\nOngoing\n\nTrying to understand what can be salvaged from my binary circuit idea (by implementing and measuring stuff)\nWorking on the Plonk notes\n"},"codex/updates/2024-04-08":{"title":"2024-04-08 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Apr 2nd - Apr 8th §\n\nThe Codex team continues to make progress with various initiatives to wrap up the demo for the Q2 public testnet release. An internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\nThe Codex team is currently attending the week long Logos all hands off-site, attending ZK Summit and having their team specific off-site the following week.\n\nLogos and Codex Off-site Links (2024/04/01 - 2024/04/15) §\nThe following are links containing artifacts from both off-sites:\n\nCodex Athens Presentation\nCodex Athens Presentation Video Recording\nCodex Workshop Presentation\nCodex Athens Off-site Artifacts\n"},"codex/updates/2024-04-15":{"title":"2024-04-15 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Apr 9th - Apr 16th §\n\nThe Codex team continues to make progress with various initiatives to wrap up the demo for the Q2 public testnet release. An internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\nThe Codex team is currently attending the week long Logos all hands off-site, attending ZK Summit and having their team specific off-site the following week.\n\nLogos and Codex Off-site Links (2024/04/01 - 2024/04/15) §\nThe following are links containing artifacts from both off-sites:\n\nCodex Athens Presentation\nCodex Athens Presentation Video Recording\nCodex Workshop Presentation\nCodex Athens Off-site Artifacts\n"},"codex/updates/2024-04-22":{"title":"2024-04-22 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Mar 16th - Mar 22nd §\n\nThe Codex team wrapped up a successful demo at the Logos off-site and now aims to prepare the demo for the Q2 public testnet release potentially coinciding with EthCC.\nAn internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe following are their team updates.\nClient, Testing and Infrastructure §\n\nmost members OOO\n\nMarketplace §\n\nmost members OOO\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nstarted looking into the Goldilocks field and Plonky2 (unfortunately, there appears to be NO documentation at all…)\nwrote a draft document about our proof research needs\n"},"codex/updates/2024-04-29":{"title":"2024-04-29 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update Mar 22nd - Mar 29th §\n\nThe Codex team wrapped up a successful demo at the Logos off-site and now aims to prepare the demo for the Q2 public testnet release potentially coinciding with EthCC.\nAn internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe following are their team updates.\nClient, Testing and Infrastructure §\n\nMembers OOO\n\nMarketplace §\nCompleted\n\nWork on duration for expiry\nnim-codex PR https://github.com/codex-storage/nim-codex/pull/793\ncontracts PR https://github.com/codex-storage/codex-contracts-eth/pull/99\n\nOngoing\n\nwhitepaper review\nTokenomics discussions\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nNone\n\nOngoing\n\nWhitepaper review (90% done)\nCoordinating Vac cooperation\nTried to look a little bit into set accumulator schemes\n"},"codex/updates/2024-05-06":{"title":"2024-05-06 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update April 30th - May 6th §\n\nThe Codex team wrapped up a successful demo at the Logos off-site and now aims to prepare the demo for the Q2 public testnet release potentially coinciding with EthCC.\nAn internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe following are their team updates.\nClient, Testing and Infrastructure §\nCompleted\n\nNone\n\nOngoing\n\nSplitting two big PRs into a series of smaller ones\n\nExpiry per dataset\nSafe block deletion (with ref count)\n\n\nReviewing various PRs in the client\n\nMarketplace §\nCompleted\n\nTokenomics meeting to discuss existing questions, as well as the new slot reservations proposal\nDiscussion about the slot reservations proposal, in which we came up with a simplified version, opting to allow for emergent behaviors before adding to complexity\nDiscussion about fill reward curve\nDiscussion about the new slot reservations proposal\nReviews :\n\nhttps://github.com/codex-storage/nim-codex/pull/793\nhttps://github.com/codex-storage/codex-contracts-eth/pull/99\n\n\n\nOngoing\n\nWriting out new proposal for slot reservations as well as capturing the original bloem method idea\nTokenomics &amp; Marketplace proposal discussions\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nDiscussion with marketplace team about slot fill reward and address window expansion curves\n\nOngoing\n\nStudying various FFT/NTT algorithms\nLooking at new research\nLooking a bit into the recent “Foreign Arithmetic” (SigmaBus) paper. Unfortunately it seems to be much less useful for us than originally thought.\n"},"codex/updates/2024-05-13":{"title":"2024-05-13 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update May 7th - May 13th §\n\nThe Codex team wrapped up a successful demo at the Logos off-site and now aims to prepare the demo for the Q2 public testnet release potentially coinciding with EthCC.\nAn internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe following are their team updates.\nClient, Testing and Infrastructure §\nCompleted\n\nOrganized new Kanban board to sort through new and existing Epics and Issues associated with ongoing work to test &amp; fix bugs in the core client towards stability - two large items of focus for the coming two months is:\n\nEthCC Workshop Client work\nFirst release of Codex for the testnets\n\n\nFixed upload/addition of blocks but did not fix it in the advertising loop yet\nFinished evaluation of LevelDB vs SQLite\n\nOngoing\n\nSplitting two big PRs into a series of smaller ones\n\nExpiry per dataset\nSafe block deletion (with ref count)\n\n\n\nMarketplace §\nCompleted\n\nNew proposal for slot reservations and capturing the original bloem method idea; developed simplified version of slot reservations opting to allow for emergent behaviors before adding to complexity\nCompleted PR Reviews and merged:\n\nFeat: expiry specified with number of seconds\nFeat: expiry specified as duration\n\nFollow up fix with adding confirmation: https://github.com/codex-storage/nim-codex/pull/802\n\n\n\n\nUpdated Marketplace sections of Codex Whitepaper\n\nOngoing\n\nTokenomics meeting to discuss existing questions as well as the new slot reservations proposal\nDiscussion with Research team about fill reward curve\nApplication Properties for Codex contract\n\nLearning about Properties and how to write them in Certora system\n\n\nNew UI team sync\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nWrote down current thinking about tracking sets of proofs (WIP)\nNotes on Tracking proofs in Codex\n\nOngoing\n\nLearning about different FFT / NNT algorithms\nContinued work on Plonk notes\nCurrent focus is mainly on recursive proofs in the elliptic curve setting\n"},"codex/updates/2024-05-20":{"title":"2024-05-20 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update May 14th - May 20th §\n\nThe Codex team wrapped up a successful demo at the Logos off-site and now aims to prepare the demo for the Q2 public testnet release potentially coinciding with EthCC.\nAn internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe following are their team updates.\nClient, Testing and Infrastructure §\nCompleted\n\nPackaged self-contained LevelDB Nim project so no dependencies on system packages lifted from existing wrapper and then wrapped it in a datastore implementation\n\nPreliminary tests shows increased performance is as expected\n\n\nResolved issue with dependency bump and broken dependency chain and now stuck with serialization issue - bug was related to resolving to wrong deserializer and work on nim-serde and nim-RPC\n\nOngoing\n\nStarted work on LevelDB migration; Discord bot, reward system and chain inspection broken\nResolving failing integration tests re: expiry of the request in storage\nWorking on issue related to inability to see amount of tokens sent in block explorer\nDeploying faucet web app for testnet tokens (ETH &amp; TST)\nWorking on Codex release workflow\nTrying to use DST’s k8s cluster and have not been able to use it yet\nMigrate dist test cluster from Digital Ocean to Hetzner and deploy different mointoring tools (e.g., Victoria Metrics) - parametrics logs replacing elastic search with similar API and CLI scrollingto be added to UI later on\n\nMarketplace §\nCompleted\n\nHelped with some work related to LevelDB integration\nAdded custom errors PR in nim-ethers that required attention\n\nOngoing\n\nWriting documentation around some of the Solidity code ahead of audit\nCoordinating audit with SC team (Vac) and looping in Security; still deciding on 2nd security audit company\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nSync w/ Client team about circom-compat\nStudying bulletproofs with the goal to try to use them in proof recursion, on the “wrong” curve - see writeup here\nUpdated thinking about proof recursion\nWrote a high-level overview explaining all the moving parts of a ZK proofs (different files and steps and their meaning)\n\nOngoing\n\nProposal for tracking proofs (more precisely, the multiset commitments in there) has a scaling problem, and started thinking about an alternative motivated by Plookup\nLooking more into Winograd-type FFT\n"},"codex/updates/2024-05-27":{"title":"2024-05-27 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update May 21th - May 27th §\n\nThe Codex team wrapped up a successful demo at the Logos off-site and now aims to prepare the demo for the Q2 public testnet release potentially coinciding with EthCC.\nAn internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe following are their team updates.\nClient, Testing and Infrastructure §\nCompleted\n\nN/A\n\nOngoing\n\nContinued work on LevelDB migration; failing unit test uncovered bug on race condition in one of the state machines in the Marketplace module and switch to LevelDB reveleaed it and changing timing of DB reproduced it; reproduced it in SQLite by putting a sleep statement and nothing wrong in LevelDB\n\nMarketplace picked this bug up\n\n\nDocker build problems; Rust build failed and Circom devices no longer building - rolled back Codex to previous Docker image and it doesn’t build anymore so not something changed on our end\nWorking on debugging Rust FFI threading\n\nMarketplace §\nCompleted\n\nContract deployment and security writeup\nMore adjustments to the slot queue PR, and merge\nRe-review of ethers custom errors PR\nMerge fix for forcing scope of deserialization\nRelease new version of nim-serde to unblock chronos v4\nBump serde version and merge\nMerged Remove overloaded UInt256.fromJson\nCleanup integration tests review\nAddressed Slot Reservations PR comments with some rewrites\n\nOngoing\n\n“Application Properties” writeup for Certora issues tracked here and  ongoing discussion of issues here\nReviewing RFC spec for Marketplace\nBuilding frontend for the EthCC Demo that shows past and real time contract events, and downloads CIDs and displays as images\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nInitial Dynamic data proposal WIP\n\nOngoing\n\nUnderstanding aggregator node hybrid-system dynamics\n"},"codex/updates/2024-06-03":{"title":"2024-06-03 Codex Weekly","links":["(https:/discord.com/channels/895609329053474826/1230457525854539819/1245555994465931294)"],"tags":["codex-updates"],"content":"Codex Update May 28th - June 3rd §\n\nThe Codex team wrapped up a successful demo at the Logos off-site and now aims to prepare the demo for the Q2 public testnet release potentially coinciding with EthCC.\nAn internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe following are their team updates.\nClient, Testing and Infrastructure §\nCompleted\n\nAdded custom Docker file for release workflow\n\nOngoing\n\nEthCC planning meeting with Marketplace\nContinued bug hunting and fixing towards stability of client\nPlanning around EthCC Codex demo logistics; Dockerized Codex in VMs, cloud VPN, and physical MikroTik router setup\nNaming conventions of testnet deployments\nNAT Traversal issues; AutoNAT issues not working as expected - formal writeup to come describing issues and potential solutions\nChallenges with DHT and peer discovery\nFast-track reviews of ‘rework async iter’, ‘safe block deletion’ and ‘expiry per dataset’ PRs\nExplore scalability issues with LevelDB and large node tests\n\nMarketplace §\nCompleted\n\nMarketplace discussion meeting (release branches/versions, conditional deployments, pointer calculation, contract gas estimates, upgradability legal implications)\n\nAdd freezing functionality for emergency use cases\nCall with Legal for POV of Contract’s security and upgradability\nCall with SC team (Vac) about Legal POV for Contract’s security and upgradability\n\n\nMarketplace team meeting with Legal about contract freezing/upgradability\nReview of Bug/sales race PR\nSales module concurrency issue - reworking fix after feedback\n\nOngoing\n\nMore progress on EthCC Demo frontend\nGas reporting plugin attempt to run against Codex integration tests\nInvestigate deploying unchanged contracts using hardhat-deploy and newer hardhat Ignition (created issue for upgrade)\nFrontend dev application reviews\nWIP in the Certora’s Application Properties work\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nL2 Deployment\n\nOngoing\n\nProxy re-encryption call with ACZ (Vac)\nInterviewing ZK engineer candidates\nEncryption options WIP\nSet commitment proposal with details WIP\n"},"codex/updates/2024-06-10":{"title":"2024-06-10 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update June 4th - June 10th §\n\nThe Codex team wrapped up a successful demo at the Logos off-site and now aims to prepare the demo for the Q2 public testnet release potentially coinciding with EthCC.\nAn internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe following are their team updates.\nClient, Testing and Infrastructure §\nCompleted\n\nSetup similar VPN from home to cloud VPN for router OS similar to MikroTik router and APs; purchased hardware to test - ordered physical SIM adapter for router\n\nOngoing\n\nWorkshop preparation\nOngoing scalability work; intially had to fix the Docker build and got updated build with LevelDB, odd stuff happening in cluster but 4.5GiB exchange for upload/download succeeded\nNAT Planning and roll out\n\nMarketplace §\nCompleted\n\nTBD\n\nOngoing\n\nWorkshop preparation\nCertora setup &amp; integration\n\nWIP in the Certora’s Application Properties work\n\n\nPersistent Availabilities\nSlot Reservations\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nOngoing work on details of the dynamic data proposal (the proof parts)\nHelped Nomos with a small FFT issue\n\nOngoing\n\nLooking at new research\nWorking on Winograd-type NTT\nWorking on proof recursion\nLooking into more FFT/NTT algorithms (ECFFT, prime order FFT, etc; we need non-power-of-two sizes for foreign field arithmetic)\nReliability and Proof Frequency (WIP)\n"},"codex/updates/2024-06-17":{"title":"2024-06-17 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update June 11th - June 17th §\n\nThe Codex team wrapped up a successful demo at the Logos off-site and now aims to prepare the demo for the Q2 public testnet release potentially coinciding with EthCC.\nAn internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe following are their team updates.\nClient, Testing and Infrastructure §\nCompleted\n\nL2 assumptions, planning and deployment options\nNAT Traversal in Codex\n\nOngoing\n\nWorkshop preparations\nDeveloping single binary pipeline for releases\nSome splitting of PRs further into datastore and rework\nNeed this Safe block deletion (with ref count) PR approved\n\nMarketplace §\nCompleted\n\nMerged fix: createReservation lock\nL2 overview and Marketplace support/compatibility check\n\nOngoing\n\nWorkshop preparations\nLooking into more research about contract upgradability and industry practices\nReviews of Marketplace spec\nWIP in the Certora’s Application Properties work\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nFiguring out usable NTT options on the Grumpkin curve; WIP notes\n\nOngoing\n\nPrototyping with intent of a full implementation soon\n"},"codex/updates/2024-06-24":{"title":"2024-06-24 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update June 18th - June 24th §\n\nThe Codex team wrapped up a successful demo at the Logos off-site and now aims to prepare the demo for the Q2 public testnet release potentially coinciding with EthCC.\nAn internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe following are their team updates.\nClient, Testing and Infrastructure §\nCompleted\n\nMerged safe block deletion PR\n\nOngoing\n\nWorkshop preparations\n\nSlides presentation and complete demo run-through\n\n\nManifest initialization bug\nCrash fixing; second release failing because of CPU load - possible prover blocking I/O and need better threading (to use async profiler to resolve this)\nWork on scheduler\nWorking on bug fix for EC issues\n\nProblem with verifiable manifest (was not enabled for Athens demo) &amp; tree roots issue\nCrashes resulting in SIGSEGV error\n\n\n\nMarketplace §\nCompleted\n\nHired full-stack dev to work on Codex App and some Client/Marketplace tasks\n\nOngoing\n\nWorkshop preparations\n\nFrontend session cookies issue - CORS requests problems; sticky sessions are problem for replicated services because reqeusts can be sent to different sessions, problem is how to persist RPC session w/ 3 RPC nodes and if you want to send all requests to same RPC node is problematic\n\n\nWIP in the Certora’s Application Properties work\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nPlausible deniability writeup from ACZ (Vac)\n\nOngoing\n\nDynamic data proposal WIP\n"},"codex/updates/2024-07-01":{"title":"2024-07-01 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update June 25th - July 1st §\n\nThe Codex team wrapped up a successful demo at the Logos off-site and now aims to prepare the demo for the Q2 public testnet release potentially coinciding with EthCC.\nAn internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe following are their team updates.\nClient, Testing and Infrastructure §\nCompleted\n\nRelease pipeline for Linux setup (x64 &amp; ARM for Ubuntu and MacOS)\n\nOngoing\n\nWorkshop preparations\n\nSlides presentation and complete demo run-through\n\n\nGeneral bug hunting and fixing towards baseline stability and BitTorrent-like performance\n\nMarketplace §\nCompleted\n\nWorkshop preparations\n\nOngoing\n\nWIP in the Certora’s Application Properties work\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nGathered all ZK related documents here\nWriteup on OTP-like encryption to prevent outsourcing attacks\n\nOngoing\n\nOngoing research into the details of folding\nInterviewing more ZK engineer candidates\n\nCreating take-home programming exercise\n\n\nThinking about how to describe Plonkish circuits\nLooking at new ZK research\n"},"codex/updates/2024-07-08":{"title":"2024-07-08 Codex Weekly","links":[],"tags":["codex-updates"],"content":"Codex Update July 2nd - July 8th §\n\nThe Codex team wrapped up a successful demo at the Logos off-site and now aims to prepare the demo for the Q2 public testnet release potentially coinciding with EthCC.\nAn internal devnet has been running for the past few weeks and has been used to test the latest version of Codex and can be accessed using the Codex Testnet Starter documentation.\n\nDevelopment is currently broken into three distinct teams:\n\nClient, Testing, and Infrastructure\nMarketplace\nResearch\n\nThe following are their team updates.\nClient, Testing and Infrastructure §\nCompleted\n\nWorkshop preparations\n\nSlides presentation and complete demo run-through\n\n\nRelease pipeline for Windows (x64 &amp; ARM) setup\n\nOngoing\n\nGeneral bug hunting and fixing towards baseline stability and BitTorrent-like performance\nWriteup of Merkle Trees and Proof Tree\nEC in Codex\n\nMarketplace §\nCompleted\n\nWorkshop preparations\n\nOngoing\n\nWIP in the Certora’s Application Properties work\n\nResearch §\n2024 R&amp;D Goals\n1. Proving system and aggregation improvements (folding or lookups)\n2. Aggregator/validator design\n3. DHT improvements\n4. Tokenomics and incentive design\n5. Bandwidth incentives\n6. Dynamic data (appendable data)\n7. Encryption\n\nCompleted\n\nN/A\n\nOngoing\n\nN/A\n"},"index":{"title":"","links":["terms-of-use","what-is-a-milestone","tags/monthly-report","waku/","codex/overview","nomos/"],"tags":[],"content":"This site attempts to inform the previous, current, and future work required to fulfill the requirements of the projects under the Logos Collective, a complete tech stack that provides infrastructure for the self-sovereign network state. To learn more about the motivation, please visit the Logos Collective Site.\nThis site is an ongoing work in progress. The links within are an attempt to capture a lot of moving targets. This means that the information here may or may not be the bleeding edge of what is true with respect to the development within the Logos Collective projects. Your use of this Website is subject to the following terms of use which we ask you to read carefully prior to your use of the Website.\nEvery year (starting this year), each project defines its plans in a number a milestones, which are then reflected and tracked here-in. You an read more about the contents of a given milestone and the various justifications for that content in What is a Milestone.\nNavigation §\n\nMonthly Project Reports\n\nProjects §\n\nWaku\nCodex\nNomos\n"},"innovation_lab/index":{"title":"Innovation Lab Roadmap Overview","links":["innovation_lab/milestones-overview","tags/ilab-updates"],"tags":["overview"],"content":"Welcome to the Innovation lab Roadmap Overview\n\nMilestones\nweekly updates\n"},"innovation_lab/milestones-overview":{"title":"Innovation Lab Milestones Overview","links":[],"tags":["milestones"],"content":"iLab Milestones can be found on the Notion Page"},"innovation_lab/monthly-reports/2023-aug":{"title":"2023-aug","links":[],"tags":[],"content":"Innovation Lab Monthly Report - August 2023 §\nWaku Objects Prototype §\nThe Innovation Lab team is currently working on the Waku Objects prototype, a modular system for transactional chat objects. Despite some slower progress due to vacations and team events in early August, significant advancements were made throughout the month.\nKey Achievements §\n\n\nColor System Release:\n\nReleased the first version of a color system as an npm package called Luminance.\nBased on grayscale design and uses luminance for customization.\nAvailable for testing in the Playground app.\n\n\n\nGroup Chat Support:\n\nCompleted and merged the implementation for private group chat support.\nDeveloped a custom “toy” group chat protocol implementation due to lack of readily available solutions.\n\n\n\nBlockchain Integration:\n\nIntegrated support for Gnosis chain transactions.\nAdded support for xDai and Gno tokens, with easy expansion for other ERC-20 tokens.\n\n\n\nNew Domain Launch:\n\nRegistered and deployed the latest version to a new domain: wakuplay.im\n\n\n\nMilestones §\n\n\nCompleted: Group Chat Support\n\nSuccessfully implemented and merged group chat functionality.\nIdentified and addressed various issues that arose during the transition from 1-on-1 chats to group chats.\n\n\n\nIn Progress: Splitter Waku Object\n\nAims to support group chats and smart contracts.\nWill be the first Waku Object meaningful in a group chat context.\nDemonstrates the use of smart contracts and multiparty transactions.\nDesign completed and implementation started.\n\n\n\nIn Progress: Basic Waku Objects Website\n\nStarted work on the website structure.\nContent development is progressing well.\nImplementation of the website has begun.\n\n\n\nChallenges and Learnings §\n\nThe team faced challenges in finding existing implementations for group chat protocols, leading to the development of a custom solution.\nThe transition from 1-on-1 chats to group chats revealed various issues with both Waku integration and from a product perspective.\n\nResources and Links §\n\nDeployed version: https://www.wakuplay.im/\nMain development repo: https://github.com/logos-innovation-lab/waku-objects-playground\nGrayscale design: https://grayscale.design/\nLuminance package on npm: https://www.npmjs.com/package/@waku-objects/luminance\n\nCommunity Engagement §\nThe team is actively engaging with the community and welcomes feedback and contributions. They can be reached through:\n\nDiscord channel: https://discord.com/channels/973324189794697286/1118949151225413872\nDiscord invite link: https://discord.gg/eaYVgSUG\n\nLooking Ahead §\nThe team is focused on completing the Splitter Waku Object and the basic Waku Objects website. These developments will showcase the capabilities of Waku Objects in group chat contexts and provide a central hub for information about the project."},"innovation_lab/updates/2023-07-12":{"title":"2023-07-12 Innovation Lab Weekly","links":[],"tags":["ilab-updates"],"content":"Logos Lab 12th of July\nCurrently working on the Waku Objects prototype, which is a modular system for transactional chat objects.\nMilestone: deliver the first transactional Waku Object called Payggy (attached some design screenshots).\nIt is now possible to make transactions on the blockchain and the objects send notifications over the messaging layer (e.g. Waku) to the other participants. What is left is the proper transaction status management and some polishing.\nThere is also work being done on supporting external objects, this enables creating the objects with any web technology. This work will guide the separation of the interfaces between the app and the objects and lead us to release it as an SDK.\nNext milestone: group chat support\nThe design is already done for the group chat functionality. There is ongoing design work for a new Waku Object that would showcase what can be done in a group chat context.\nDeployed version of the main branch:\nhttps://waku-objects-playground.vercel.app/\nLink to Payggy design files:\nhttps://scene.zeplin.io/project/64ae9e965652632169060c7d\nMain development repo:\nhttps://github.com/logos-innovation-lab/waku-objects-playground\nContact:\nYou can find us at https://discord.com/channels/973324189794697286/1118949151225413872 or join our discord at https://discord.gg/UtVHf2EU\n\nConversation §\n\n\npetty — 07/15/2023 5:49 AM\nthe waku-objects repo is empty. Where is the code storing that part vs the playground that is using them?\n\n\npetty\nthe waku-objects repo is empty. Where is the code storing that part vs the playground that is using them?\n\n\nattila🍀 — 07/15/2023 6:18 AM\nat the moment most of the code is in the waku-objects-playground repo later we may split it to several repos here is the link: https://github.com/logos-innovation-lab/waku-objects-playground\n\n"},"innovation_lab/updates/2023-08-02":{"title":"2023-08-02 Innovation Lab weekly","links":[],"tags":["ilab-updates"],"content":"Logos Lab 2nd of August\nCurrently working on the Waku Objects prototype, which is a modular system for transactional chat objects.\nThe last few weeks were a bit slower than usual because there were vacations, one team member got married, there was EthCC and a team offsite.\nStill, a lot of progress were made and the team released the first version of a color system in the form of an npm package, which lets the users to choose any color they like to customize their app. It is based on grayscale design and uses luminance, hence the name of the library. Try it in the Playground app or check the links below.\nMilestone: group chat support\nThere is a draft PR for group chat support for private groups and it is expected to be finished this week. At the end we decided to roll our own toy group chat protocol implementation because we did not find anything ready to use. It would have been great if we could have just used an existing implementation.\nNext milestone: Splitter Waku Object supporting group chats and smart contracts\nThis will be the first Waku Object that is meaningful in a group chat context. Also this will demonstrate how to use smart contracts and multiparty transactions.\nDeployed version of the main branch:\nhttps://waku-objects-playground.vercel.app/\nMain development repo:\nhttps://github.com/logos-innovation-lab/waku-objects-playground\nGrayscale design:\nhttps://grayscale.design/\nLuminance package on npm:\nhttps://www.npmjs.com/package/@waku-objects/luminance\nContact:\nYou can find us at https://discord.com/channels/973324189794697286/1118949151225413872 or join our discord at https://discord.gg/ZMU4yyWG\n\nConversation §\n\n\nfryorcraken — Yesterday at 10:58 PM\n\nThere is a draft PR for group chat support for private groups and it is expected to be finished this week. At the end we decided to roll our own toy group chat protocol implementation because we did not find anything ready to use. It would have been great if we could have just used an existing implementation.\n\nWhile status-js does implement chat features, I do not know how nice the API is. Waku is actively hiring a chat sdk lead and golang eng. We will probably also hire a JS engineer (not yet confirmed) to provide nice libraries to enable such use case (1:1 chat, group chat, community chat).\n\n\nAugust 3, 2023\n\n\nfryorcraken\n\n &gt; There is a draft PR for group chat support for private groups and it is expected to be finished this week. At the end we decided to roll our own toy group chat protocol implementation because we did not find anything ready to use. It would have been great if we could have just used an existing implementation. While status-js does implement chat features, I do not know how nice the API is. Waku is actively hiring a chat sdk lead and golang eng. We will probably also hire a JS engineer (not yet confirmed) to provide nice libraries to enable such use case (1:1 chat, group chat, community chat).\n\n\n\nattila🍀 — Today at 4:21 AM\nThis is great news and I think it will help with adoption. I did not find a JS API for status (maybe I was looking at the wrong places), the closest was the status-js-api project but that still uses whisper and the repo recommends to use js-waku instead  https://github.com/status-im/status-js-api Also I also found the 56/STATUS-COMMUNITIES spec: https://rfc.vac.dev/spec/56/ It seems to be quite a complete solution for community management with all the bells and whistles. However our use case is a private group chat for your existing contacts, so it seems to be a bit overkill for that.\n\n\nfryorcraken — Today at 5:32 AM\nThe repo is status-im/status-web\n\n\n[5:33 AM]\nSpec is https://rfc.vac.dev/spec/55/\n\n\nfryorcraken\nThe repo is status-im/status-web\n\n\nattila🍀 — Today at 6:05 AM\nAs constructive feedback I can tell you that it is not trivial to find it and use it in other projects It is presented as a React component without documentation and by looking at the code it seems to provide you the whole chat UI of the desktop app, which is not necessarily what you need if you want to embed it in your app It seems to be using this package: https://www.npmjs.com/package/@status-im/js Which also does not have documentation I assume that package is built from this: https://github.com/status-im/status-web/tree/main/packages/status-js This looks promising, but again there is no documentation. Of course you can use the code to figure out things, but at least I would be interested in what are the requirements and high level architecture (does it require an ethereum RPC endpoint, where does it store data, etc.) so that I can evaluate if this is the right approach for me. So maybe a lesson here is to put effort in the documentation and the presentation as well and if you have the budget then have someone on the team whose main responsibility is that (like a devrel or dev evangelist role)\n\n"},"innovation_lab/updates/2023-08-11":{"title":"2023-08-17 <TEAM> weekly","links":[],"tags":["team-updates"],"content":"Logos Lab 11th of August §\nCurrently working on the Waku Objects prototype, which is a modular system for transactional chat objects.\nWe merged the group chat but it surfaced plenty of issues that were not a problem with 1on1 chats, both with our Waku integration and from product perspective as well. Spent the bigger part of the week with fixing these. We also registered a new domain, wakuplay.im where the latest version is deployed. It uses the Gnosis chain for transactions and currently the xDai and Gno tokens are supported, but it is easy to add other ERC-20 tokens now.\nNext milestone: Splitter Waku Object supporting group chats and smart contracts\nThis will be the first Waku Object that is meaningful in a group chat context. Also this will demonstrate how to use smart contracts and multiparty transactions. The design is ready and the implementaton has started.\nNext milestone: Basic Waku Objects website\nWork started toward having a structure for a website and the content is shaping up nicely. The implementation has been started on it as well.\nDeployed version of the main branch:\nhttps://www.wakuplay.im/\nMain development repo:\nhttps://github.com/logos-innovation-lab/waku-objects-playground\nContact:\nYou can find us at https://discord.com/channels/973324189794697286/1118949151225413872 or join our discord at https://discord.gg/eaYVgSUG"},"insight/business-analysis/index":{"title":"Insight Business Analysis Overview","links":[],"tags":[],"content":"insight:business-analysis: §\n\ndatalake-repo-ingestion §\nreal-opt-keycard §"},"insight/dao/index":{"title":"Insight DAO Overview","links":[],"tags":[],"content":"insight:dao: §\n\nspiff-process-growth §\nspiff-bounty-experiment §"},"insight/index":{"title":"Insight Team Overview","links":["insight/monthly-reports/2023-oct","insight/dao/","insight/project-reporting/","insight/business-analysis/"],"tags":[],"content":"Description §\nThe insight team acts as a glue within the Logos Collective. They serve development projects by helping to track development activity and aiding in resource allocation. They serve the broader service units within the organization by helping them understand who’s doing what, how much effort is going into each chunk of work, how much it costs, and future projections of milestone delivery.\nThis page tracks the various work that they engage in throughout the org. As this is a service unit and not a project, it does not strictly work off a milestone based approach and has consistent service work to the various groups within the Logos Collective.\nMonthly Reports §\n\n2023 October\n\nCurrent work §\ndao: details §\nproject-reporting: details §\nbusiness-analysis: details §"},"insight/monthly-reports/2023-oct":{"title":"2023 October Insights Monthly Report","links":[],"tags":[],"content":"Executive Summary §\nKey Updates §\nPersonnel §\nA senior and junior software engineer have been brought on to support the ongoing development of SpiffWorkflow.\n\nMichael is a senior python developer with years of experience. He also contributed to SpiffWorkflow in the past by giving it an external security review before it was launched. He will be leading the internal development and mentoring the junior dev.\nKayvon joined as a junior dev to contribute to the ongoing development and web3-ification of SpifWorkflow.\n\nMonthly Highlights §\nSpiffWorkflow §\nThe project has received two new in-house developers so that ongoing maintenance and development can continue. The entire Kanban board is currently held in Notion but may move to somewhere more public in the near future.\nA new release happened that brought about a bunch of bug fixes and improvements, namely (copy/paste from Sasha’s Discord post):\n\nUI/UX changes across the site have been made to make it cleaner and easier to navigate\nNo more copying and sending process instance ID and sending it to someone. There is now a shareable link on each process instance that produces a short link to share.\nA new way to quickly understand where the process is upto. Rather than just seeing in-progress, you will now see things like “Pending Approval - Insights” or “Request Approved” etc. You will see this on the home page and all tables across the platform, under the column name: Last milestone\nHow many times have you wanted to look at the data previously entered into forms? You can now do this with the addition of a new section called My completed tasks, which can be found on the Process Instance Detailed page. This is one of the most requested features!\nWe now support the ability of parallel processing for tasks. Things like calling 3 different APIs can be done in parallel now, significantly speeding up all processes.\nSpiff now allows external systems to call it using APIs. I.e. on some trigger, external systems calls Spiff to start a process or complete a task for an existing process. This will be extremely powerful when integrating with of our systems.\nREADME files about a process are now embedded in Spiff. When you head to the process model page, you will see the About tab, which has a readme.md file with everything you need to know about a process.\nMarkdown support added across the platform\nAdded a tooltip component to the checkboxes in forms to enhance the user experience. Now, when you submit a travel request and are unsure about the Per Diem, simply hover over the checkbox and the help text will appear.\nAuto-approvals for processes. In order to reduce approval time, when someone holds both the role of Budget Owner and is part of the SME group, double-approval is not required. For example, if an Infra Lead provides approval as a Budget Owner for software and licenses, the Infra team review step will be automatically completed (approved). You can find the list of Budget Owners here.\nAdded Event categories to the Request Goods/Services process. The list of purchase categories can be found here\nFixed bugs and errors\nImplemented admin functionality to improve the support team’s ability to assist users when needed\nWe can now invite any external user to complete one/multiple steps in a process, without that user being created within Keycloak/Spiff. This allows us to do things like ask a vendor being onboarded to complete a form or perform a step in process, by simply sending them an email with all instructions. The access is time based password protected.\nIf you come across a missing City in the Travel request drop-down, simply inform the support team. They can add it for you, allowing you to proceed with your request.\n\nKudos to the team for such an awesome amount of work.\nA technical roadmap has begun to be developed which outlines the process of “DAOification” of the organization. The initial focus is on understanding the time-cost of the project and required resources.\nContract Extension Negotiations with Sartography §\n\nSummarizations provided by Eric in legal:\nJust to summarise where we’re at with Sartography as of the latest agreement, Sartography has indicated that they will develop additional SpiffWorkflow components called “SpiffWorkflow Extensions”. The negotiations with Sartography revolve around the issue ownership and licensing of the IP for these SpiffWorkflow Extensions as developed for Status. The points are as follows:\n\n(i) Commercial license instead of an open source license: Originally all Spiffworkflow software would either be open source or be delivered to Status for its ownership. Sartography are insisting on deviating from this approach for the Extensions and intend to apply a commercial license to it. This is an unacceptable position. If they develop IP with Status’ money, then it must align with the original approach.\n(ii) Waiver of fee for commercial license: Sartography have indicated that they are willing to “waive” the fee for any commercial license for the Extensions (referring this as a “gift” to Status). The terms of the commercial license will still need to be negotiated and are unknown to us right now. The waiver of a fee for a commercial license which we don’t have any view on may not be worth much if it turns out to be very restrictive.\n\n\n\nAn image of what Sartography aims to do, important to note this is not funded by Status:\n\nFor the avoidance of doubt, all “original” Spiffworkflow Software still aligns with our original agreed approach i.e. Sartography is obliged to keep it open source and any thing it delivers to Status will belong to Status who is obliged to make it open source.\nPath Forward - Still needs to be finalized by legal; however, Sartography is building an ability to commercialize features that they are developing outside of development with Status. They will extend a commercial license to us and waive all fees associated if Status uses any of those features. All feature they’ve expressed they are building are not features Status would leverage. For example, datastores for personal data and data stores for financial data.\nReal Options Analysis §\nFrederico lead the way on developing a framework (and explainer) for performing Real Options Analysis on Keycard. Keycard was chosen based on its smaller project size and traditional evaluation methodology as a project (the easiest one to start with) with the goal in mind of generalizing the framework for all projects within Logos and Status. The current analysis and framework can be found in Notion for now. Once finalized and reviewed, it may be released for public consumption.\nThis framework is expected to allow us to identify performance and evaluation trends for projects within their respective ecosystems, thus adding valuable insight to the decisions we as an org can make to steer them in the direction of success. More info on this can be seen in Jarrad’s previous townhall (Org internal link - sorry - picture below for public) where he discussed it.\n\nRevamping Accounting with Finance §\nWork continues with the Finance team to revamp the budgeting process for projects and services. The dashboard (mentioned below) being developed has helped track and monitor how money is being spent and allocated across the org.\nProject Dashboards §\nA lot of work has been done to create various dashboards for cohorts across the org. The project dashboards are mainly created from the development activity we can glean from Github thus is heavily dependent upon the team’s reporting and Github tagging process at the moment.\nCurrently, the following dashboards are being worked on and iterated with their respective teams to ensure they’re providing appropriate and correct information (ask Lalo if access if you feel you should have it and don’t):\n\nProject Reporting (Waku)\nProject Reporting (Status)\nBudget Reporting\nMilestone Table\nProcess Performance for Spiff\nWaiting for Twitter API v2 access to be purchased to complete the social engagement dashboard.\n\nThe Waku team gave a presentation on their adapted project reporting process to the PMs across the org and work has been started to adapt projects to something similar to allow for more automation and dashboard creation.\nThe Waku team has reported usefulness in their dashboard already despite it being incomplete (no weighting of work done yet, only tagging issues to epics and epics to milestones).\nFuture Plans §\nNext month, the insights team plans to focus on increasing the coverage of project roadmaps within this website as well as the backend development activity automation coverage for projects.\nThe more we cover projects development activity, the better dashboards we can make to serve them.\nNEED MORE HERE"},"insight/project-reporting/index":{"title":"Insight Project Reporting Overview","links":[],"tags":[],"content":"insight:project-reporting: §\n\nmilestone-publishing: §\n\ncodex\nnomos\nwaku\nvac\n\nmonthly-reports §\nllm-dev-activity §"},"monthly-reports/2023-aug":{"title":"2023-aug","links":[],"tags":[],"content":"Logos Collective Monthly Report - August 2023 §\nExecutive Summary §\nIn August 2023, the Logos Collective made significant progress across all its projects: Acid, Codex, Innovation Lab, Nomos, Vac, and Waku. Key achievements include advancements in network privacy, data availability, proof systems, and scalability solutions. Teams focused on improving existing protocols, developing new features, and conducting extensive research to support future innovations.\nProject Highlights §\nAcid §\n\nDeveloped Status app relaunch comms campaign plan\nProgressed on Logos Podcast Experience (LPE) launch\nAdvanced work on brand guidelines and presentation templates\nPlanned global event strategy, including Network State event\n\nCodex §\n\nImplemented Merkle tree for block data\nAdvanced block discovery and retrieval simulations\nImproved distributed client testing and stability\nProgressed on L2 integration and marketplace sales features\n\nInnovation Lab §\n\nContinued development of Waku Objects prototype\nImplemented group chat support\nIntegrated blockchain support (Gnosis chain, xDai, and Gno tokens)\nLaunched new domain: wakuplay.im\n\nNomos §\n\nAdvanced network privacy and mixnet implementation\nContinued research on Private Proof of Stake (PPoS)\nProgressed on Data Availability Sampling (DAS) with RS and KZG implementations\nImproved simulation capabilities for large-scale testing\n\nVac §\n\nEnhanced P2P networking capabilities\nConducted extensive research on various proof systems for zkVM\nAdvanced RLN-relay enhancements for Waku\nContinued development of Tor-push method for validator privacy\n\nWaku §\n\nCompleted Autosharding v1 implementation\nProgressed on PostgreSQL integration for improved performance\nEnabled RLN by default in go-waku\nAdvanced light protocols (push and filter) for Status integration\n\nCross-Project Achievements §\n\n\nScalability: Multiple projects focused on improving scalability, with Waku targeting 10K users and laying groundwork for 1 million users.\n\n\nPrivacy: Advancements in network privacy across Nomos (mixnet) and Vac (validator privacy) projects.\n\n\nData Availability: Progress in both Codex and Nomos on data availability solutions.\n\n\nProof Systems: Extensive research and benchmarking of various proof systems in Vac’s zkVM initiative.\n\n\nEcosystem Growth: Increased community engagement through events, social media, and documentation improvements.\n\n\nChallenges and Next Steps §\n\nContinue refining and implementing scalability solutions across projects.\nFurther development and integration of privacy-enhancing technologies.\nAdvance research and implementation of novel consensus mechanisms and proof systems.\nExpand test coverage and improve quality assurance processes.\nEnhance cross-project collaboration and knowledge sharing.\nContinue ecosystem growth through strategic partnerships and community engagement.\n\nConclusion §\nAugust 2023 saw substantial progress across all Logos Collective projects. The teams demonstrated a strong focus on scalability, privacy, and ecosystem growth while continuing to innovate in their respective domains. The collaborative efforts and cross-project synergies position the Logos Collective well for future developments and increased adoption of its technologies."},"nomos/base-layer-spec/data-availability/index":{"title":"Nomos Data Availability Details","links":[],"tags":[],"content":"nomos:data-availability: §\n\nDescription §\nNomos Data Availability design:\n\nOur Base Layer doesn’t have execution. Only the (global) Coordination Layer has a minimal set of operations.\nOur rollups are quasi-sovereign, meaning that they do not prove their state to the Base Layer, but they have to prove asset deposit/withdrawals, as well as implement the mechanism to pay for using the Base Layer DA+consensus. Note that full sovereignty means no bridging and implementing a client of the DA for the payments.\nWe also have a form of PBS, but enshrined in the L2s. The Base Layer only performs consensus on data that has been dispersed by the Builder. The Proposer is a node in the Base Layer, and the Builder is a node of the Execution Zone.\n\nResearch §\n\nData Availability Specification: https://www.notion.so/Data-Availability-Specification-wip-c3961b681eba4ccdab2be9181e4207b4\n\nEngineering §\n%%{ \n  init: { \n    &#039;theme&#039;: &#039;base&#039;, \n    &#039;themeVariables&#039;: { \n      &#039;primaryColor&#039;: &#039;#BB2528&#039;, \n      &#039;primaryTextColor&#039;: &#039;#fff&#039;, \n      &#039;primaryBorderColor&#039;: &#039;#7C0000&#039;, \n      &#039;lineColor&#039;: &#039;#F8B229&#039;, \n      &#039;secondaryColor&#039;: &#039;#006100&#039;, \n      &#039;tertiaryColor&#039;: &#039;#fff&#039; \n    } \n  } \n}%%\ngantt\n  tickInterval 1month\n  dateFormat YYYY-MM-DD \n  section Status\n    - Initial data availability implementation: In progress, 2023-09-01, 2023-11-30\n"},"nomos/base-layer-spec/index":{"title":"Nomos Milestone: Full Base Layer Specification","links":["nomos/base-layer-spec/network-privacy/","nomos/base-layer-spec/priv-pos/","content/nomos/base-layer-spec/data-availability/","vac/dr/consensus/nomos/carnot-2-3rds-vote-aggregation","vac/tke/g/nomos/economic-analysis"],"tags":[],"content":"nomos:base-layer-spec: §\n\nDescription §\nThe initial milestone of the Nomos project is a full specification of the Base Layer. This entails detailed explanations of the working parts of the architecture and how they lay the groundwork for future layers to be built on top. The working parts are:\n\nA private P2P network\nData availability\nA private Proof-of-State model leveraging a scalable, lightweight consensus algorithm\n\nThis work can be tracked via the following epics.\nKey Epics §\nnetwork-privacy: details §\n\ndue:\nprogress:\nshort description: Creation of a privacy preserving network underlay\n\nprivate-pos: details §\n\nnext deliverable: Sept 29, 2023\nprogress: 99%\nshort description: Creation of a Proof-of-Stake model that preserves the privacy of the stakers within the network\n\ndata-availability: details §\n\ndue:\nprogress:\nshort description: Definition of how Nomos makes data available to network participants, and its reference implementation for the Base Layer.\n\nDependent Upon: §\nvac:dr:carnot-aggregation-spec §\n\ncarnot-2-3rds-vote-aggregation\n\nvac:tke:stake-rewards §\n\neconomic-analysis\n"},"nomos/base-layer-spec/network-privacy/index":{"title":"Nomos Network Privacy Details","links":[],"tags":[],"content":"nomos:network-privacy: §\n\nCurrent Focus §\nMixnet 1.0 - a technology/system that helps keep information sent over the internet private and secure. It does so by mixing up data from different sources before sending it to its destination. In Nomos chain:\n\nMixnet nodes opt-in by publishing their IP and providing stake.\nThe mixnet topology of layers is public and defined on-chain (by some deterministic algorithm using the random-beacon for example).\nAfter certain number of epochs (to be determined), a new set of nodes is chosen and a new topology of Mixnet layers is defined. Nodes need to renew their stake and their keys (for security).\n\nFor more information, check https://www.notion.so/Private-Routing-Mixnet-Network-Privacy-Component-1-613f53cf11a245098c50af6b191d31d2\nResearch §\nCurrent Tasks §\n%%{ \n  init: { \n    &#039;theme&#039;: &#039;base&#039;, \n    &#039;themeVariables&#039;: { \n      &#039;primaryColor&#039;: &#039;#BB2528&#039;, \n      &#039;primaryTextColor&#039;: &#039;#fff&#039;, \n      &#039;primaryBorderColor&#039;: &#039;#7C0000&#039;, \n      &#039;lineColor&#039;: &#039;#F8B229&#039;, \n      &#039;secondaryColor&#039;: &#039;#006100&#039;, \n      &#039;tertiaryColor&#039;: &#039;#fff&#039; \n    } \n  } \n}%%\ngantt\n  tickInterval 1month\n  dateFormat YYYY-MM-DD \n  section Status\n    Viability analysis of the Embedded Mixnet: In progress, 2023-09-18, 2023-10-06\n\nEngineering §\nCurrent Tasks §\n%%{ \n  init: { \n    &#039;theme&#039;: &#039;base&#039;, \n    &#039;themeVariables&#039;: { \n      &#039;primaryColor&#039;: &#039;#BB2528&#039;, \n      &#039;primaryTextColor&#039;: &#039;#fff&#039;, \n      &#039;primaryBorderColor&#039;: &#039;#7C0000&#039;, \n      &#039;lineColor&#039;: &#039;#F8B229&#039;, \n      &#039;secondaryColor&#039;: &#039;#006100&#039;, \n      &#039;tertiaryColor&#039;: &#039;#fff&#039; \n    } \n  } \n}%%\ngantt\n  tickInterval 7day\n  dateFormat YYYY-MM-DD \n  section Status\n    Mixnet 1.0 Stabilization: In progress, 2023-09-18, 2023-09-30\n"},"nomos/base-layer-spec/priv-pos/index":{"title":"Nomos Private Proof of Stake Details","links":[],"tags":[],"content":"Description §\nIn PoS systems, preserving stake privacy is vital to avoid exposing users’ wealth. Diﬀerent approaches to achieve this include leveraging conﬁdential assets, such as  or coin mixing protocols applied to staking.\nCurrent Status §\nResearch phase: writing Private Proof of Stake Specifications:\nDue Date: 2023-09-29\n%%{ \n  init: { \n    &#039;theme&#039;: &#039;base&#039;, \n    &#039;themeVariables&#039;: { \n      &#039;primaryColor&#039;: &#039;#BB2528&#039;, \n      &#039;primaryTextColor&#039;: &#039;#fff&#039;, \n      &#039;primaryBorderColor&#039;: &#039;#7C0000&#039;, \n      &#039;lineColor&#039;: &#039;#F8B229&#039;, \n      &#039;secondaryColor&#039;: &#039;#006100&#039;, \n      &#039;tertiaryColor&#039;: &#039;#fff&#039; \n    } \n  } \n}%%\ngantt\n  tickInterval 1month\n  dateFormat YYYY-MM-DD \n  section Status\n    PPoS Specifications: In progress, 2023-06-25, 2023-09-29\n"},"nomos/base-layer-testnet/index":{"title":"Nomos Milestone: Base Layer Testnet Implementation","links":["nomos/base-layer-testnet/testnet/","ci-integration"],"tags":[],"content":"nomos:base-layer-testnet: §\n\nDescription §\nKey Epics §\ntestnet: index §\n\ndue: October 27th\nprogress: 66% (unstable testnet)\nshort description: deployment of the initial testnet for the Nomos network\n\nDependent Upon: §\nvac:dst:node-cicd §\n\nci-integration\n"},"nomos/base-layer-testnet/testnet/index":{"title":"Nomos Testnet Details","links":[],"tags":[],"content":"nomos:testnet: §\n\nDescription §\nWe aim for having an unstable testnet (asap) with no guarantees on breaking changes:\n\nData can be wiped out at every new rollout\nAccounts may disappear at some point\nThere are no incentives initially (ie no token as it requires data permanence)\nA good first functionality target would be to implement something like Bitcoin’s ordinals (NFTs), since they are just signed data.\n\nMore information: https://www.notion.so/Testnet-55049d959a6145fd9c542c5b3999c65a\nResearch §\nEngineering §\nCurrent Focus §\n%%{ \n  init: { \n    &#039;theme&#039;: &#039;base&#039;, \n    &#039;themeVariables&#039;: { \n      &#039;primaryColor&#039;: &#039;#BB2528&#039;, \n      &#039;primaryTextColor&#039;: &#039;#fff&#039;, \n      &#039;primaryBorderColor&#039;: &#039;#7C0000&#039;, \n      &#039;lineColor&#039;: &#039;#F8B229&#039;, \n      &#039;secondaryColor&#039;: &#039;#006100&#039;, \n      &#039;tertiaryColor&#039;: &#039;#fff&#039; \n    } \n  } \n}%%\ngantt\n  tickInterval 1month\n  dateFormat YYYY-MM-DD \n  section Status\n    Node for Testnet: In progress, 2023-08-28, 2023-10-27\n\n%%{ \n  init: { \n    &#039;theme&#039;: &#039;base&#039;, \n    &#039;themeVariables&#039;: { \n      &#039;primaryColor&#039;: &#039;#BB2528&#039;, \n      &#039;primaryTextColor&#039;: &#039;#fff&#039;, \n      &#039;primaryBorderColor&#039;: &#039;#7C0000&#039;, \n      &#039;lineColor&#039;: &#039;#F8B229&#039;, \n      &#039;secondaryColor&#039;: &#039;#006100&#039;, \n      &#039;tertiaryColor&#039;: &#039;#fff&#039; \n    } \n  } \n}%%\ngantt\n  tickInterval 1month\n  dateFormat YYYY-MM-DD \n  section Status\n    Client for Testnet: In progress, 2023-09-11, 2023-10-27\n\n%%{ \n  init: { \n    &#039;theme&#039;: &#039;base&#039;, \n    &#039;themeVariables&#039;: { \n      &#039;primaryColor&#039;: &#039;#BB2528&#039;, \n      &#039;primaryTextColor&#039;: &#039;#fff&#039;, \n      &#039;primaryBorderColor&#039;: &#039;#7C0000&#039;, \n      &#039;lineColor&#039;: &#039;#F8B229&#039;, \n      &#039;secondaryColor&#039;: &#039;#006100&#039;, \n      &#039;tertiaryColor&#039;: &#039;#fff&#039; \n    } \n  } \n}%%\ngantt\n  tickInterval 7day\n  dateFormat YYYY-MM-DD \n  section Status\n    DevOps for Testnet: In progress, 2023-09-11, 2023-09-30\n"},"nomos/consensus-def/index":{"title":"Nomos Milestone: Scalable Consensus Definition","links":[],"tags":[],"content":"nomos:consensus-def: §\n\nDescription §\nThis tracks the work of the initial discovery effort that lays the groundwork for all other work, consensus. A survey of options was undertaken, explored and documented. The product of all the work is Carnot.\nMain whitepaper:\nPseudocode specification of Carnot: https://github.com/logos-co/nomos-specs/blob/master/carnot/spec.md\nStatus: Delivered"},"nomos/index":{"title":"Nomos Roadmap Overview","links":[],"tags":["nomos","roadmap","overview"],"content":"Nomos Overview §\nThe Nomos project building a blockchain for Network States. To learn more about the project, please visit the website\nNomos is currently in its research phase, and actively building a Testnet."},"nomos/milestones/coordination-layer":{"title":"Coordination Layer","links":[],"tags":["nomos-milestone","roadmap-2024"],"content":"Core Tasks §\n\nDefine data model (ie UTXO + partial transactions)\nSelect proving system. This could potentially become a very large project, requiring tooling and compiler development. But we should try by all means using a ZK system with a compiler readily available.\nProvide the necessary tools for a ZK engineer to develop the 3 proofs and experimental Zone bridges.\n\nAction Plan §\nThe stages of research and development for the CL are as follow:\n\nPhase 1: Design CL data model. We need a simple, expressive transaction system that supports synchronous composability. The output from this phase will be a CL specification focused on supporting one key feature: private atomic asset transfers between zones.\nPhase 2: Choose ZK system. The single most important task of the research team in this work-stream is to make the fundamental choices that will allow us to build the foundation as fast as possible for a usable CL. This has to be done carefully and considering the specific use case of ZK in the CL, with the requirements that we have.\nPhase 3: Build the minimal system for protocol dependencies. After this, we need to put a minimal system in place, so that the 3 proofs of the protocol can be built. This is a big blocker for the network privacy and PPoS protocols, so it needs to be the primary implementation objective.\nPhase 4 (partially in 2024): Develop the CL tooling and integration to unlock more complex engineering feats. This will be a larger task, and not assumed to be finished by 2024. These include:\n\nZone bridges\nSynchronous composability\nAggregation/Solving layer\n\n\n"},"nomos/milestones/data-availability":{"title":"Data Availability","links":[],"tags":["nomos-milestone","roadmap-2024"],"content":"Core Tasks §\n\nDispersal. Design Dispersal algorithm. With current conclusions on the DA requirements of Zones, we can design dispersal given:\nNumber of chunks\nNumber of nodes participating in DA\nPoV. This solution will require gossip-based distribution of Proof of Validator (see below) and public keys, to allow VID without relying on validator registries.\nVID? Analyze if VID is still a better option than async validator light-node verification (the Danksharding way), given the target design with many more nodes than initially accounted for.\nDissemination. Design of an altruistic replication protocol (ie dissemination), to further strengthen the DA, by extending it beyond the Nomos validators to Light Nodes. This could be a DHT or similar solution.\nPerhaps this turns into “DA starts with a groups of selected validators and then it’s further disseminated although without proof in VID” situation, which might actually be more coherent with our vision. Answering this question is very important.\n\nAction Plan §\nSolving the remaining problems of DA requires mainly knowledge of distributed systems. The only exception is the PoV, which can be designed a researcher with more knowledge of Zk. Note that it’s mainly an ZK engineering problem, not a protocol problem.\nThe steps to implement Data Availability are the following:\n\nInitial implementation. Pick a number of nodes and disperse the chunks directly to them. This solution is insufficient for production because it lacks two things:\n\nEven distribution of chunks in the entire validator set.\nA single client cannot disperse the chunks well enough, while at the same time gossiping cannot be used for this (defeats the entire purpose of DA).\nA way to verify that the network has achieved enough dissemination.\nIt doesn’t scale. If we have 100k nodes, do we select a subset? How’s that subset gonna distribute to the rest of the network.\n\n\nASAP, Design a dispersal and dissemination protocol, to solve the above problems. This can be thought of an IPFS kind of protocol. The main difference is that the validators are able to verify DA through sampling to ensure the data is there.\nImplement solution in 2.\n\nDA is a problem that looks more solved than it actually is. The key aspects that remain to be solved are listed above. Working on solutions for this, while maintaining the design principle of maximizing validator count with low reliability, it’s paramount."},"nomos/milestones/index":{"title":"Nomos Milestones","links":["nomos/milestones/p2p-privacy","nomos/milestones/data-availability","nomos/milestones/ppos-consensus","nomos/milestones/coordination-layer","nomos/milestones/testnet-insights","nomos/milestones/user-tools"],"tags":["milestones","nomos"],"content":"Milestones §\n\nP2P Privacy\nData Availability\n Consensus\nCoordination Layer\nTestnet + Insights\nUser Tools\n\nAdditional Resources §\n\nNotion Milestone Execution Plan\nNotion Milestone Tracker\n"},"nomos/milestones/p2p-privacy":{"title":"P2P Privcay","links":[],"tags":["nomos-milestone","roadmap-2024"],"content":"Core Tasks §\n\nImplement Proof of Leader Election\nImplement Proof of Validator (rather employed at other layers, but planning-wise it’s better to consider it here)\nFull Analysis of Wealth Concentration using game-theoretical node behavior.\nFull Analysis of privacy leak due to orphan proofs\n\nAction Plan §\nThe consensus protocol is the best-known piece of our design, given our extensive experience in the matter. However, its guarantees depend largely on the network layer, while all the remaining cryptographic components depend on the CL. These two is where our focus is on. Besides this, most of the deliverables are advanced-stage components, meaning that they are the last pieces remaining.\nThe road towards finalization looks as follows:\n\nImplement the 2 proofs. This depends on the Coordination Layer.\nFully analyze the remaining open questions (wealth concentration and privacy leaks via orphan proofs). The work on wealth concentration is scheduled to start soon.\n"},"nomos/milestones/ppos-consensus":{"title":"PPoS / Consensus","links":[],"tags":["nomos-milestone","roadmap-2024"],"content":"Core Tasks §\n\nImplement Proof of Leader Election\nImplement Proof of Validator (rather employed at other layers, but planning-wise it’s better to consider it here)\nFull Analysis of Wealth Concentration using game-theoretical node behavior.\nFull Analysis of privacy leak due to orphan proofs\n\nAction Plan §\nThe consensus protocol is the best-known piece of our design, given our extensive experience in the matter. However, its guarantees depend largely on the network layer, while all the remaining cryptographic components depend on the CL. These two is where our focus is on. Besides this, most of the deliverables are advanced-stage components, meaning that they are the last pieces remaining.\nThe road towards finalization looks as follows:\n\nImplement the 2 proofs. This depends on the Coordination Layer.\nFully analyze the remaining open questions (wealth concentration and privacy leaks via orphan proofs). The work on wealth concentration is scheduled to start soon.\n"},"nomos/milestones/testnet-insights":{"title":"Testnet + Insights","links":[],"tags":["nomos-milestone","roadmap-2024"],"content":"Core Tasks §\n\nTestnet Instrumentation. Internal, for debugging pre-releases.\n\nHealth Monitoring\nInstrumentation for DS debugging\nLeader selection and Fork visualization\n\n\nNetwork Explorers. Public access, but a critical tool for debugging.\n\nBlock and mempool explorers\n\n\n\nAction Plan §\nThis work-stream is purely an engineering effort, but with the caveat that introduces user-facing systems like the Network Explorer. Both internal instrumentation and public-facing functionality should be initiated as soon as possible.\nThe key in implementing these is to start with a minimal functionality keeping these two primary objectives in mind:\n\nHelp us develop, debug and understand our network\nAttract users by exposing visualizations of the blockchain with cool tools for exploring the chain and the network behavior. This is, in a way, a marketing tool.\n"},"nomos/milestones/user-tools":{"title":"User Tools","links":[],"tags":["nomos-milestone","roadmap-2024"],"content":"Core Tasks §\n\nWallet\n\nMajor browser support\nBasic functionality: payments, inscriptions, tokens\n\n\nUltra-easy to run validator software\n\nMust have GUI and background runner (similar to Dropbox tool)\nOne-click installation for Windows/OSX/Linux\n\n\n\nAction Plan §\nThe priority should be to implement the wallet, since we can have initially a node that is not easy to run. Making it easy is something that can be achieved once we have a functioning system. The wallet is however necessary for any usable Testnet that we want to make public.\nThe main problem is that the wallet is highly dependent on the Coordination Layer, so further efforts in this area are blocked until that is solved (at least past Phase 1)."},"nomos/monthly-reports/2023-aug":{"title":"2023-aug","links":[],"tags":[],"content":"Nomos Monthly Report - August 2023 §\nNetwork Privacy and Mixnet §\nResearch §\n\nConducted in-depth research on Nym mixnet architecture to design prototype architecture.\nDiscussed mixnet topology management and reached a preliminary agreement on architecture.\nAnalyzed end-to-end latency in Mixnet PoC, identifying potential optimization areas.\n\nDevelopment §\n\nImplemented a prototype for Sphinx packet building, mixing packets at the first hop of gossipsub with 3 mixnodes.\nAdded support for libp2p in tests and nomos node.\nDeveloped base implementation of Mixnet PoC and continued improvements.\nImplemented mixnode core module and mixnet-client library.\nAdded features like Sphinx packet delay support, auto port for integration tests, and graceful shutdown for mixnode elements.\nBegan shifting from channels to streams in mixnet message handling.\n\nDocumentation §\n\nCreated Mixnet Architecture document: Mixnet Architecture\nPrepared Mixnet Measurements documentation: Mixnet Measurements\n\nPrivate Proof of Stake (PPoS) §\nResearch §\n\nWorked on PPoS design, addressing potential metadata leakage due to staking and rewarding.\nFocused on potential bribery attacks and privacy reasoning.\nUpdated draft addressing comments related to shielded and transparent transaction types.\nDefined an opportunistic voting problem.\nContinued analysis on zCash transaction’s construction.\nDiscussed token-engineering and staking in private settings.\n\nDevelopment §\n\nProgress on this project was slower compared to others and requires more attention going forward.\n\nData Availability Sampling (DAS) §\nResearch §\n\nAnalyzed data decimation in the data availability problem.\nConducted DA benchmarks and analysis for data commitments and encoding.\nExplored and discarded the idea of node sharding.\nStudied RS+KZG in the context of DA architecture.\nAnalyzed node decay in relation to data availability.\nDiscovered limitations in RS and KZG implementation, particularly with library scalability and finite field challenges.\n\nDevelopment §\n\nCreated basic wrappers and APIs for Reed-Solomon encoding and KZG commitments.\nImplemented RS and KZG libraries with simplistic APIs.\nConducted benchmarks for KZG implementation and simulation runs for different configurations.\nDeveloped KZG Base Layer initial approach.\n\nDocumentation §\n\nImproved upper bound analysis on data availability probability: Overleaf Document\nDocumented RS &amp; KZG benchmarking results: Notion Document\n\nTesting, CI, and Simulation App §\nDevelopment §\n\nMade various fixes and improvements to the simulation application.\nShared simulation app and instructions.\nUpdated and merged CI improvements.\nImplemented parallel node init for improved simulation run times.\nDeveloped branch overlay for simulating 100K+ nodes.\nUpdated sequential builds for nomos node features in CI.\nCreated a new repository for simulations configurations and test results.\nImplemented graceful shutdown of simulations.\nAdded support for CSV format output of simulation data.\n\nChallenges and Next Steps §\n\nThe Private PoS project is progressing slower than others and requires more attention.\nAddressing limitations discovered in RS and KZG implementations, particularly scalability issues.\nContinuing to optimize the Mixnet implementation based on PoC results.\nFurther development and refinement of the simulation app for more comprehensive testing.\n\nResources and Links §\n\nNomos Node Repository: https://github.com/logos-co/nomos-node\nNomos Simulations Repository: https://github.com/logos-co/nomos-simulations\nMixnet Architecture Document: https://www.notion.so/Mixnet-Architecture-613f53cf11a245098c50af6b191d31d2\nData Availability Analysis: https://www.overleaf.com/read/gzqvbbmfnxyp\n\nThe Nomos team has made significant progress across multiple areas in August, with notable advancements in Mixnet implementation, Data Availability Sampling research, and simulation capabilities. The Private PoS project requires additional focus in the coming months to keep pace with other developments."},"nomos/monthly-reports/2023-sept":{"title":"2023 September Nomos Monthly Report","links":["vac/acz/","","vac/zkvm/","vac/dr/consensus/nomos/carnot-2-3rds-vote-aggregation","nomos/updates/2023-09-04","nomos/updates/2023-09-11","nomos/updates/2023-09-19","nomos/updates/2023-09-26"],"tags":["monthly-report","nomos"],"content":"Executive Summary §\nThe Nomos team continues to stay focused on research related to the fine-grained details of the Base Layer specification and implementation. The addition of a Project Manager is expected to not only expedite the research by allowing the lead to dive deeper into the issues involved but also make that work and progress more transparent.\nMehmet joins the team next month to fulfill a long needed dedicated role in research privacy and zero-knowledge technology as it pertains to the Nomos requirements.\nThe whitepapers plan to be polished and published by early next month which not only details the current specifications but also known problems that need to be solved.\nKey Updates §\nPersonnel §\n\nFilip has joined as a Project Manager (last month) to assist in various activities. His position is to sit in between the Insights team and the Nomos project to facilitate development tracking and resource allocation. It is anticipated that his involvement will speed up development as current resources are then freed to focus on research and development. Until demands within Nomos require full-time engagement from him, he will also be assisting with Vac Program Management.\nAfter a lot of candidate interviews, Mehmet was offered a position and accepted to focus on the privacy and cryptography research needs within the project. His background in cryptography and security auditing of popular zero-knowledge platforms is expected to be very useful in aiding to architect Nomos. Mehmet’s starting date is Oct 2\n\nAnother candidate for this role that was considered, Ramses, has joined the Vac team and will initially be aiding in this work and growing the relationship with their Applied Crypto and Zero-Knowledge team. Ramses started in\n\n\nAn offer has been extended to a candidate for the open role of Applied Network Researcher. He passed all interview rounds but unfortunately passed on the final offer for another opportunity.\nThe roles of Applied Network Researcher and Distributed Systems Researcher are still open and candidates are being interviewed.\n\nMilestones §\nNomos’ roadmap is currently composed of five main sections, each of which is broken up into Research and Development. Obviously, Development lags behind the Research section. These five areas are as follows:\n\nWhitepapers\nNetwork Privacy and Mixnet\nTestnet\nPrivate PoS\nData Availability\n\nThe Milestone definitions and timelines are not yet ported to this site, and as such, are private to Logos. They are planned to be publicized on this site by the end of the this month, potentially bleeding into the beginning of October. For those with Notion access, you can view the Milestone definitions here.\nThe following sections will outline key activity across these milestones. If more information and detail is desired, links can be found under the associated heading among the Sources and Useful Links Weekly updates section.\nWhitepapers §\nThe current Whitepaper drafts are almost ready for publication. They require only “beautification” and a listing of detailed “current unsolved problems” that need to be explored later in the total project. This will be done following the current prioritization of mixnet specification.\nThis milestone will be completed next month.\nNetwork Privacy and Mixnet §\nThe specification of the mixnet is currently underway and expected to wrap up soon (next month??).  This initial specification is modeled after the current State of the Art in the mixnet industry. This is chosen to be critical path based on all the depending architectural decisions that stem from decisions of the networking layer.\nReview and analysis of current mixnet literature continues. Throughout this review, a modeling framework was developed in order to help evaluate future (v2) speculative mixnet architectures as compared to the current one. This theoretical framework has already been able to reproduce known results within the industry, such as deriving that the probability of an anonymity failure:\n\ndecreases when increasing the number of layers\nincreases when increasing the number of nodes within a single layer.\n\nFramework and analysis details can be found in the overleaf document.\nWhile research explores subtleties in the mixnet specification, development has tackled the foundations of its implementation on top of libp2p within the nomos-node repository. They’ve logically setup how it connects to the rest of the pieces of the node, setup testing frameworks and node monitoring hooks, and generally got it provisioned for the upcoming testnet.\nTestnet §\nA PoC/Draft Testnet was created and merged via Docker-Compose, then general exploration was done to identify what to measure and how to do it within the nomos-node software.\nSimulations of the branch overlay with 1 committee was conducted. Initial results discovered a bug  in reproducibility that was fixed. Additional simulations resulted in discovery of inter-module errors with the leader selection. This is currently being explored along with integration of mixnet developments.\nPrivate PoS §\nResearch was conducted in a variety of areas around a Private Proof of Stake spec relevant to the architecture of Nomos. All details can be found in the Whitepaper descriptions.\nThe initial design was created based on Zcash designs with section details around how “stake” is considered for the Base Layer of Nomos, how “restaking” could work, and various consensus modifications around Carnot. An introduction of “shadows” was done which presents the ideas around the initial voting process. The logic of these “shadows” is currently being fleshed out so that they’re more intuitive to understand. One result is that they’re now called “Validators” in an effort to keep naming conventions reasonable across the industry.\nMuch attention was spent on a discovered issue with vote propagation within this construction. This issue is around the implications of vote withholding and how they change as you move up the overlay. The solution being to propagate a map of seen votes upstream alongside the vote, thus increasing transparency of participation.\nThe concept of “Hastiness” has been introduced to describe the leader’s ability to decide whether or not to include votes from the root committee if the threshold is reached before they’ve had the opportunity to conclude. More research is underway to detail the implications of this decisions with respect to payout, latency, and security.\nMost notably, an extension (or more constrained parameterization) of Carnot was initiated and is underway (expected by end of Oct) as a consequence of needing to mitigate a signature aggregation issue. This extension requires 2/3 votes to be collected before a decisions is made.\nData Availability §\nResearch continues on the various available Data Availability schemes and their trade-offs which resulted in the ability to make some decisions on the Nomos specification and identified a more specific personnel requirement for specialized cryptographic expertise. This research demand will now be filled by the new addition to the team and progress is expected to accelerate.\nAn analysis of the impact of node decay in Data Availability was performed and presented in a Logos Research Seminar. This research resulted in a draft specification of private DA. This then lead to the first draft of a complete privacy solution for the networking layer for consensus and DA.\nThe architecture of Data Availability services was fleshed out within nomos-node software. Data dissemination implementation was completed and the mempool for certificates is currently in progress.\nPerceived Changes in Project Risk §\nPrivacy remains at the forefront of this project’s desired requirements. As such, it is important to define what types of privacy the project can offer and then detail exactly how various technology provides it. This is a “ground up” process that starts at the lowest layers and propagates up through the stack. Due to the continued exploration and designing of the Base Layer, it remains to be seen how the currently designs will impact upper layers, namely “Execution Zones.” The on-going development of the zkVM incubation project within Vac raises the risk of incompatibility between the two as both projects are optimizing for their respective domains in parallel and without much communication.\nFuture Plans §\nInsight §\nIt is expected that the entire Nomos roadmap will be specified within this site and the weekly reporting process will be in line with the Milestones defined therein.\nA Logos Collaborations section will be included next month to highlight differences in alignment with the Logos Collective as well as cross project collaboration updates.\nDepending on the uptake and viability of the Waku reporting process to other projects, then a myriad of quantitative measures will be included in the next monthly report.\nProject §\nNext month focuses on finalizing and publishing:\n\nthe first version of the Whitepapers\n\nemphasis that specification details will focus on the Base Layer implementation, leaving unknowns and explicit detail of above layers to be explored as open problems.\n\n\na Nomos Testnet Client and Node implementation\na viability analysis of an embedded mixnet\na specification and pseudocode for the extended 2/3-vote aggregation Carnot consensus algorithm (Vac dependency: carnot-2-3rds-vote-aggregation)\n\nSources and Useful Links §\nWeekly updates referenced\n\n2023-09-04\n2023-09-11\n2023-09-19\n2023-09-26\n"},"nomos/monthly-reports/index":{"title":"Nomos Monthly Reports","links":[],"tags":[],"content":"Here are the monthly reports that are generated for Nomos."},"nomos/updates/2023-07-24":{"title":"2023-07-24 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Research\n\nMilestone 1: Understanding Data Availability (DA) Problem\nHigh-level exploration and discussion on data availability problems in a collaborative offsite meeting in Paris.\nExplored the necessity and key challenges associated with DA.\nIn-depth study of Verifiable Information Dispersal (VID) as it relates to data availability.\nBlocker: The experimental tests for our specific EC scheme are pending, which is blocking progress to make final decision on KZG + commitments for our architecture.\nMilestone 2: Privacy for Proof of Stake (PoS)\nAnalyzed the capabilities and limitations of mixnets, specifically within the context of timing attacks in private PoS.\nInvested time in understanding timing attacks and how Nym mixnet caters to these challenges.\nReviewed the Crypsinous paper to understand its privacy vulnerabilities, notably the issue with probabilistic leader election and the vulnerability of anonymous broadcast channels to timing attacks.\n\nDevelopment\n\nMilestone 1: Mixnet and Networking\nInitiated integration of libp2p to be used as the full node’s backend, planning to complete in the next phase.\nBegun planning for the next steps for mixnet integration, with a focus on understanding the components of the Nym mixnet, its problem-solving mechanisms, and the potential for integrating some of its components into our codebase.\nMilestone 2: Simulation Application\nCompleted pseudocode for Carnot Simulator, created a test pseudocode, and provided a detailed description of the simulation. The relevant resources can be found at the following links:\n\nCarnot Simulator pseudocode (https://github.com/logos-co/nomos-specs/blob/Carnot-Simulation/carnot/carnot_simulation_psuedocode.py)\nTest pseudocode (https://github.com/logos-co/nomos-specs/blob/Carnot-Simulation/carnot/test_carnot_simulation.py)\nDescription of the simulation (https://www.notion.so/Carnot-Simulation-c025dbab6b374c139004aae45831cf78)\n\n\nImplemented simulation network fixes and warding improvements, and increased the run duration of integration tests. The corresponding pull requests can be accessed here:\n\nSimulation network fix (https://github.com/logos-co/nomos-node/pull/262)\nVote tally fix (https://github.com/logos-co/nomos-node/pull/268)\nIncreased run duration of integration tests (https://github.com/logos-co/nomos-node/pull/263)\nWarding improvements (https://github.com/logos-co/nomos-node/pull/269)\n\n\n"},"nomos/updates/2023-07-31":{"title":"2023-07-31 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Nomos 31st July\n[Network implementation and Mixnet]:\nResearch\n\nInitial analysis on the mixnet Proof of Concept (PoC) was performed, assessing components like Sphinx for packets and delay-forwarder.\nConsidered the use of a new NetworkInterface in the simulation to mimic the mixnet, but currently, no significant benefits from doing so have been identified.\nDevelopment\nFixes were made on the Overlay interface.\nNear completion of the libp2p integration with all tests passing so far, a PR is expected to be opened soon.\nLink to libp2p PRs: https://github.com/logos-co/nomos-node/pull/278, https://github.com/logos-co/nomos-node/pull/279, https://github.com/logos-co/nomos-node/pull/280, https://github.com/logos-co/nomos-node/pull/281\nStarted working on the foundation of the libp2p-mixnet transport.\n\n[Private PoS]:\nResearch\n\nDiscussions were held on the Privacy PoS (PPoS) proposal, aligning a general direction of team members.\nReviews on the PPoS proposal were done.\nA proposal to merge the PPoS proposal with the efficient one was made, in order to have both privacy and efficiency.\nDiscussions on merging Efficient PoS (EPoS) with PPoS are in progress.\n\n[Carnot]:\nResearch\n\nAnalyzing Bribery attack scenarios, which seem to make Carnot more vulnerable than expected.\n\nDevelopment\n\nImproved simulation application to meet test scale requirements (https://github.com/logos-co/nomos-node/pull/274).\nCreated a strategy to solve the large message sending issue in the simulation application.\n\n[Data Availability Sampling (or VID)]:\nResearch\n\nConducted an analysis of stored data “degradation” problem for data availability, modeling fractions of nodes which leave the system at regular time intervals\nContinued literature reading on Verifiable Information Dispersal (VID) for DA problem, as well as encoding/commitment schemes.\n"},"nomos/updates/2023-08-07":{"title":"2023-08-07 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Nomos weekly report §\nNetwork implementation and Mixnet: §\nResearch §\n\nResearched the Nym mixnet architecture in depth in order to design our prototype architecture.\n(Link: https://github.com/logos-co/nomos-node/issues/273#issuecomment-1661386628)\nDiscussions about how to manage the mixnet topology.\n(Link: https://github.com/logos-co/nomos-node/issues/273#issuecomment-1665101243)\n\nDevelopment §\n\nImplemented a prototype for building a Sphinx packet, mixing packets at the first hop of gossipsub with 3 mixnodes (+ encryption + delay), raw TCP connections between mixnodes, and the static entire mixnode topology.\n(Link: https://github.com/logos-co/nomos-node/pull/288)\nAdded support for libp2p in tests.\n(Link: https://github.com/logos-co/nomos-node/pull/287)\nAdded support for libp2p in nomos node.\n(Link: https://github.com/logos-co/nomos-node/pull/285)\n\nPrivate PoS: §\nResearch §\n\nWorked on PPoS design and addressed potential metadata leakage due to staking and rewarding.\nFocus on potential bribery attacks and privacy reasoning, but not much progress yet.\nStopped work on Accountability mechanism and PPoS efficiency due to prioritizing bribery attacks.\n\nCarnot: §\nResearch §\n\nAddressed two solutions for the bribery attack. Proposals pending.\nWork on accountability against attacks in Carnot including Slashing mechanism for attackers is paused at the moment.\nModeled data decimation using a specific set of parameters and derived equations related to it.\nProposed solutions to address bribery attacks without compromising the protocol’s scalability.\n\nData Availability Sampling (VID): §\nResearch §\n\nAnalyzed data decimation in data availability problem.\n(Link: https://www.overleaf.com/read/gzqvbbmfnxyp)\nDA benchmarks and analysis for data commitments and encoding. This confirms that (for now), we are on the right path.\nExplored the idea of node sharding: https://arxiv.org/abs/1907.03331 (taken from Celestia), but discarded it because it doesn’t fit our architecture.\n\nTesting and Node development: §\n\nFixes and enhancements made to nomos-node.\n(Link: https://github.com/logos-co/nomos-node/pull/282)\n(Link: https://github.com/logos-co/nomos-node/pull/289)\n(Link: https://github.com/logos-co/nomos-node/pull/293)\n(Link: https://github.com/logos-co/nomos-node/pull/295)\nRan simulations with 10K nodes.\nUpdated integration tests in CI to use waku or libp2p network.\n(Link: https://github.com/logos-co/nomos-node/pull/290)\nFix for the node throughput during simulations.\n(Link: https://github.com/logos-co/nomos-node/pull/295)\n"},"nomos/updates/2023-08-14":{"title":"2023-08-17 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Nomos weekly report 14th August §\n\nNetwork Privacy and Mixnet §\nResearch §\n\nMixnet architecture discussions. Potential agreement on architecture not very different from PoC\nMixnet preliminary design [https://www.notion.so/Mixnet-Architecture-613f53cf11a245098c50af6b191d31d2]\n\nDevelopment §\n\nMixnet PoC implementation starting [https://github.com/logos-co/nomos-node/pull/302]\nImplementation of mixnode: a core module for implementing a mixnode binary\nImplementation of mixnet-client: a client library for mixnet users, such as nomos-node\n\nPrivate PoS §\n\nNo progress this week.\n\n\nData Availability §\nResearch §\n\nContinued analysis of node decay in data availability problem\nImproved upper bound on the probability of the event that data is no longer available given by the (K,N) erasure ECC scheme [https://www.overleaf.com/read/gzqvbbmfnxyp]\n\nDevelopment §\n\nLibrary survey: Library used for the benchmarks is not yet ready for requirements, looking for alternatives\nRS &amp; KZG benchmarking for our use case https://www.notion.so/2D-Reed-Solomon-Encoding-KZG-Commitments-benchmarking-b8340382ecc741c4a16b8a0c4a114450\nStudy documentation on Danksharding and set of questions for Leonardo [https://www.notion.so/2D-Reed-Solomon-Encoding-KZG-Commitments-benchmarking-b8340382ecc741c4a16b8a0c4a114450]\n\n\nTesting, CI and Simulation App §\nDevelopment §\n\nSim fixes/improvements [https://github.com/logos-co/nomos-node/pull/299], [https://github.com/logos-co/nomos-node/pull/298], [https://github.com/logos-co/nomos-node/pull/295]\nSimulation app and instructions shared [https://github.com/logos-co/nomos-node/pull/300], [https://github.com/logos-co/nomos-node/pull/291], [https://github.com/logos-co/nomos-node/pull/294]\nCI: Updated and merged [https://github.com/logos-co/nomos-node/pull/290]\nParallel node init for improved simulation run times [https://github.com/logos-co/nomos-node/pull/300]\nImplemented branch overlay for simulating 100K+ nodes [https://github.com/logos-co/nomos-node/pull/291]\nSequential builds for nomos node features updated in CI [https://github.com/logos-co/nomos-node/pull/290]\n"},"nomos/updates/2023-08-21":{"title":"2023-08-21 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Nomos weekly report 21st Oct §\n(delayed as I was on holidays and then took me some time to clarify some things with the team)\nNetwork Privacy and Mixnet §\n\nImproved the mixnet implementation based on latest discussion. https://github.com/logos-co/nomos-node/pull/307\nBase implementation of Mixnet PoC: https://github.com/logos-co/nomos-node/pull/302\nRefactor to encapsulate message body creation&amp;write&amp;read: https://github.com/logos-co/nomos-node/pull/308\nNew issues related to mixnet: https://github.com/logos-co/nomos-node/issues?q=is%3Aopen+is%3Aissue+label%3Amixnet\n\nPrivate PoS §\n\nUpdated draft addressing comments related to shielded and transparent transaction types.\nDefined an opportunistic voting problem.\nContinuing analysis on zCash transaction’s construction.\nThis is currently the project that is going slowest and needs more attention going forward. It’s also the most complex and with the most unknowns.\n\nSimulations app §\n\nGraceful shutdown of simulations.\nCreated a new repository for simulations configurations and test results: https://github.com/logos-co/nomos-simulations\nUpdates and discussed test runs: https://github.com/logos-co/nomos-simulations/pull/3\nChanges to support CSV format output of simulation data: https://github.com/logos-co/nomos-node/pull/304 and https://github.com/logos-co/nomos-node/pull/306\nMinor issue on integration tests fixed: https://github.com/logos-co/nomos-node/pull/315\n\nData Availability Sampling §\n\nStudied RS+KZG in context of our DA architecture.\nRS: basic encoding/decoding lib. Created a basic wrapper around reed-solomon-encoding library to work with arbitrary bytearrays with the simples API possible. Created basic tests and docs as well.\nKZG: basic commitment + proof creation, also proof verification lib. Same here, created a simplistic API that abstract from the confusing types in the underlaying used library.\nCreated a simplistic API for RS: https://github.com/logos-co/nomos-node/pull/303\nCreated a simplistic API for KZG: https://github.com/logos-co/nomos-node/pull/309\n"},"nomos/updates/2023-08-29":{"title":"2023-08-29 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Nomos weekly report §\nMilestone 1: Network Privacy and Mixnet §\nResearch §\n\nA Mixnet PoC was conducted to gauge end-to-end latency, revealing a slight latency increase when utilizing mixnet. Several potential optimization areas have been identified.\n\nDevelopment §\n\nVarious enhancements for the Mixnet have been developed, including the addition of delays for Sphinx packets, auto port for integration tests, and introducing a graceful shutdown for mixnode elements.\nThere’s an ongoing shift from channels to streams in mixnet message handling.\nRefactoring of Mixnet Node &amp; Client: https://github.com/logos-co/nomos-node/pull/320\nMixnet PoC Architecture Documents: https://www.notion.so/Mixnet-and-Network-Privacy-Architecture-613f53cf11a245098c50af6b191d31d2\nMixnet Measurements Documentation: https://www.notion.so/Mixnet-Measurements-551ade11ae4d44ca9f3d947ea6950c67\nSphinx Packet Delay Support: https://github.com/logos-co/nomos-node/pull/321\nAuto Port for Tests: https://github.com/logos-co/nomos-node/pull/327\nMixnet Criterion Measurement: https://github.com/logos-co/nomos-node/pull/328\nGraceful Shutdown for Mixnet: https://github.com/logos-co/nomos-node/pull/330\n\n\nMilestone 2: Private PoS §\nResearch §\n\nDiscussions were held about token-engineering and staking in private settings, resulting in documentation that delves into the validation and delegation aspects of PPoS. Current considerations involve the integration of the ZeroCash/zCash construction into the staking model.\n\n\nMilestone 3: Data Availability Sampling (RS, KZG) §\nResearch §\n\nLimitations discovered during RS and KZG implementation, notably with RS library scalability issues and bls12_381 curve finite field challenges. Found KZG libraries are primarily designed for Ethereum, which constrains the blob size.\nBenchmarks for KZG implementation were carried out, and simulation runs were conducted for different configurations.\nNode decay in relation to data availability was analyzed, leading to the derivation of an equation for understanding node averages in the network.\n\nDevelopment §\n\nKZG Library: https://github.com/logos-co/nomos-node/pull/325\nKZG Base Layer initial approach: https://github.com/logos-co/nomos-node/pull/309\nDetailed KZG Operation Benchmarks: https://github.com/logos-co/nomos-node/tree/da-kzg-benches\nNode Decay Analysis &amp; Results: https://www.overleaf.com/read/gzqvbbmfnxyp\n"},"nomos/updates/2023-09-04":{"title":"2023-09-04 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"nomos: §\n\nnetwork privacy and mixnet: §\nresearch §\n\nNo specific research tasks reported this week related to this milestone.\n\ndevelopment §\n\nMade mixnet tests stable: https://github.com/logos-co/nomos-node/pull/334\nFinished the delay implementation: https://github.com/logos-co/nomos-node/pull/362\nMigrated the mixnode binary to Overwatch for better integration: https://github.com/logos-co/nomos-node/pull/339\nAdded a retry mechanism to the libp2p backend for transient errors: https://github.com/logos-co/nomos-node/pull/332\nFixed network tests failing with mixnet: https://github.com/logos-co/nomos-node/pull/338\nFix panic for RandomDelayIter: https://github.com/logos-co/nomos-node/pull/335\nConnection cache for mixnet: https://github.com/logos-co/nomos-node/pull/343\nImplemented mempool network adapters for libp2p: https://github.com/logos-co/nomos-node/pull/344\nImplemented the libp2p version of the addtx endpoint: https://github.com/logos-co/nomos-node/pull/345\n\n\ntestnet: §\ndevelopment: §\n\nPOC/Draft for testnet using Docker Compose: https://github.com/logos-co/nomos-node/pull/364\nDNS Multiaddr parsing and peer id configuration: https://github.com/logos-co/nomos-node/pull/346, https://github.com/logos-co/nomos-node/pull/361\n\n\nprivate PoS: §\nresearch: §\n\nIntroduced the Base Design section, focusing on the ZCash design’s constructions, building an understanding of the data structures and algorithms, and presenting relevant algorithms with comprehensive descriptions.\nDeveloped the Staking Extension section, leveraging Base Design constructions to introduce staking mechanics, defining the “Stake” algorithm that transforms shielded coins into voting “staking coins”, and the “Reward” algorithm that distributes rewards and restakes coins back into the pool.\nCreated the Consensus Modifications section, detailing modifications to the Carnot Consensus algorithm based on the Staking Extension, introducing mapping of staking coins to validator “shadows”, presenting the initial voting construction, introducing a vote aggregation mechanism, and elaborating on vote dissemination and aggregation through a tree overlay.\n\n\ndata availability: §\nresearch: §\n\nStudied more options for DA verification schemes: https://www.notion.so/Data-Availability-Specification-WIP-c3961b681eba4ccdab2be9181e4207b4\nReached some conclusions that allow us to make progress in implementing the architecture. Blocker: we need specialized cryptographic expertise to make further progress on this. I will personally keep working on it later on, but privacy matters are more important now as they have a higher impact on the architecture.\nAnalysis of node decay in the data availability problem is complete: https://www.overleaf.com/read/gzqvbbmfnxyp\n\ndevelopment: §\n\nIncluded BL blobs in the block: https://github.com/logos-co/nomos-node/pull/368\n"},"nomos/updates/2023-09-11":{"title":"2023-09-11 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"nomos: §\n\nnetwork privacy and mixnet: §\nresearch: §\n\nRevised mathematical methods, such as the Poisson point process, etc., used in analysis of mixnets.\nExplored literature related to mixnets where approaches from differential privacy are used. The latter could lead to a more general privacy guarantee which is relevant to not only current but also future attacks on privacy.\n\ndevelopment: §\n\nFixed a bug in the connection pool implementation https://github.com/logos-co/nomos-node/pull/373\nFixed Cargo.toml for nomos-network https://github.com/logos-co/nomos-node/pull/380\nAdded defaults to libp2p settings https://github.com/logos-co/nomos-node/pull/388\nFixed request handling in mixnode: https://github.com/logos-co/nomos-node/pull/372\nAdded benchmark code (in localhost): https://github.com/logos-co/nomos-node/pull/375\nAfter trying to find existing solutions to routing strategies (routing first, privacy later), and not finding a proper solution, moved to thinking about a naive approach:  https://www.notion.so/WIP-Proposal-Routing-7b034dcac64940eda25ee415806d0ec8\nFound using sync Mutex will lead to a block. https://github.com/logos-co/nomos-node/pull/370\nFinish implementing the first version of retry for mixnode and mixclient https://github.com/logos-co/nomos-node/pull/386\n\n\ntestnet: §\ndevelopment: §\n\nNode config via environment variables: https://github.com/logos-co/nomos-node/pull/382\nObservability and node configuration in testnet work in progress: https://github.com/logos-co/nomos-node/pull/364 (Same draft PR as last week WIP).\nResolving more GH Actions related issues:\n\nhttps://github.com/logos-co/nomos-node/pull/385\nhttps://github.com/logos-co/nomos-node/pull/389\n\n\n\n\nprivate PoS: §\nresearch: §\n\nFound an issue in vote propagation of the PPoS construction: When a vote is propagated upstream to the higher committee there is a chance that a malicious shadow in committee decides not to broadcast their vote to the committee members and send it only upstream. Then this “unseen” vote will block the possibility of reconstructing the most common committee_vote, and at the same time prove that other shadows have voted. The solution for that is to propagate a map of seen votes upstream alongside the vote, this enables the higher committee to select only the votes that are most commonly seen for building the committee_vote thus making that kind of malicious behavior detectable.\nImproving the PPoS description: working on selecting proper naming conventions, as currently there are voters, shadows, coins which are confusing. That is done in pair with revising the logic.\n\n\ndata availability: §\nresearch: §\n\nA draft for private DA can be found here: https://www.notion.so/Data-Availability-Specification-c3961b681eba4ccdab2be9181e4207b4?d=d4e8d1bcd6224682ba74737100106e48#0c70202794214cbab626e51f7f1f7c24\n\ndevelopment: §\n\nBlobs in block: https://github.com/logos-co/nomos-node/pull/368\nDA service architecture: https://github.com/logos-co/nomos-node/pull/376\nDa service backend implementation: https://github.com/logos-co/nomos-node/pull/381\n"},"nomos/updates/2023-09-19":{"title":"2023-09-19 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"nomos: §\n\nnetwork privacy and mixnet: §\nresearch: §\n\nReview of  the   “Untraceable electronic mail, return addresses, and digital pseudonyms”  paper. Review of  the  “The Loopix anonymity system” paper.\nNotes provided in the overleaf document https://www.overleaf.com/read/rybwvjftfrrg\n\ndevelopment: §\n\nPolishing mixnet to make it ready for the testnet:\nHelping preparing mixnet deployments: https://github.com/logos-co/nomos-node/pull/408\nReviewed mixnet connection management\nRefactor the libp2p network backend: https://github.com/logos-co/nomos-node/tree/libp2p-refactor-yjlee and based on that prepare to measure the quality of unobservability - https://github.com/logos-co/nomos-node/issues/391\nBlock building: https://github.com/logos-co/nomos-node/pull/401\nFountain codes: https://github.com/logos-co/nomos-node/pull/407\nGot the mixnet retry PR merged: https://github.com/logos-co/nomos-node/pull/386\nFinish the concrete error implementation for mixnet and ready for merge: https://github.com/logos-co/nomos-node/pull/405\nWIP: fan-in message passing model for mixnode: https://github.com/logos-co/nomos-node/tree/mixnet-fan-in\n\n\ntestnet: §\ndevelopment: §\n\nTestnet preparation: https://github.com/logos-co/nomos-node/pull/410\nTestnet POC with libp2p merged: https://github.com/logos-co/nomos-node/pull/364\nThe POC for testnet using etcd and docker compose was reviewed and merged. The mixnet functionality will be added on top of this.\nSimulation branch overlay with 1 committee fix: https://github.com/logos-co/nomos-node/pull/402\nA bug where branch overlay results different from tree overlay with one committee blocked research team to use simulations results. Fixed it.\nImprovements in CI:\n\nhttps://github.com/logos-co/nomos-node/pull/409\nhttps://github.com/logos-co/nomos-node/pull/411\nhttps://github.com/logos-co/nomos-node/pull/412\n\n\nMinor improvements to remove annoying red x’s from our CI\n\n\nprivate PoS: §\nresearch: §\n\nShadows logic: Looking at how to describe the logic of the shadow in the most clear way: It will be divided into a set of modules, each module taking care of processing a separate communication channel.\nAll channels have their logic described in adequate modules and with references to self-descripting functions. However, some of them (like how exactly to aggregate votes)  must yet to be defined.\nHastiness issues: In short, the leader, in order to limit the cost of vote aggregation can decide to not to include votes from top committees (and root in particular). This is an acceptable strategy and will lead to a correctly formed aggregation proof. The proof will include a global threshold of votes from lower committees but not from the top committees (and root committee in particular). The impact of this leader’s hastiness does not break the security of the protocol as a threshold of votes is correctly gathered. However, it may limit rewards from the top committees (and root in particular), as the votes from those committees may not be needed to reach the threshold. More on that under the issues section of the PPoS doc.\n\n\ndata availability: §\nresearch: §\n\nFirst stab at privacy solution for the network layer for consensus and DA: https://www.notion.so/Practical-Private-Addressing-Network-Privacy-Component-2-2b9b4923124a4fdb81dba5d2bba1d289?d=99166164267a46589c5715175e1b3657#5e27d2010d30468f9d8f0d0928b9c639\nInit survey of SoA in network privacy alternative solutions\n\ndevelopment: §\n\nDA nomos core kickstart, added different pieces that were missing for abstractions: https://github.com/logos-co/nomos-node/pull/390\nAdded attestation trait\nAdded certificate trait\nAdded DaProtocol trait that abstracts encoding/decoding, and put the pieces together for blob+attestation+certificate handling.\nRefactored (moved and restructured) da modules\nRefactor and improve common traits - https://github.com/logos-co/nomos-node/pull/395\nImplement a simple da protocol with full replication - https://github.com/logos-co/nomos-node/pull/400\nImplement a command to disseminate blobs through the network - https://github.com/logos-co/nomos-node/pull/396\nAdded da-service to nomos node - https://github.com/logos-co/nomos-node/pull/404\nHousekeeping:\n\nhttps://github.com/logos-co/nomos-node/pull/403\nhttps://github.com/logos-co/nomos-node/pull/388\nhttps://github.com/logos-co/nomos-node/pull/399\n\n\n"},"nomos/updates/2023-09-26":{"title":"2023-09-26 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"nomos: §\n\nnetwork privacy and mixnet: §\nresearch: §\n\nWith the assumption that nodes of a mixnet are selected without replacement, we performed analysis with Byzantine node presence (for specific widths and lengths). This gives the probability that there is at least one path where all nodes are Byzantine (“anonymity” failure)\nEvaluation in the “Loopix” paper used the mixnet with n1=2 and L=5\nConclusion: probability of anonymity failure decreases when increasing length and increases with increasing width\nNotes provided in the overleaf document https://www.overleaf.com/read/rybwvjftfrrg\nDiscussions on how to model the network privacy for analysis; viability of the embedded mixnet design\nNotes (WIP): https://www.notion.so/Network-Privacy-2dabf0aa878744e299b2ebb97120876f\n\ndevelopment: §\n\nMaking integration tests work with FlatOverlay and RandomBeacon:\n\nhttps://github.com/logos-co/nomos-node/pull/425\nhttps://github.com/logos-co/nomos-node/pull/426\n\n\nSome integration tests are randomly failed. Debugging them: https://github.com/logos-co/nomos-node/pull/437\nRefactoring libp2p network layer: https://github.com/logos-co/nomos-node/pull/417\nAdd missing error handlings in mixnet: https://github.com/logos-co/nomos-node/pull/436  (+ more coming soon)\nTrying to enable gathering metrics for libp2p (but needs to be discussed about how this can be used with our existing metrics service): https://github.com/logos-co/nomos-node/pull/431\nNew mixnet message handle PR: https://github.com/logos-co/nomos-node/pull/435\nQC checks: https://github.com/logos-co/nomos-node/pull/430\n\n\ntestnet: §\ndevelopment: §\n\nTreeOverlay in Nomos node:\n\nhttps://github.com/logos-co/nomos-node/pull/415\nhttps://github.com/logos-co/nomos-node/pull/423\n\n\nAfter adding tree overlay to Nomos node, integration tests started failing. Main reason was that the leader didn’t spawn in time and nodes failed to send their votes. This mainly affected the happy path test. Work will be merged once the issues are fixed.\nTestnet with mixnode: WIP\nWork on the mixnet node in testnet continues. Ongoing inter-team discussions in regards to how we should monitor and extract info from the network. The PR for libp2p metrics might be the way to go.\nCI chores: https://github.com/logos-co/nomos-node/pull/432\n\n\nprivate PoS: §\nresearch: §\n\nAdd missing function descriptions and finalize structure definitions.\nDefined/redefined structures used in all algorithms that required a rewrite.\nUpdated the terminology and made the Shadows name obsolete, and now they are called Validators (for synchronization with other PoS designs).\nThe validators logic was redesigned, improved and updated accordingly.\nThe same was with the ledger/transactions part, and now they form a complete logic.\nReadability: the specification part was updated. The rest of the document is out of sync and needs to be revised as the focus was put on the specification.\nCritical analysis: an issue was identified and described (under the issues section) that touches on a problem where insufficient number of votes are aggregated and the need for an additional voting round before commencing an overlay tree reconstruction. This can be mitigated with an additional votes collection from late voters (before the tree timeout) or increased level of votes that are collected during initial voting collection.\nReview of the Delegation and Validation rewards document by Frederico.\n\n\ndata availability: §\ndevelopment: §\n\nDissemination ready\n\nhttps://github.com/logos-co/nomos-node/pull/416\nhttps://github.com/logos-co/nomos-node/pull/400\nhttps://github.com/logos-co/nomos-node/pull/404\n\n\nMempool for certificates in progress\n"},"nomos/updates/2023-10-09":{"title":"2023-10-09 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet: §\nresearch: §\n\nDerived asymptotic expressions for anonymity and communication failure probabilities, when taking into account certain values for population size and network size. Used simulations and analytic framework to study failure probabilities in mixnets of different sizes. Assuming delays between sending and receiving messages are independent random variables from the exponential distribution, derived probability distribution of latency. Main result: one cannot have both low probability of communication and low probability of anonymity failures. The probability of anonymity failure is decreasing with the number of layers but at the expense of increasing the latency.\nFinalize research of network-level privacy solutions. Learned important information on: Framework for formalizing privacy, Nym and tokenomics of a Mixnet, Sphinx, and Loopix. Notes found at: https://www.notion.so/Network-Privacy-2dabf0aa878744e299b2ebb97120876f (summaries still WIP).\n\ndevelopment: §\n\nLock Overwatch to a specific revision in nomos: https://github.com/logos-co/nomos-node/pull/455.\nImplement and pipe services lifecycle handling in Overwatch: https://github.com/logos-co/Overwatch/pull/27.\nBash is being replaced with python due to adding mixnet to docker. At the moment, small issues with node spawning order are being resolved (for tree overlay). ETA on finishing: beginning of this week.\nAdd API to return mempool item status: https://github.com/logos-co/nomos-node/pull/449.\nMake libp2p gossipsub settings configurable: https://github.com/logos-co/nomos-node/pull/454.\nAvoid temporary gossipsub errors when bootstrapping tests: https://github.com/logos-co/nomos-node/pull/442.\n\ntestnet: §\ndevelopment: §\n\nSkeleton for nomos API service - https://github.com/logos-co/nomos-node/pull/451.\nSupport generics for overwatch derive - https://github.com/logos-co/Overwatch/pull/26.\nFix clippy warnings for rust 1.73 - https://github.com/logos-co/nomos-node/pull/452.\nRemove waku mentions from codebase - https://github.com/logos-co/nomos-node/pull/446.\nImproved integration tests.\nHandle corner cases in the unhappy path: https://github.com/logos-co/nomos-node/pull/438.\nAdd canonical ID to attestations and certificates: https://github.com/logos-co/nomos-node/pull/448.\nAdd functionalities to nomos-cli: https://github.com/logos-co/nomos-node/pull/450.\n\nprivate PoS: §\nresearch: §\n\nExploring multi-staking PPoS design for Carnot.\nIdea: a slightly modified version of PoS, unknown how much funds a single validator has and validators are grouped by the amount of stake they have. This property gives validators group-based k-anonymity, where they are indistinguishable (on the stake level). This also enables us to assign the same voting power per each group of validators, which then can be reflected on the overlay structure.\nConsidering a couple of additional stake hiding/obfuscating techniques without making the initial design too complex. We incentivize/penalize validators based not on the voting power they represent but on the stake. We can have a system that diverges from an equality between voting power and stake, to a system that approximates the voting power based on the stake but the rewarding/penalization directly follows the stake.\n\ndata availability: §\ndevelopment: §\n\nDA nomos API based on the new skeleton: https://github.com/logos-co/nomos-node/pull/456.\nAdd API to return DA blobs: https://github.com/logos-co/nomos-node/pull/453.\n"},"nomos/updates/2023-10-17":{"title":"2023-10-17 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet: §\nresearch: §\n\nFinalized the write up and summaries of the privacy network research - https://www.notion.so/Network-Privacy-2dabf0aa878744e299b2ebb97120876f (Pinned those notes that are the most important, to serve as a guidance for anyone who wants to have a quicker overview of the topic)\n\n\ntestnet: §\ndevelopment: §\n\nImproved integration tests: https://github.com/logos-co/nomos-node/pull/458\nPreparing for demo\nLifecycle handling: https://github.com/logos-co/nomos-node/pull/457\nA note on current testnet implementation. Realized that even with python code the configuration of mixnet and libp2p nodes are getting too complicated, nodes are still missing features and the glue code is not a solution in the long run. Will have more discussions.\n\n\nprivate PoS: §\nresearch: §\n\nInitial proposal for multi-staking PPoS design for Carnot: https://www.notion.so/Sketch-Approximated-PoS-with-k-anonymity-towards-multi-staking-for-Carnot-BFT-e066eb4f80114ddc862a8665aea952b6?pvs=4\n\n\ndata availability: §\nresearch: §\n\nSona polynomial commitment scheme was examined and found to be applicable to data availability. Comparisons and notes can be viewed here:https://www.notion.so/Polynomial-Commitment-Schemes-59bf8f6fe39840babe819c5c0a9628fc\nIf we continue with KZG, the method to be followed for “trusted setup” was investigated. Some methods can be found here: https://www.notion.so/Trusted-Setup-19a29ee752f14e96895328a0bd7a9634\nAdded notes on using prime field: https://www.notion.so/Notes-c4a680142a954953a2c0ea0e4b6fdcf1\n\n\nEurorust Event: §\nHere are some notes by Daniel about the event the Engineering Team attended to last weekend:\n\nFrom the ecosystem speeches we can say they are constantly making efforts on making the language mature. impl Trait in traits are coming later this year, will impact our codebase (will need some refactors). It doesn’t look like a big change but it kind of is. We use a lot of abstractions (futures + streams mostly) that force use to box everything (dynamic dispatch), that now will be statically dispatched.\nOverall keynotes and speeches were not really good. More exploratory than anything. Some of them showed tech that was mostly not relevant to us.\nGathering the team had some impact. We had some bonding on related topics that all of us enjoy. And we had some conversations that otherwise would not probably took place.\nIMO probably not worth to repeat this kind of events unless we participate in a more active way (preparing a speech ourselves and apply which I think we are totally capable of. We have a few things we could show up - Simulation app or Overwatch for example).\n"},"nomos/updates/2023-10-23":{"title":"2023-10-25 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet: §\nresearch: §\n\nSet up a calculation for the probability of anonymity (communication) failure in the mix network of a large size, sampled from a large population of nodes, such that mix network size is comparable with the node population size. The latter is the most challenging regime to analyse but potentially can give us much more accurate estimates of probabilities. Previously we have analysed regimes when mix network size is much smaller than network size and when all nodes in the network are also used in the mix network.\nNotes on “Anonymity Trilemma: Strong Anonymity, Low Bandwidth Overhead, Low Latency - Choose Two” paper provided in the overleaf document. https://www.overleaf.com/read/rybwvjftfrrg ; The latter  derives necessary conditions for anonymous communication in terms of latency, amount of noise messages and some measure of anonymity.\n\ndevelopment: §\n\nMixnet development specifications: went through the Loopix paper again - writing the draft specs: https://www.notion.so/WIP-Mixnet-Development-Specifications-807b624444a54a4b88afa1cc80e100c2 (covering the current Loopix-based implementation + Future work: cover traffic, multicasting (TBD), incentivization (TBD))\n\ntestnet: §\ndevelopment: §\n\nSave block contents to storage - https://github.com/logos-co/nomos-node/pull/464\nRefactoring for future content - https://github.com/logos-co/nomos-node/pull/461\nServices state watchers - added a first version so overwatch can await for other services signal that they are ready to work. First version using relay did not work (among other things, too complicated). Second version uses an aditional handle per service, it is morestraight forward. It may add more intricated relationship among services, and they cannot be handled/caught on runtime. Testing only for now.\nFailing services status PR: https://github.com/logos-co/Overwatch/pull/29\nWorking services status PR: https://github.com/logos-co/Overwatch/pull/30\nUpdate lifecycle handling: https://github.com/logos-co/nomos-node/pull/457\nGenerics metrics API: https://github.com/logos-co/nomos-node/pull/466\nHuman readable ser/deser for array based types: https://github.com/logos-co/nomos-node/pull/468\nUpdate libp2p breaking changes: https://github.com/logos-co/nomos-node/pull/470\nFinished mixnodes in docker testnet: https://github.com/logos-co/nomos-node/pull/467 - The testnet in docker compose is now merged and has a README. There are still  room for improvement, like spawning some nodes sequentially (like in https://github.com/logos-co/nomos-node/pull/425), but this will be solved in added in a new PRs or solved by other node improvements.\nImprovements for node config: https://github.com/logos-co/nomos-node/pull/460, https://github.com/logos-co/nomos-node/pull/471 - These changes were required for spawning nodes in testnet, will be useful for our endusers too\n\nprivate PoS: §\n::research §\n\nSingle-staking - reviewed and updated the design up to the construction section.\nMulti-staking - all comments have been addressed, but new are coming.\nRight now we are investigating a scenario where we are limiting the amount of validators in the Single-Staking case by diverging from the requirement of having multiples of validators by removing the economical incentives. In other words, we are considering to allow registering validators that have at least a threshold of stake (that is or is not capped) and a single (unitary) voting power. This way we are limiting the economical need for having multiple validators hosted by a single node, and at the same time limiting the network overhead of the single-staking design.\nThe “Delegation and Validation Rewards” document (WIP): https://www.notion.so/Delegation-and-Validation-Rewards-d4af3f87a0b240739ff99b15af11cb3f?pvs=4\nIncorporating notes in the architecture whitepapers. These readings are not as deeply technical as papers, but more about understanding the directions currently explored at the edge of blockchain architectures (namely rollups, modular architectures and intent-centric architectures).\nWorking on the problem of PPoS, one of the most critical points of focus right now, to have at least an understanding of the available options\n\nnomos::data availability §\n::research §\n\nHyrax, Dory and Dark schemes were studied, comparisons here: https://www.notion.so/Polynomial-Commitment-Schemes-59bf8f6fe39840babe819c5c0a9628fc ; It was concluded that schemes with verifier time above logarithmic are not a good option for data availability.\nFRI is a structure that should be used not for now, (at this stage especially, due to large proof size - higher than KZG), but can be used for quantum resistance in the future. Here are some sources that say this can be used in later stages (the reasons are the same as ours). - https://scroll.io/blog/kzg#user-content-fn-6 and https://notes.ethereum.org/@vbuterin/proto_danksharding_faq#Why-use-the-hash-of-the-KZG-instead-of-the-KZG-directly\n\n::development §\nnomos::miscellaneous §\n\nDavid Rusu has joined - warm welcome to him!\n"},"nomos/updates/2023-10-30":{"title":"2023-10-30 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet: §\nresearch: §\n\nAnalysis of failure probability in random partitions of networks constructed from nodes with prescribed voting “weights” - derived equations for the probability of anonymity (communication) failure in the mix network of a large size, n, sampled from a large population of nodes of the size, N, such that n is comparable with N (https://www.overleaf.com/read/rybwvjftfrrg). Analysis of these equations is currently in progress.\nSet up a model of random partitions of networks where each node has a weight (https://www.overleaf.com/read/kkmsngmcgbkj#c4de95). Derivation of probability distributions for this model is currently in progress.\nWe have agreed to put more effort into designing a fully weighted multi-staking privacy PoS design. The goal is to map the space of possible solutions (at least the subset of solutions that have been worked on and thought about lately) and their impact on the privacy, security and efficiency of the network.\n\ndevelopment: §\n\nMixnet specifications: Goals + Basic specs (implemented already) + Cover traffic - https://www.notion.so/WIP-Mixnet-Development-Specifications-807b624444a54a4b88afa1cc80e100c2\nMaking Nomos &amp; Mixnode stable for Testnet - Investigated/resolved CI failures: https://github.com/logos-co/nomos-node/pull/49\n\ntestnet: §\ndevelopment: §\n\nTest nomos demo this week!\nSimulation overlay topology info: https://github.com/logos-co/nomos-node/pull/478 and https://github.com/logos-co/nomos-node/pull/479 - to understand better how the network topology looks inside a simulation with a large number of nodes, a way to visualise the network was added\nSimulation optional network capacity: https://github.com/logos-co/nomos-node/pull/483 - after discussing potential issues for getting baseline simulation results for networks with large number of nodes, the option to disable network capacity simulation was added. Advised the DST team to drastically increase the timeout number, so that the baseline will have all the nodes participating (happy path)\nTestnet consensus layer setup: https://github.com/logos-co/nomos-node/pull/482\nCI summary for long running integration tests: https://github.com/logos-co/nomos-node/pull/484\nDiscussion about metrics service and prometheus - current http metrics service is fine, but its design is more fitting for the UIs rather than metrics collectors like prometheus. Explored this idea with libp2p (https://github.com/logos-co/nomos-node/pull/431), it seems like a good idea to have a node-wide service like node-http-api for prometheus metrics.\nFix overwatch lifecycle refactor issue: https://github.com/logos-co/Overwatch/pull/31\nSighandler service: https://github.com/logos-co/nomos-node/pull/480\nImplement da-blob API: https://github.com/logos-co/nomos-node/pull/487\nImplement storage API: https://github.com/logos-co/nomos-node/pull/488\nImplement add cert and add tx APIs: https://github.com/logos-co/nomos-node/pull/489\nIntegrate the new HTTP backend to nomos-node: https://github.com/logos-co/nomos-node/pull/490\nAdd http API to revive block contents from storage: https://github.com/logos-co/nomos-node/pull/473\nAdd API to revive DA blobs: https://github.com/logos-co/nomos-node/pull/477\nAllow deprecated type in Swarm: https://github.com/logos-co/nomos-node/pull/486\n\nprivate PoS: §\nresearch: §\n\nRewards for validators/delegators - the live document “Delegation and Validation Rewards”: https://www.notion.so/Delegation-and-Validation-Rewards-d4af3f87a0b240739ff99b15af11cb3f?pvs=4\nRead up on Zarcanum (PPoS chain), not much to get inspired from them - https://www.notion.so/Private-Proof-of-Stake-182722d1bdef4894af1d56fece334eae#b8cc6b67f7334b41930bd091458dff2b\nWeighted-BRB - https://www.notion.so/Weighted-Byzantine-Reliable-Broadcast-in-front-of-PoS-consensus-d160a930522942ac98ebf42dc7c515bd\n\ndata availability: §\nresearch: §\n\nSurvey of polynomial commitment schemes - https://www.notion.so/Mehmet-5e698a9bba5d489aa058d3a695cda12f - work in progress, but-RS+KZG seems to be the more reasonable option for data availability at the first stage.\n"},"nomos/updates/2023-11-06":{"title":"2023-11-06 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\ndevelopment §\n\n\nEnriched cover traffic specs: Notion link \n\n\nAdded a fallback for the case where mixnet fails: Notion link \n\n\nNomos integration test stabilization\n\n\nTune timeouts (by heavy debugging):\n\nhttps://github.com/logos-co/nomos-node/pull/492\nhttps://github.com/logos-co/nomos-node/pull/494 \n\n\n\nPrevent Duplicate error from libp2p gossipsub broadcasting: https://github.com/logos-co/nomos-node/pull/498 \n\n\nFix port conflict: https://github.com/logos-co/nomos-node/pull/504 \n\n\nStore CI artifacts:\n\nhttps://github.com/logos-co/nomos-node/pull/508 \nhttps://github.com/logos-co/nomos-node/pull/510 \n\n\n\nMixnet implementation improvement\n\n\nMixclient reconnect: https://github.com/logos-co/nomos-node/pull/501 \n\n\ntestnet §\ndevelopment §\n\nServices APIs:\n\nhttps://github.com/logos-co/nomos-node/pull/476 \nhttps://github.com/logos-co/nomos-node/pull/487 \nhttps://github.com/logos-co/nomos-node/pull/488 \nhttps://github.com/logos-co/nomos-node/pull/489 \n\n\nMempool aware of included blocks: https://github.com/logos-co/nomos-node/pull/485\nVoter attestation: https://github.com/logos-co/nomos-node/pull/498 \nCommunity PRs - typos:\n\nhttps://github.com/logos-co/nomos-node/pull/503 \nhttps://github.com/logos-co/nomos-node/pull/481 \n\n\nHttp API integration (Made the CI all green for the integrating PRs): https://github.com/logos-co/nomos-node/pull/490 \nChat demo: https://github.com/logos-co/nomos-node/pull/495 \nNomos node types (extract common types from nomos-node crate): https://github.com/logos-co/nomos-node/pull/496 \nNomos update for demo call: Notion link \nStatic testnet configuration: https://github.com/logos-co/nomos-node/pull/499 \nIn order to reliably expose all services when deployed, static configuration was added.\nPublic deployment of temporal nomos testnet: ⁠general⁠\nTo work out all missing pieces a temporal VPS was chosen for testnet deployment. The deployment was tested with nomos-cli app\nPreparing for testnet deployment on nomos infrastructure: https://github.com/status-im/infra-misc/issues/189 \nTo have testnet properly deployed and available at nomos.tech domain, we need to deploy it on - New API: https://github.com/logos-co/nomos-node/pull/509 \nImplement a basic version concrete error for Overwatch: https://github.com/logos-co/Overwatch/pull/32 \nRemove included  blocks from mempool: https://github.com/logos-co/nomos-node/pull/485\nDA utilities: https://github.com/logos-co/nomos-node/pull/493  \nRework consensus API: https://github.com/logos-co/nomos-node/pull/502 \nInclude block ID during serialization of carnotinfo:\nhttps://github.com/logos-co/nomos-node/pull/505  \nOpened a new issue: https://github.com/logos-co/nomos-node/issues/506 \n\nprivate PoS §\nresearch §\n\nMulti-staking - prepared a discussion doc drafting a couple of ideas such as: how we can hide stake/voting power using homomorphic encryption and the consequences of that approach. The bottom line is that with Carnot and its tree structure we cannot follow the generic Proof of Stake approach and hide the voting power at the same time. We need to modify the Proof of Stake to follow the number of votes rather than the voting power during the vote aggregation phase. This modification bears consequences that need to be studied carefully, as the probability of a failure or liveness issues might be higher: Notion link \nRich Nodes Attack on Weighted Carnot worked out an attack that any private weighted-Carnot protocol will need to overcome: Notion link \nPrivate Weighted Voting w/ Ring Signatures a solution to the above attack that relies on ring signatures to break the connection between a vote and voter: Notion link \nFrom discussions on the above docs, started accumulating a summary of which behaviors to reward or penalize: List of Rewarded and Penalized Actions: Notion link \nDerived a probability distribution for the weights of committees for a scenario  when weights of nodes, modeled as random variables, are sampled in every voting round.\nA derivation of a probability distribution for a scenario when weights of nodes are only sampled once (currently in progress).\nWrote a simulation code which would  allow us  to compare failure probabilities in the above  two scenarios with the (unweighted) original Carnot version.\nDetails for probability distribution for the weights of committees for a scenario when weights of nodes, modeled as random variables, are sampled in every voting round, are provided in https://www.overleaf.com/read/kkmsngmcgbkj#c4de95 \nRewards for validators/delegators: the live document Notion link \nResearch notes on rewards for validators/delegators: Notion link \nList of Rewarded or Penalized Actions: Notion link \n\ndata availability §\nresearch §\n\nFinished the survey on the polynomial commitment schemes: Notion link  \nPCS related libraries were examined. The structures and benchmarks used were reviewed. Resources related to this were added to the research notes above. \nThis work in particular is a nice compilation:https://xn—2-umb.com/23/pc-bench/ \nStudied on EC+Commitment data structures. 1D or 1.5D structure may be more suitable for data availability within the scope of the Nomos project: Notion link \n\ndevelopment §\nmiscellaneous §\n\nNomos team will be at the offsite next week.\n"},"nomos/updates/2023-11-13":{"title":"2023-11-06 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nAnalysis of failure probability in random partitions of networks constructed from nodes with prescribed voting “weights”:\nConsidered a scenario when weights and Byzantine labels of nodes are sampled once, i.e. fixed, and then assigned to committees randomly.\nA derivation of a probability distribution for the random process is currently in progress\nConsidered designing a gradient descent algorithm which, given weights and Byzantine labels of nodes, tries to find assignments to committees with the smallest number of failures.\nAnalysis and implementation of the above algorithm is currently in progress. -reviewed literature on analysis of Loopix mixnets and implemented code for a simulation which computes fraction of de-anonymized messages.\nThe details on all of the above are provided in https://www.overleaf.com/read/kkmsngmcgbkj#c4de95\nWalked through core parts of Nym implementation again to get details of what are written in papers.\nClarified sphinx packet creation process (+ encryption): https://www.notion.so/Mixnet-Specification-807b624444a54a4b88afa1cc80e100c2#d0bbc9d1f63e43faaa30bb4c888102bd]\nClarified delay calculation in Poisson distribution (inspired to Nym impl): https://www.notion.so/Mixnet-Specification-807b624444a54a4b88afa1cc80e100c2?pvs=4#3ae7e03fcbad461ab8d6b57e5c0e88fe\nClarified loop cover traffic creation &amp; interval in Poisson (inspired to Nym impl): https://www.notion.so/Mixnet-Specification-807b624444a54a4b88afa1cc80e100c2?pvs=4#14f53c5d6c844c828689f0412d5e2195\nSuggesting skipping two other types of cover traffic (at least, for now)\nDrop cover by nomos-node: https://www.notion.so/Mixnet-Specification-807b624444a54a4b88afa1cc80e100c2?pvs=4#76993c1312ea464a88557987a2f37b60\nLoop cover by mix-node: https://www.notion.so/Mixnet-Specification-807b624444a54a4b88afa1cc80e100c2?pvs=4#f07a473a4b5d4f338ff024a145f6b525\n\ndevelopment §\n\nNomos integration test stabilization: https://github.com/logos-co/nomos-node/pull/533\nMixnet implementation improvement\nFixed the concurrent packet handling in Mixnode: https://github.com/logos-co/nomos-node/pull/530\n\ntestnet §\ndevelopment §\n\nPublic deployment of Nomos testnet on nomos.tech infra: ⁠general, https://github.com/status-im/infra-misc/issues/189, https://github.com/logos-co/nomos-node/pull/513, https://github.com/logos-co/nomos-node/pull/520, https://github.com/logos-co/nomos-node/pull/524\nThe hardware and automation done and already running a master branch of our docker compose testnet. New tasks will be created for improving metrics, logging and stability, but this is a big milestone as we are now in control of this environment.\nPrometheus with new http api: https://github.com/logos-co/nomos-node/pull/522, https://github.com/logos-co/nomos-node/issues/523\nA proposal for metrics collection using prometheus, this will enable us to see what’s happening in the node network easier.\nSimulations finalization times debugging: The issue when views are advanced faster than they should in simulations remains, the ability to remove all network constraints didn’t resolve the issue. I still don’t know the main reason for it, hopefully this week we’ll have a breakthrough in this regard.\nFixed an issue with nomos-cli api https://github.com/logos-co/nomos-node/pull/525\nAdd options to provide custom writer for log https://github.com/logos-co/nomos-node/pull/518\nDisable logs https://github.com/logos-co/nomos-node/pull/517\nRemove process::exit(1) from library code https://github.com/logos-co/nomos-node/pull/516\nLimit carnot/blocks response size https://github.com/logos-co/nomos-node/pull/515\nDo not use 0x prefix in serialization https://github.com/logos-co/nomos-node/pull/514\nIdentified https://github.com/logos-co/nomos-node/issues/526\n\nprivate PoS §\nresearch §\n\n“Delegation and Validation Rewards” doc update: https://www.notion.so/Delegation-and-Validation-Rewards-d4af3f87a0b240739ff99b15af11cb3f?pvs=4\nMulti-staking: The discussion doc was discussed and we have decided that the complexities mentioned in the document are currently out of the scope.\nPrivate Leader Election: During the week it become more apparent that the private voting design is not a priority and we have decided to design a (general also multi-staking compatible) private leader election mechanism that is based on the single-staking design. The output is documented here: https://www.notion.so/Private-Leader-Election-for-Carnot-PoS-e720168ff3c44d098ec6a4aa586188da?pvs=4\nExplore interesting lines for PPoS:\n\n\n\n[Automatic Persistant Validator Identifier from Public Staking Transactions](https://www.notion.so/Public-Stake-Value-w-o-a-Persistent-Identifier-62a3237b97d44b87924ba3fff74f0362?pvs=4 “Automatic Persistant Validator Identifier from Public Staking Transactions)\n\n\nSingle Staking w/ Network Tricks\nFailed attempt: Hashed and Salted Stakes\nIs Network Privacy enough for PPoS\n\n\n\ndata availability §\nresearch §\n\n\n\ndevelopment §\nmiscellaneous §\n\nNomos team will be at the offsite this and next week (ends of 2023-11-23).\n"},"nomos/updates/2023-11-27":{"title":"2023-11-27 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Offsite §\n\nSummary of the offsite (daily): https://docs.google.com/document/d/1qJ_hP2FA7P3kB5TNi-tkFaWGmqlP8tZd9RC1dAlU5kw \nCarnot in a Privacy Setting under Mixnet Assumption: https://docs.google.com/document/d/1fICGvSkTCgvk879uaapzFzy6Qbzz6VkXX0lL_iJ8GJo\nPPoS + Carnot discussion - why Carnot will not be used for the base layer, exploring combinations of different approaches as well as a potential solution for fully private base layer\nMixnet: numerical experiments were conducted - more details here: https://docs.google.com/spreadsheets/d/1MaSBbfUGmJniILPvcQLxtyXqjBExUUEB6C2-YWNP6uI/edit#gid=0 \nData Availability: exploring cryptography, deciding on base layer structure, looking into super commitments, proving schemes.\nConclusions and next steps as a team for the implementation of the Nomos 1.0 Base Layer.\nFilmed presentation: Preliminary Privacy Analysis https://drive.google.com/file/d/1mrNWdJMX_WneUFNmHJn316uLrPXkBbMH/view?usp=sharing \nFilmed presentation: Last day summary PPoS - https://drive.google.com/file/d/1DlDi3bWglIRR3nJ6owjLemQSy9YiRSZY/view?usp=sharing \n\nPrivate PoS Tokenomics §\nResearch §\n\nValidator rewards function - https://www.notion.so/Delegation-and-Validation-Rewards-d4af3f87a0b240739ff99b15af11cb3f?pvs=4 \nSimulation results: https://github.com/logos-co/token-economics/blob/nomos-linear-reward-function/Nomos/multi_staking_rewards/linear_reward.ipynb**\n"},"nomos/updates/2023-12-04":{"title":"2023-12-04 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nProgress on the Mixnet implementation specification, with particular emphasis on integration on the rest of the system.\nDiscussing and analyzing possible strategies for cover traffic specially tailored to the consensus algorithm.\n\ndevelopment §\ntestnet §\ndevelopment §\n\nMerged Prometheus metrics service\n\nprivate PoS §\nresearch §\n\nWe consider leader election in PoS observed over some period of time by an adversary who wants to learn its stake with high “accuracy” and high “confidence”.\nFor the probability of stake greater than some threshold derived rigorous lower and upper bounds on this probability.\nFor the same probability considered an asymptotic long-time regime and developed a mathematical framework for this regime. \nVerification of above results by simulations is in progress. \nThe above will be a part of the  framework which will be used to get a more accurate estimate of the number of layers which are required to reduce anonymity failures in the mixnet. More details provided here\nAnalyzed how stake splitting affected leader rates in Crypsinous: Stake Splitting in Praos\n\ndata availability §\nresearch §\n\nDesigned a new super-commitment structure and explained it here. After some discussions, we agreed that  prover cannot temper the column entries by adding and subtracting some values but he can reorder the column entries. The proof does not guarantee column ordering. Solution methods for this were discussed, but since the focus was on a different structure design, this development was postponed for now.\nThought of a different design and explained it here. The main idea of the design is to take a commitment of commitments. As a result of the investigations, the structure is thought to be working. Cryptographic proof will be worked on.\nThe newly designed structures were compared with these existing schemes. It is thought that our current design will provide the whole advantages of Avail.\n\ndevelopment §\n\nContinuing DA mock implementation - splitting it into reviewable parts\n1D benchmarking\n\nmiscellaneous §\n\nThe Whitepaper now contains a whole new section on Light Nodes.\nCarnot’s role in Nomos has been updated.\nExplanations about privacy have been expanded and adapted to include the notion of resiliency.\nAdded other sections, like Multiple Base Layers and others related to Light Nodes.\nAdded new diagrams\n"},"nomos/updates/2023-12-11":{"title":"2023-12-11 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nCrypsinous over Mixnet  contains the summarization of investigation into how Crypsinous will work in combination with the Mixnet\nIn the development section below, we will go into further into details in terms of how this researched affected the specification.\nThe discussions are still open and the specification is still prone to change.\n\ndevelopment §\n\nUpdated the Mixnet Specification according to the new research and analysis in the Crypsinous over Mixnet document. The gist of the document update is that every node emits real/cover packets with a rate in a Poisson distribution.\n\nA slot leader publishes 3 block proposals and several drop cover packets within a slot (a slot is published every 20s)\nAt that time, all of the other nodes emit only drop cover packets (“decoys”) within a slot.\nThe target mean packet delay is 2s.\nBased on this:\n\nDefined a packet emission mechanism\nRefined a packet delay calculation\nDefined a cover traffic strategy\n\n\n\n\n\ntestnet §\ndevelopment §\n\nNo updates\n\nprivate PoS §\nresearch §\n\nResearching on a potential problem of wealth concentration in the token engineering model that was reported by DarkFi since it contradicts the results we have calculated in the Validation Rewards\nPerformed additional research in terms of feasibility of learning total stake: the problem here is that we cannot compute relative stake based on what is the Crypsinous paper.\n\nTherefore we came up with Dynamic Lottery Function Difficulty adjustment\n\n\nRefined rigorous lower and upper bounds on the probability of stake greater than some threshold, i.e. “confidence”. The details can be seen in Notes on mathematical and statistical aspects of proof of stake consensus mechanisms\n\nThe upper bound was only available for prob. 0.9 and higher and a new version also allows for lower prob.\nThe latter is needed for a more accurate estimation of the number of layers in the mixnet.\nThe asymptotic result for the same probability also can be used only for higher values and extending this result for lower values is currently in progress\n\n\n\ndata availability §\nresearch §\n\nWriting of the new protocol specification complete - it is still open for discussion - comments and proposals with valid reasoning can still adjust the specification - anyone can comment.\nFor the historical records, the trail of thoughts, scenarios and improvements can be seen here.\nThe new specification was also looked at by the Nescience team - it has no cryptographical weaknesses.\nImplementation expected to start at the beginning of January.\nIn the future, we will evaluate additional Data Availability structures (based on internal literature) to see how they compare to what we have.\nthe DA node read/write API implementation is in progress - we have reviewed and reevaluated the initial plan to implement DA data dissemination and retrieval flows and created an action plan based on that.\n\ndevelopment §\n\nWe have performed simulations to confirm there will be no “flatness” issues with Carnot implementation.\nWe are currently in the process of finalizing the Carnot paper - the simulations action plan will also be shown there.\nFound additional proofs that simulations and rust Carnot implementation acts as expected in varying committee overlays - more info on Discord.\n"},"nomos/updates/2023-12-18":{"title":"2023-12-18 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nContinuing the research on the effects of wealth concentration within Ouroboros Crypsinous - more precisely fixing some of the code and running simulations. The results and reports will continue to be provided in the Notion doc.\nAlso, doing additional research into the Darkfi’s Crypsinous implementation (and why they are striving away from it)\nMixnet specification is done, currently in review - once additional comments have been added, will provide new updates\nThere have been some slight improvements in the Crypsinous over Mixnet document - not too major\nCompiled a high-level overview of the Ouroboros family\nStudying byzantine gossip and swarm consensus as part of the effort of solving the tagging attack problem (as alternatives to random subsampling and reliable broadcast) - some of the ideas involve the use of gradecast over byzantine gossip, but providing more details in the following week.\n\ndevelopment §\n\nSolved [an issue](https://github.com/logos-co/nomos-node/pull/544](https://github.com/logos-co/nomos-node/pull/544 ”https://github.com/logos-co/nomos-node/pull/544)  that was causing problems with simulations (Carnot 10k nodes - Tree implementation returned different results when searching for child committee and then using child committee to find its parent)\nBy fixing the above and the depth calculation in the analysis script, the simulations stall  has been fixed totally, and we are meeting in the deadlines in terms of releasing the Carnot papers - no additional showstoppers\n\ntestnet §\ndevelopment §\n\nNo updates\n\nprivate PoS §\nresearch §\n\nNormalize stake for lottery - we have a proof of convergence to expected fixed point and stability conditions for that fixed point: Analysis Summary\nWe’ve run simulations of the process and they confirm the stability conditions and convergence derived analytically (above)\nThere is still work to be done in terms of slots observation to understand a good measurement of leader rate as well as some additional confirmation of the analysis\nAnalysis of stake de-anonymization (details are [here](https://www.overleaf.com/read/xvgmfchdhgzh#acd15d](https://www.overleaf.com/read/xvgmfchdhgzh#acd15d ”https://www.overleaf.com/read/xvgmfchdhgzh#acd15d) and here): and here)\nUsed the lower bound (LB), asymptotic estimate (AE) and upper bound (UB) on the probability of stake greater than some threshold (“confidence”), within a given “accuracy”, to estimate the number of layers in the mixnet.\nThe UB (on the number of layers) is loose. The AE (for the number of layers) is close to the LB (on the number of layers), suggesting that LB is closer to true values (AE is in very good agreement with simulations). However, AE is only available for “confidence” higher than 0.6 and some “accuracies”\nFor the currently used lottery function, derived the maximum likelihood estimator of relative stake. The latter can be used by an adversary to infer the relative stake of a node\nAnalysis of fraction of compromised paths is currently in progress and more details will be provided in the following weeks\n\ndata availability §\nresearch §\n\nContinuing on the process of comparing different DA structures - the comparison can be found [here](https://www.notion.so/Comparison-of-DA-Structures-WIP-47350a408cbd4d8db545527b7a598ccf](https://www.notion.so/Comparison-of-DA-Structures-WIP-47350a408cbd4d8db545527b7a598ccf ”https://www.notion.so/Comparison-of-DA-Structures-WIP-47350a408cbd4d8db545527b7a598ccf) . Right now we are comparing Merkle Tree, RS+KZG and Merkle Tree+Snarks - based on the literature at the bottom of the aforementioned document.\nThe parameters we are currently comparing are proof size, prover time, verifier time and commitment size, but in terms of theoretical examples, not actual benchmarks.\n\ndevelopment §\n\nThe new read/write DA API is still in progress - there are conversations ongoing which can be seen in the draft PR\n\nmiscellaneous §\n\nThe architecture whitepaper is awaiting feedback and expected to be finalized in the first week of 2024 - the paper can be found on Discord\n"},"nomos/updates/2023-12-25":{"title":"2023-12-25 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nUsed bounds and asymptotic analysis to create a new version of the table (see  this for reference) which estimates the number of layers needed in the mixnet protecting the network layer. The latter assumes a very simple lottery function where the probability of winning is equal to the relative stake.\n\ndevelopment §\n\nNo updates\n\ntestnet §\ndevelopment §\n\nWe are experiencing an issue with the file system on metal-01.he-eu-hel1.nomos.misc entering a read-only state. This is preventing any write operations on the system, impacting normal operations and services.\nNomos node stability investigation - found a main reason for tesnet failing after some time, consensus engine has some asserts that are not met during the run. I’m trying to replicate the same behaviour in integration tests.\n\nprivate PoS §\nresearch §\n\nA consensus reference page has been written detailing the path and the history of decisions made as a context to the other documents we have provided. It is important to mention that this is a living document that might be updated further in the future.\nUpdated the ongoing document of DarkFi Crypsinous implementation with new details.\nSummarized the findings and ideas from different papers around byzantine gossip and consensus. There are some ideas that might be useful to us in the future.\nFor the Crypsinous lottery function analyzed the maximum likelihood (ML) statistical inference framework. The latter can be used by an adversary for inference of stakes of nodes to infer relative stake. Formally the ML framework suggests that observations of election statistics of all nodes are required in order to infer relative stake of a single node. However, for long time observations there is a possibility that statistics for a single node are sufficient to infer its relative stake. The analysis of this scenario, which uses a “naive” estimator of relative stake, is currently in progress.\nNormalize stake for leader lottery: Summary with plots and equations can be found here.\nWe have a new analytical tool for analyzing the average of our process for learning stake, it lets us study how the process converges without the slow simulation runs and makes analytical work much simpler.\nWe found that our process for learning D will underestimate true total stake by up to 3% (depends on our choice of constants), we have some analytical bounds on the underestimate and confirmed them with simulation.\n\ndata availability §\nresearch §\n\nFinished the comparison article of DA structures (Merkle Tree, RS+KZG and Merkle Tree+Snarks) and reach the conclusion that the structure we designed is flexible. We can easily switch to the Merkle tree + Plonky2 structure in the future.\nSome additional research notes in terms of DA comparison can be found here.\nSkimming through NOTRY: Deniable messaging with retroactive avowal to check if there is anything interesting to us\n\ndevelopment §\n\nNo updates\n\nmiscellaneous §\n\nArchitecture whitepaper will be reviewed internally by the team in the following weeks.\n"},"nomos/updates/2024-01-08":{"title":"2024-01-08 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nThe Mixnet specification doc has been updated with new details after a discussion was help in terms of establishing connections in advance - Whenever a Mixnet topology is reconstructed, each mix node in the layer l establishes connections optimistically with all mix nodes in the layer L+1 , in order to reduce the latency of individual packet delivery - more details in the relevant comments in the linked Notion doc.\n\ndevelopment §\n\nNo updates\n\ntestnet §\ndevelopment §\n\nIncreased the storage limit in addition setting up firewall rules for the Nomos http ports - they are set in the same range for containers and host - more details here.\nOpened TCP ports 18080-18083 for HTTP - more details here. Also opened some additional ports\nAdded missing configuration and fixed conflicting rules for ports: Limit number of committed blocks in info requests - more info here; Receive blocks blobs in parallel - more info here; Set and get blocks tip without filtering - more info here.\nOptimized consensus related methods, the changes allow node to run without problems on a testnet: CI - more work in progress (in terms of DA specification)\n\nprivate PoS §\nresearch §\n\nAfter trying 6 attempts, we had a breakthrough in understanding variance of our learning process around the fixed point: this latest method shows very good agreement with simulation across the full parameter space that we tested - This sets up to answer some of the burning questions we have had for a while (How big should T be, how small should delta be, how fast does this converge).\nWe came up with a good measure of “centrality of stake”, this has allowed us to do much more informative simulations across the parameters that matter: More detailed update with plots in Notion: 2024-01-08 Progress\nAnalysis of total stake inference problem: the analytical framework, derived for the algorithm which uses Crypsinous lottery function stochastic process to estimate the total stake, was used to construct the simplest possible theory which describes expectation and variance of the total stake statistical estimator.\nSeveral approaches were tried, including mapping to the physical thermal relaxation process, but explained simulations but only for a  limited scope of parameters.\nThe latest approach, which uses large stake expansion, leads to simple theory  with a small number of parameters which explains simulations quite well. More details here.\nLarge numbers of validators issue has been documented - something that Carnot doesn’t solve implicitly - more details here.\n\ndata availability §\nresearch §\n\nWe have made a new design - the 2D Data Availability Structure based on a problem whether the execution zones perform the RS-encoding process correctly; it has been solved accordingly but it is costly due to the size of the data - more studies to come.\nThe protocols we have examined and also designed so far were compared on relevant data. Detailed information can be viewed here. Additionally, the total data size can be accessed by entering the data size and number of nodes here\n\ndevelopment §\n\nNo updates\n\nmiscellaneous §\n\nArchitecture whitepaper is being reviewedg.\nShared sequencing - compiled notes on some of the implications, architectural designs, discussions, inspirations and more, in an article here.\nNotes on the MTR Declaration of Decentralization provided [here](https://www.notion.so/Filip-8b260c1bfddd43cc9cd1211478be53e8 here- It is in an interesting proof of value approach (mix of PoS on main chain with a sidechain Relay/CER for the PoW, merged every sidechain’s 30 blocks), that they are utilizing, but I think that it has too many holes to fulfill - risks and attack vectors. Even though the ecosystem has been live for a couple of years, it never reached the heights they apparently planned. They focused too much on becoming “big” rather than building up from ground zero. However, the interesting design choice is their utilization of sidechains (more precisely their adaptors and connectors) in the attempt to connect to other ecosystems. The paper didn’t provide too many details about it though.\n"},"nomos/updates/2024-01-15":{"title":"2024-01-15 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nNo updates.\n\ndevelopment §\n\nRefined Mixnet specs: Decided to use libp2p even for direct QUIC connections for v1, so that we can use peer discovery and NAT traversal later on; Defined an initial approach to report on unresponsive mix nodes, though it should be improved later; Simplified the specification of using Sphinx packets, by abstracting the internal Sphinx spec ;Updated the calculation of lambda and mu by suggesting a refined approach of emission rates; Decided to start with only mixnode-defined delays.\nThree quarters of mixnet python specification code has been done; since it has been decided to move Sphinx out of the mixnet specs(see comments) - it will be moved to a new repo in order to be utilized properly; the basic structure and topology construction and Sphinx packet builder have also been added.\nResearch of QUIC and QUIC connections - what is available and what is the difference from the TCP connections\n\ntestnet §\ndevelopment §\n\nInitial node metrics PR has been merged - to reiterate, this will add metrics service + initial metrics for CL and DA mempools. We will continue the effort to collect data about other services in the coming weeks.\n\ncryptarchia §\nresearch §\n\nThe Private Proof of Stake milestone has been renamed to Cryptarchia in order to better reflect current work.\nUpdated the living document that showcases if the leader election function leads to wealth concentration - more precisely the stochastic fork choice rule - which seems to ignore the validator stake.\n[Analysis](https://www.overleaf.com/read/fzbrxvkwwscq#f2907c](https://www.overleaf.com/read/fzbrxvkwwscq#f2907c) of total stake inference problem: For the statistical estimator of the total stake D, the results of a large stake expansion were used to derive Gaussian approximation for the distribution of D. The latter was used to define “confidence” and “accuracy”. The large stake expansion was used to study other important properties, such as convergence rate of inference algorithm, and provides a relatively simple and compact set of relations between different parameters, such as number of nodes N, learning rate h, number of epochs T, stake mean and stake variance\nWe were able to answer most of the open questions (from previous weekly - remaining is analytical grounds for fast convergence) - How big should T be (# of slots in an epoch), How small should h be , How fast does this converge.\nWe have a general solution to the total stake inference problem - based on this document we have a good understanding of Accuracy, Convergence Rate and Stability.\nWriting of the Cryptarchia specification is well underway - you can check the latest version here.\nReviewed Ouroboros Praos, the focus was to understand the whole design and put a bit more attention at the design of the random beacon and some security assumptions. More on that in the notes.\n\ndevelopment §\n\nThe Cryptarchia development plan initially stated is still valid and has been updated. We will have the first milestone defined soon as well.\nRefactor consensus engine in preparation for adding a new consensus - PR.\n\ndata availability §\nresearch §\n\nThe DA Layer Comparison table has been finished and is currently in review and update phase. For the raw data, refer to this Google sheet\nBlock format specification has been added.\nDA API specification has been added.\n\ndevelopment §\n\nMerged a couple of small fixes for the nomos-chat app - more details here.\n\nmiscellaneous §\n\n3 interrelated topics that have the potential to create an interesting element of differentiation have been researched: turning Execution Zones into Plasma chains with ZK proofs (findings), solutions for instant deposit/withdrawal, solutions for ZK-bridging with the Base Layer (basically the CL layer, but as minimal as possible).\nPolygon Avail has been researched - findings.\nSimulations working principle (the Carnot paper Appendix) has been added.\nWhitepaper feedback review in progress.\nCarnot paper has been reviewed.\n"},"nomos/updates/2024-01-22":{"title":"2024-01-22 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nOne of the last pieces of the mixnet specification: “Defining topology update and entropy injection in a clear way” - we are close to a solution and will include new findings next week. To see the current proposal and differences being discussed (for example architecting the consensus and mixnet interaction) please check the GitHub PR. Code review is also in progress.\n\ndevelopment §\n\nTested libp2p stream protocol for the mixclient-&gt;mixnode and mixnode-&gt;mixnode communication. Concluded that’s very simple and appropriate for our case because it’s the fundamental protocol that is used for other libp2p protocols such as DHT. That’s basically not very different from the naive communication implementation over QUIC or TCP.\nCompleted several PRs (with code-review as well) Topology, Sphinx packet construction, Packet delays, Mix client Poisson emission.\nDesigned the updated Nomos Rust project structure for mixnet v1.\nAnalyzed the rust-libp2p QUIC transport in terms of configuration and implementation details.\n\ntestnet §\ndevelopment §\n\nRemoved the async-trait from the node as well as Overwatch.\nGrafana and related services addition to the testnet (new PR).\nPreparation for demo chat app bot, ability to send data from file, non-interactively (new PR).\nPrune Carnot old block PR has been completed and is currently in review.\nAdded a test for big blobs dissemination.\nLimited the number of in-flight requests performed by the chat app to avoid using too many descriptors - more details here.\n\ncryptarchia §\nresearch §\n\nUpdated the wealth concentration analysis with the new [chapter](https://www.notion.so/Does-Crypsinous-Leader-Election-Function-lead-to-wealth-concentration-in-PoS-b81f07a791b745438443f51f00ac258f?pvs=4#1df422f6cc204cb8b362f41cda260b8b about stake relativization algorithm. The section about known total stake is also in progress.\nStake relativization specification is complete.\nSet up an analytical framework which will be used to study the impact of using the (biased) total stake estimator on the leader election process. The central object of this framework is the joint probability distribution of two copies of the election process with the same (random) sampling noise, the same stake but different values of the total stake.\n\ndevelopment §\n\nNo updates, heavily in research.\n\ndata availability §\nresearch §\n\nDA API specification is written (likely to change due to active discussions).\nDA Layer Comparison article is almost finished - there are several comments still left to be resolved. Protocols were explained in more detail. Tables have been updated and to see the raw updated data on its own refer to this sheet.\n\ndevelopment §\n\nDA implementation plan is written (with active discussions it is likely to change).\n\nmiscellaneous §\n\nDevised a plan to take action for Nomos marketing and comms strategy: devised a couple of WIP docs (strategic one and mission one). We will start compiling our resources to help out the comms team with “ammo” for the Twitter and other social media.\nCarnot paper is currently being reviewed. Team feedback collected, several issues (for example of administrative and legal nature) were raised and will be addressed.\n"},"nomos/updates/2024-01-29":{"title":"2024-01-29 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nThe Mixnet specification is ready for review and can be frozen with the current version for v1 (until we find additional requirements during the implementation).\nDefined the mixnet topology update mechanism as a result of internal team discussions - conclusion: we should abstract a robustness layer that will handle mixnet configuration.\nRedefined mix destination: Instead of having an extra hop to the mix destination after L layers, we’re going to use the last mix layer as the mix destination (for message reconstruction).\nAlso, the problem of the common view of candidate nodes for mixnet participation was raised - how to ensure that the whole network will know which mixnodes are selected. As previously discussed, we confirmed that we need to have a dedicated staking action for registering candidate mixnet nodes on-chain - the sampling will be performed only from the list created by that staking action.\nThe PRs that entail the changes and piece them all together in the executable mixnet specification can be found here and here.\n\ndevelopment §\n\nAdded a couple of PRs in preparation for the mixnet rust development - crate structure, remove mixnet legacies 1, and remove mixnet legacies 2.\n\ntestnet §\ndevelopment §\n\nStarted the document on the design of Block Explorer 2. Also, added a PR regarding naive blocks query implementation from the storage layer (the PR is still open with an ongoing discussion).\nAdded a testnet basic bot to the chatapp non-interactive mode (PR). In more detail, we have previously added the ability to disseminate a file to the DA in the testnet, and we updated the chatapp with a similar functionality, which is used to have a bot that constantly pushes readable data to our DA in the testnet. This data (as opposed to file upload) will be readable by our testnet users and will be useful during the demos.\nContainer for the basic bot PR - performed some required changes to our testnet infrastructure.\n\ncryptarchia §\nresearch §\n\nUpdated the wealth concentration analysis chapter about stake relativization algorithm.\nStarted the Nomos Tokenomics Design Canvas that will be filled in with additional details in the future.\nWe have discussed an alternative path for the leader election function (stake relativization) in the. Refer to this comment for more details. This helped answer a high-priority question: Do we need to learn total stake?\nThe initial version of the Cryptarchia executable specification PR has been merged.\nAdded fork choice rule to the Cryptarchia executable specification.\nMerged implementation of slot leader election check to the Cryptarchia executable specification.\nAnalysis of Impacts of Approximate Total Stake - having considered two alternative election histories of a node (one when using the true stake and the other when using the approximate stake), the population study shows higher staked nodes are more impacted by errors in estimating total stake. Also, impact on the finality study shows high sensitivity to overestimates of stake. This was done by deriving the analytic expression for the Hamming distance between the two aforementioned histories which allows quantifying differences - for the detailed analytic work, refer to the Overleaf document.\n\ndevelopment §\n\nNo updates, heavily in research.\n\ndata availability §\nresearch §\n\nDA Layer Comparison article has been updated according to the latest review. In addition to that, we also provided details about the Ethereum Danksharding Protocol and its comparison to the Nomos DA protocol (according to our research).\nVID Certificate section in the DA API Specification has been added. In it, we explained the steps required to create VID Certificate and their order, described what data is sent to different participants (Nomos Zone, DA Node, Block Producer). We have reviewed it internally and added some new questions and comments - refer to the discussion for more details.\nBased on the definitions from the VID certificate, revised the Block DA Metadata structure with some minor updates, more precisely with the data that should be written in the block for DA.\n\ndevelopment §\n\nNo development updates.\n\nmiscellaneous §\n\nFinalized v0.5 of the darkpaper: updates according to feedback and new insights and strategy: rewritten several sections and eliminated a bunch of sections that were not satisfactory. Some changes of the darkpaper are conceptual, not just cosmetic, improving the strategical focus.\n"},"nomos/updates/2024-02-05":{"title":"2024-02-05 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nPolishing the mixnet specification regarding the topology algorithm and all parameters - we’ve had some concerns about it, so there are several ongoing discussions on Notion and GitHub in regards to answering them. For more details on the discussion, check this PR.\nWhile it has been postponed from v1, we will have to define the mix node identity soon for incentivization.\nAfter careful consideration and discussion, the topology update and public APIs PRs for core logic have been merged.\n\ndevelopment §\n\nAdded a utilities function of python mixnet to rust PR. Currently in review.\n\ntestnet §\ndevelopment §\n\nAdditional polishing (route separation) of the Naive blocks query implementation from the storage layer PR.\nAdded DA API for Explorer, while removing the unused API PR - currently in review.\nIntegrated the block explorer into the demo. Currently thinking about writing integration tests for it.\nTestnet fixes PR: the testnet ran on Linux with no issues; however, several fixes were needed for it to work on MacOS (about Grafana, Nomos chat bot params, and Nomos chat OpenSSL libs build version).\n\ncryptarchia §\nresearch §\n\nUpdated the wealth concentration analysis chapter about the stake relativization algorithm - specifically about the impact of the stake relativization.\nUpdated the Nomos Tokenomics Design Canvas with details about the “Validators” role. More roles to be entered in the coming weeks.\nAdded the fork choice rule PR as described in “Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability”. Tests will be added later.\n“Follower maintains ledger state as it follows the blockchain” PR. Leader coins are now spent when they become slot leaders. The next step is to have the leaderproof produce a new coin that the validator can then use to lead another slot.\nMerged the “Add header ID and message” PR.\nSummarized the mathematical analysis work in the Impact on Forks chapter and Reducing Forking chapter. More precisely, derived the probability of the “forking” event and the “empty slot” event when the approximate value of the total stake is used. Considered the large total stake and finite number of slots scenario to derive the typical number of forks and empty slots expected in the T number of slots. This framework was used to assess impacts of underestimation/overestimation of the total stake on the number of forks and empty slots. For the detailed mathematical analysis, check the Overleaf document.\n\ndevelopment §\n\nNo updates, heavily in research.\n\ndata availability §\nresearch §\n\nDA Document has been updated with new details based on the team review (specifically around adding more details about Ethereum Danksharding).\nMerged a mandatory PR containing a big chunk of primitives from the ETH specification that’s a dependency for building our DA specification. It will help us save a good amount of time during our implementation (and testing) of everything.\n\ndevelopment §\n\nStarted work on the DA Layer Implementation Details document. This is a an executable spec.\nThe sketch of the DA layer can be seen in this branch.\n\nmiscellaneous §\n\nThe website’s copywriting has been updated to reflect the changes from the Darkpaper.\nStarted publishing posts on X.\nWe have chosen several articles and will be publishing more detailed, scientific blog posts in the coming weeks. Once the specifications are complete, they will also be communicated via our social media.\nDarkpaper v0.5 published internally.\n"},"nomos/updates/2024-02-12":{"title":"2024-02-12 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nStarted the investigation of the mixnet participation problem. We have looked at Nym and how they constructed a mechanism for populating the mixnet. We extracted the design and described it in detail here. In short, they require the mixnet nodes to register on-chain; once there, they are randomly selected using weight as stake (plus delegated stake), and rewards are paid based on the mix node performance.\n\ndevelopment §\n\nNo development updates.\n\ntestnet §\ndevelopment §\n\nFixed the race for nomos log service PR.\nNomos-cli: Integrated the explorer into the nomos-cli in one PR with the integration tests coming in another one once it is unblocked (blocked due to the sled dependency).\n\ncryptarchia §\nresearch §\n\nNew details have been added to the Cryptarchia specification: the epoch transition, nonce specification, orphan proofs validation, leader lottery VRF details, leader coin evolution. With these additions, the Cryptarchia v1 is now ready internally.\nThe impact of approximate total stake (total stake underestimation/overestimation) document has been finalized and summarized. Awaiting internal review. For the mathematical analysis and results, please check the Overleaf document.\nWe have considered adversarial statistical inference of relative stake when the Ouroboros Crypsinous lottery function is used in the leader election process while assuming that only a fraction of election results are observed. For this scenario, we also derived a statistical estimator of relative stake. The analysis of the (naive) statistical estimator is currently in progress. The summary of this work is provided here while the detailed analysis can be found here.\nTokenomics Design Canvas has been updated with new objectives &amp; requirements in addition to new sections.\nAdded a chapter about the “stake relativization algorithm” to the “Does Crypsinous’ Leader Election Function lead to wealth concentration in PoS?” document.\n\ndevelopment §\n\nNo updates, heavily in research.\n\ndata availability §\nresearch §\n\nThe DA Layer Comparison Table has been finalized, after several reviews and additional efforts.\nData Availability Specification has been updated according to recent comments.\nDA protocol details page has been created with the protocol diagrams included in the latest iteration.\nThe DA specification has been updated with new details. To see them and, in general, the progress of the DA specification, refer to this PR.\n\ndevelopment §\n\nDue to the focus on the DA Specification, protocol details, and the comparison table, no development updates.\n\nmiscellaneous §\n\nBlog coming this week and will be posted on the Nomos website (with the link on our X/Twitter).\n"},"nomos/updates/2024-02-19":{"title":"2024-02-19 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nBased on previous investigation, started a document about integrating the population strategy from Nym into the Cryptarchia setting. In it, while following an explicit staking assumption, it is assumed that a node that wants to be a mix node must register and stake on-chain. WIP with a lot of potential changes.\n\ndevelopment §\n\nImplementation WIP: defining structure for mixnode / mixclient.\nImplementation: concluded that the nymtech/sphinx crate can be used for our use case. For reference, previously we used a wrapper of sphinx developed in the nymtech/nym codebase - but now, we can use the nymtech/sphinx crate as it is.\nModified libp2p to use QUIC. Replaced TCP with QUIC in the nomos-libp2p crate, which will be used by the mixnet network backend: PR.\nFixed integration tests for QUIC. With the QUIC updates, some DA integration tests were failing - now they are working properly: PR.\n\ntestnet §\ndevelopment §\n\nCreated a document regarding embeddable databases with their analysis. In more detail, the document includes benchmark code, analysis of several rust-based DBs, a proposal for which DB we should use, and example code for our most important use cases.\n\ncryptarchia §\nresearch §\n\nUpdated the “Does Crypsinous’ Leader Election Function lead to wealth concentration in PoS?” document with new details about stake relativization - more precisely new simulations in regards to validators of certain ranges.\nStarted building out a NIZK (Non-interactive Zero-Knowledge) Glossary of terms that will be used for internal education as well as writing the specification.\nWIP: writing a how-to guide for reading/writing NIZK specifications. This will help us in the future when writing certain Nomos specifications.\nAnalysis of de-anonymization of relative stake: for adversarial inference of relative stake in the leader election process, considered statistical properties of (naive) maximum likelihood (ML) estimator of relative stake - in the naive ML approach, the relative stake of node i is obtained from the frequency of observed 1’s, representing vins in elections, and properties of lottery function. Also, analyzed statistical properties of the naive ML estimator of relative stake. The consequences of the aforementioned results for the mixnet are in progress and will be shared in the future. To see the math behind the analysis check the Overleaf document.\n\ndevelopment §\n\nNo tangible updates - but Cryptarchia rust implementation is in progress, more details in the coming weeks.\n\ndata availability §\nresearch §\n\nInitial DA API specification structure PR: defined mock zone, DA node and block producer to wrap DA spec and use it for encoding, dissemination and verification. Once the DA spec is near finalization, we will continue the mock implementation in python.\nDA Specification updated per reviews and comments. Likely more changes on the way (depending on review).\nStarted a document on studying VeriZEXE and Taiga designs. WIP, currently includes initial notes, likely to change.\n\ndevelopment §\n\nStarted implementing KZG core functionality of DA - more details in the upcoming weeks.\n\nmiscellaneous §\n\nFinalizing v0.6. of the darkpaper for internal release.\nFinalizing the first blog post for internal release.\n"},"nomos/updates/2024-02-26":{"title":"2024-02-26 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nAnalysis of the fraction of compromised paths in the mix network: developed an (asymptotic) analytical framework for the analysis of the fraction of compromised paths in the randomly generated mix network. Calculated the average and variance of the fraction of compromised paths. In the regime of a finite number of layers and very large width, the variance is vanishing, and the fraction of compromised paths becomes deterministic. Analysis of the large number of layers and large width regime is currently in progress.\nContinued the investigation of the mixnet population - analyzing the proof of mixing under the explicit staking assumption for Cryptarchia: Trying to reason the possibility to limit the number of active staking parties and uphold the same security properties as Nym has. In conclusion: without active participation of “users” (regular nodes) we cannot effectively measure the performance of the mixnet. On top of that, the engagement of the regular nodes must follow the same design as mixnet formation - it must be incentivized.\n\ndevelopment §\n\nImplemented the full spec of mixnet v1. Preparing to open a couple of small PRs by splitting a few of the bigger ones.\n\ntestnet §\ndevelopment §\n\nNo updates.\n\ncryptarchia §\nresearch §\n\nThe Tokenomics Design Canvas has been updated. Among other updates, it is important to mention that we added a new role to the canvas - Light nodes (Zone verifiers and replication providers).\nScraped cexplorer for the individual stake values held in Cardano’s: Notes.\nSimulations and plots to validate stake privacy analysis: Analysis.\nAnalysis of de-anonymization of relative stake: for adversarial inference of relative stake in the leader election process, considered statistical properties of maximum likelihood (ML) estimators of relative stake. A number of empty slots were included in the ML framework but lead to an inconsistent estimator of the relative stake - this result was confirmed in simulations. The ML framework was used to infer the relative stake in simulations using synthetic and real stake (Cardano) data. Simulations suggest that at least a 1/100 fraction of the network has to be observed at any time to infer the relative stake of the top 1% nodes with high probability within T=432000 time-slots. Summary and the detailed analysis.\n\ndevelopment §\n\nCryptarchia first PR - Cryptarchia engine - is ready for review - it’s mostly a translation from specs code apart from a few routines that were made more efficient. Additional things (e.g., orphan proofs) will be added in a future iteration.\n\ndata availability §\nresearch §\n\nStudied on the BLS threshold Signature. The detailed explanations of BLS-pairing and signature aggregation are finished - document.\nStudying Taiga designs (WIP) - This article discusses the architectural differences between the privacy-preserving execution environments Taiga, Zexe, and VeriZexe in the context of smart contract systems.\nStudied on the python implementation of KZG to understand the verification check problem. We solved the bug encountered previously - PR.\n\ndevelopment §\n\nDA API implementation for FullReplication protocol in progress: added Certificate Metadata definition and integration PR.\nResearch on SurrealDB - captured the notes as part of the greater DB research document.\nImplemented RocksDB storage service - PR. Based on this also opened the PR to start using RocksDB as the backend.\n\nmiscellaneous §\n\nv0.6 of Darkpaper is close to finalizing (internally). After the introduction is written, we will coordinate the public release.\nThe first blog (Is Network Anonymity Alone Sufficient for Proof of Stake Systems) is being finalized. We have one more round of comments to review and add the blog feature to the nomos.tech website. The next blog (regarding wealth concentration in PoS) is in progress.\n"},"nomos/updates/2024-03-04":{"title":"2024-03-04 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"network privacy and mixnet §\nresearch §\n\nStarted rewriting the “Populating mixnet” document, leading to the creation of a new document that combines both previous mixnet-related documents. Initial editing was done, a couple of minor sections have been added, and an additional section has been created that discusses a couple of cryptoeconomical problems requiring more investigation - WIP.\nMixnet Incentivization: started a new document that will contain the understanding of the mixnet incentivization problem.\nAnalysis of the fraction of compromised paths in the mix network: In the regime of a finite number of layers and very large width, the variance is vanishing, and the fraction of compromised paths, alpha, becomes deterministic. This, however, is no longer true when the number of layers and width of layers are both large. For this regime derived an analytic (asymptotic) expression for the probability that α belongs to some interval [alpha_0, alpha_1]. Verification of this analytic result by simulations is in progress, and the summary is here.\n\ndevelopment §\n\nMixnet network backend skeleton - PR.\nLibp2p stream read/write - PR.\nEmitting packets from mixclient using libp2p stream - PR.\nHandle outputs from mixnode using libp2p stream/gossipsub - PR.\nRefactor Poisson distribution implementation - PR.\nMix client Poisson emission - PR.\nMix node packet handling - PR.\nMix Packet / Fragment logic - PR.\nMove FisherYates to nomos-utils - PR.\nMixnet topology - PR.\nMix client/node unit tests PR.\nNote on the PRs above: tests will fail because the whole implementation has been split into small PRs. All tests will pass at the last PR that will be opened.\nTaking some time to refactor network adapter codes that are tightly coupled with only the libp2p network backend.\n\ntestnet §\ndevelopment §\n\nWIP: Integration for explorer - PR (marked as WIP since one of the unit tests is failing).\n\ncryptarchia §\nresearch §\n\nTokenomics design canvas has been updated with additional clarifications regarding the “Light node” role (both Zone verifiers and providers of replication).\nStake relativization has been updated as part of the Cryptarchia specification.\nStarted the Block rewards document to discuss and propose solutions to rewarding new block proposals.\n\ndevelopment §\n\nMerged all PRs for Cryptarchia here and here.\n\ndata availability §\nresearch §\n\nSeveral libraries were reviewed for the implementation of RS encoding. The usage of FFT in the implementation was examined. In the initial stage, details on how the implementation can be carried out were outlined here.\n\ndevelopment §\n\nKZG core functionality (working version) has been implemented - PR.\nStarted RS: implemented encoding.\nStarted RS: decoding implementation in progress.\nDA API Verified certificate selection from the mempool function - PR.\nDA API sign attestations in full replication - PR.\nDA API signer tests - PR.\n\ncoordination layer §\nresearch §\n\nThe examination of the Taiga design continues. Technical details and the cryptographic functions used are being researched. Verifiable encryption is under consideration, and existing libraries in the literature are being reviewed. Notes and questions related to the Taiga design are documented here (WIP).\nAs part of the same effort with the previous point, created two more documents here and here that envelop additional efforts on studying Taiga.\n\ndevelopment §\n\nNo updates at the moment, heavily in research.\n\nmiscellaneous §\n\n1 new blog post is in review regarding Wealth concentration in PoS systems. Currently in the first iteration.\n"},"nomos/updates/2024-03-11":{"title":"2024-03-11 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"cryptarchia §\nresearch §\n\nWe have updated the Cryptarchia specification with the update epoch stabilization schedule - PR.\nAnalysis of adversarial inference of relative stake: derived an equation that can be used to infer the Lagrange parameter in the maximum likelihood inference of relative stake - the details of the analysis.\n\ndevelopment §\n\nRemoved assumptions on Carnot being the consensus algorithm in the mempool: PR.\nSeparate ledger and consensus to prepare for integration: PR.\n\nmixnet (network privacy) §\nResearch §\n\nWork in Progress (WIP): The Mixnet Incentivization document has been initiated. Current open questions will be addressed, covering system design, mathematical analysis, and more.\nContinuing work on the mixnet with staking, incorporating modifications based on feedback. A section has been added concerning the hidden bonus of deanonymization. It’s a straightforward observation that random assignment of adversarial nodes can, in some cases, lead to a higher number of adversarial paths than naively expected. Also, a section about discussing the latency and anonymity relationship has been started. WIP document.\nAnalysis of the fraction of compromised paths in the mix network: using an asymptotic lower bound to estimate the probability that the fraction of compromised paths, α, belongs to the interval [α0​,α1​]. The analysis suggests that in the mixnet of size n=240 with L=3 layers sampled from N=800 nodes, where M=200 nodes are adversarial, α can be almost three times larger than the average (M/N)L which assumes a mixnet of infinite width. The parameters n=240, L=3, and N=800 are currently used in Nym’s mixnet. Here for ¼ of adversarial nodes, the fraction of compromised paths can be as high as 0.05. To compare, the average here is 0.02. Summary is provided here.\n\ndevelopment §\n\nAll PRs for Mixnet v1 implementation have been merged. We’ve taken some additional time to polish the code according to feedback.\nOne remaining PR we are working on is adding a compilation option to enable mixnet. We’re going to always enable mixnet in production, but we’ve discussed that it’s also good to remain in the libp2p-only compilation mode for development to unblock other dev topics until everything of mixnet becomes stable. Will be finished this early this week.\n\ndata availability §\nresearch §\n\nNo current updates.\n\ndevelopment §\n\nFinished RS core encode/decode: there was an issue with different FFT calls from different libraries that didn’t work and took a while to debug. They use floating numbers, and when rounding or using a big set of operations, precision leads to errors - PR.\nImplemented DA protocol encoder: PR.\nImplemented DA protocol verifier: PR.\nDA API mempool tests using a mock implementation PR - The previous PR defined an abstraction for verifying and filtering what to include in the generic mempool; this PR provides mock implementations for TX and Cert verification/filtering. WIP: DA API indexing for data blobs - adding an index to data blob in DA node when the certificate is observed in the block.\n\ncoordination layer §\nresearch §\n\nWe have begun a couple of study documents in terms of the Coordination Layer: What does it mean for an asset to be “inside” a Zone and Illustrated guide to “Mutator Sets and their Application to Scalable Privacy. With these documents, we want to solve questions and challenges before delving into the design.\nThe “Parallel Zero Knowledge Virtual Machine” paper has been reviewed, and a brief summary of GKR details has been shared.\n\ndevelopment §\n\nHeavily in research, no development updates.\n\ntestnet §\ndevelopment §\n\nExplorer works well now, can share the data directories with the node, and provide data through HTTP: PR.\n\nmiscellaneous §\n\nNomos has a new HackMD account - our team will be publishing various notes on it - mostly scientific in nature.\nBlog to be released this week. Stay tuned on our website.\n"},"nomos/updates/2024-03-18":{"title":"2024-03-18 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Cryptarchia §\nResearch §\n\nNo research updates at this moment.\n\nDevelopment §\n\nStake Relativization Specification - the spec implementation has revealed some bugs in our orphan proof handling logic. Those bugs are still being worked through in this PR.\nRefactored Cryptarchia implementation into ledger and consensus crates: PR.\nRefactored nomos header and block definition so that it’s now responsibility of the nomos-core crate: PR.\nAdded Cryptarchia consensus service: PR.\n\nMixnet (Network Privacy) §\nResearch §\n\nMixnet incentivization document has been further updated, more precisely the “Rewards” chapter that showcases the mathematic analysis and some of the parameters.\nFocused on researching the problem of mixing transactions by briefly investigating the economic perspective - emphasized on the fact that it can be a main source of the revenue for the mix network. Furthermore, we discussed the privacy perspective and potential negative impact on the privacy due to direct staking.\nStarted work on the Message Type Indistinguishability (WIP name) section, where we discuss the potential sizes of the messages, their impact on the throughput, mixnet capacity, and noted a rewarding thing leading to a negative on the privacy. Both this and the previous point can be found in this (WIP) document.\nAnalysis of the fraction of compromised paths in the mix network: optimized code which computes the (asymptotic) lower bound on the probability that the fraction of compromised paths, alpha, belongs to the interval [alpha_0, alpha_1]. The code takes the mixnet size n, sampled from N nodes where M nodes assumed to be adversarial, some initial fraction of compromised paths alpha_0 and outputs minimal fraction of compromised paths alpha_1 such that prob. that fraction of compromised paths belongs to the interval [alpha_0, alpha_1] is 1. The code can be used to design a program which optimizes the number of layers L given some threshold, on the alpha_1, which can be tolerated. However, one has to test if the asymptotic lower bound is suitable for this and gives alpha_1 which is not too loose. Summary of numerical results and simulations is provided in this document. Summary of analysis is provided in this document and the detailed analysis can be found in the Overleaf document.\n\nDevelopment §\n\nIntegrated mixnet network service for consensus, DA, and mempool: PR.\nUpdated nomos-node integration tests for Mixnet: PR.\nRefactoring mixnet code: PR - and further PRs to be opened soon.\n\nData Availability §\nResearch §\n\nA case for dispersing the same VID Certificate multiple times was discussed during development, shorter version can be found in this document (VID Related Open Questions chapter).\nBLS threshold details have been added in the relevant document. It was concluded that there could be a significant overhead in communication when using DKG. Instead, an agreement was reached to apply a different solution using aggregate BLS. The relevant changes have been updated in the specification document. At this stage, we will proceed with this method. To find the best solution for this part, we might ask for support from the VAC team.\n\nDevelopment §\n\nInitial DA API spec structure revised and merged: PR.\nTests using DA Protocol specs have been developed. Currently, there are 2 types of tests, which are showcased in the first PR and the second PR.\nFinalizing DA verifier protocol specification: PR.\nFinalizing DA encoding protocol specification: PR.\nFinalizing DA dispersal protocol specification. Full flow with tests included, using Encoders and Verifiers: PR. Also, they have gone through reviews and we started discussions in several PRs - #1, #2, #3\nAdded attesters bitfield to DA certificate. Missing compressed bitfield so we can use BLS aggregation of signatures as a threshold scheme: PR.\nAdded certificate verification specification.\n\nCoordination Layer §\nResearch §\n\nSynchronous Composability with Partial Transactions document with a proposed design.\nProgressed with the discussion on Atomic Asset Transfer w/ Taiga in this document.\nThe Taiga circuit structures have been reviewed again. Relevant comments have been added to the document.\n\nDevelopment §\n\nNo development updates.\n\nTestnet §\nDevelopment §\n\nNo updates at this moment.\n\nMiscellaneous §\n\nBlog is now live - feel free to take a look at the first article here. More to come soon!\n"},"nomos/updates/2024-03-25":{"title":"2024-03-25 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Cryptarchia §\nResearch §\n\nNo research updates at this moment.\n\nDevelopment §\n\nFixed a bug in the Cryptarchia spec regarding try_create_fork to find parent block.\nStake Relativization Executable Specification is done: PR. Also, implementing stake relativization revealed some bugs in our Cryptarchia spec which took some time to debug and write tests for. Also, the stake relativization spec has been updated with learnings from the implementation (changes were mostly around time management since we need the inferred total stake to be stable by the time we enter the next epoch).\nRegarding block rewards, our proposal would be to postpone this work for when we will have the CL available, as it’s likely best done through a ‘special’ transaction (probably in a block body rather than in the header).\nAs discussed, at this moment, we will not support multiple consensus protocols in node.\n\nMixnet (Network Privacy) §\nResearch §\n\nMixnet incentivization document has been updated with additional problem statements: we are exploring how to make delegations private.\nAnalysis of the fraction of compromised paths in the mix network: The asymptotic lower bound (asympt. l.b.) on the probability that the fraction of compromised paths, \\alpha, belongs to the interval [\\alpha_0, \\alpha_1] was used to obtain an upper bound on the maximum fraction of compromised paths, \\alpha_max, in the mixnet of size n sampled from N nodes, where M nodes are adversarial.\nComparing the asympt. l.b. and simulations shows that the latter provides a very loose upper bound on \\alpha_max when the size of mixnet n is fixed and the number of layers L is increasing. However, the asympt. l.b. provides a better upper bound on \\alpha_max when the width of the mixnet n_1 is fixed and the number of layers L is increasing.\nDerived the probability distribution for the fraction of compromised paths \\alpha in the mixnet of size n=n_1 L, where n_1 is the number of nodes per layer and L is the number of layers, with m adversarial nodes when n_1 is very large. In this regime, the number of adversarial nodes in a layer is a random variable from the binomial distribution with parameters n_1 and m/n, such that on average n_1m/n nodes per layer are adversarial. Summary of numerical results and simulations is provided in this doc while Summary of analysis is provided here and the details of the analysis are in Overleaf.\nMixnet with staking design: Message Type Indistinguishability - extended the message type indistinguishability section of the staking design document,  where we added a part about the impact of the pledged and delegated stake based rankings on the privacy. This part of the investigation, led to coining the Staking Security vs Privacy dilemma, where we describe a tension between staking security and privacy. In short, staking can increase chances for deanonymization. The details can be seen in this document.\n\nDevelopment §\n\nSome refactoring work on following PRs: #615, #616, #618.\nWIP: Testing if mix client/node emit packets according to the specified Poisson parameters.\nWIP: Testing if enough packets are mixed in each mix node.\nWIP: Working on making the aforementioned two as metrics (for monitoring).\n\nData Availability §\nResearch §\n\nNo research updates at this moment.\n\nDevelopment §\n\nFixed a new storage issue in windows build CI: PR.\nAdded a new block subscription to consensus service: PR.\nDA API testing: PR.\nAdded Certificate verification to specs: PR.\nFixed arbitrary data encoding in the Encoder specs: PR. There was an issue with this, we can only encode up to 31bytes per chunk using bls. Notice that bls uses 32bytes field elements, but some 32bytes elements would be higher than the bls_modulus, hence we need to use 31bytes.\nAdded duplicated blobs verification in verifier: Verifiers need to return the attestation in case a duplicated verification comes around, or skip it depending on different stages: PR.\nMoved current DA API implementation to draft: DA Protocol abstraction will change. Until we have an updated version, the DA API work is on hold.\n\nCoordination Layer §\nResearch §\n\nWe’ve been reading Taiga source code, and putting up minor contributions as we go through it: PR - taiga#262, taiga#260, taiga#259.\nReviewed Synchronous Composability with Partial Transactions. The relevant article has been reviewed, and comments have been added.\nDetails regarding the proof of equivalence have been explained and python code for random proof generation has been added to the following document.\nAs part of our research effort, compiled the notes on - Bitcoin L2s, New Architectures, Coordination Layer.\n\nDevelopment §\n\nNo development updates.\n\nTestnet §\nDevelopment §\n\nRemoved unused nomos services: old metrics service replaced with a Prometheus PR and old http API removed PR.\n\nMiscellaneous §\n\nA new blog post will be published this week: Tackling the Challenge of Wealth Concentration in PoS Blockchains with the simulations and scientific results.\nWe have exciting new ideas cooking about updating the Nomos documentation - stay tuned!\n"},"nomos/updates/2024-04-01":{"title":"2024-01-04 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Cryptarchia §\nResearch §\n\nUsed the probability that the naive estimator of relative stake is inside some interval which includes the true stake α, δ(α), to derive an algorithm that suggests how to divide the stake of a node in order to reduce the quality of statistical inference by an adversary. The interval [α(1−γ),α(1+γ)] is parameterized by the adversarial “accuracy” parameter γ. The probability δ(α) can be interpreted as adversarial “confidence” gained after Tq observations (on average), where T is the number of time-slots in one epoch and q is the fraction of observed slots (for example due to deanonymization failure of the mixnet), that the inferred stake is within the interval [α(1−γ),α(1+γ)]. Assuming q and γ, a node can use its stake α to compute the probability δ(α). The latter is a monotonically increasing function of α, and dividing α among a number of nodes reduces the adversarial “confidence,” thereby reducing the quality of adversarial inference. The details of the analysis can be found in the following document.\n\nDevelopment §\n\nCryptarchia fuzz tests: tried various fuzz testing strategies, but finally ended up with a simple but clear fuzz strategy, through which we can test Cryptarchia by simulating the environment where the block proposal delivery (p2p networking) is not synchronous and not predictable. The initial PR for the basic strategy has been opened. Also opened a small fix found by the fuzz test: PR.\n\nMixnet (Network Privacy) §\nResearch §\n\nDiscussed the Staking-Privacy dilemma and came to a conclusion that the Nym design needs to be fine-tuned to reduce the impact of the delegated stake on the probability of selection of a node. We also need to investigate a mysterious constant that “controls the loss of competitiveness experienced by a Sybil attacker when it partitions the stake into multiple pledges”.\nPrepared a recommendation for the first iteration of the mixnet staking. The main motivation was to present a simple staking design for mixnet that is inspired by Nym but is simplified and will be updated when our approach gets more mature.\n\nDevelopment §\n\nAdding metric APIs for Mixnet - still work in progress. A PR will be opened for a minimal but essential metric API this week. This should be enough for now because the entire mixnet architecture may change according to the mixnet staking design. The first metric is going to be the number of packets that are being mixed in each mix node, which can be considered as the quality of mixing. More details in the relevant document.\n\nData Availability §\nResearch §\n\nNomos DA specification has been rewritten - a document has been added on top of the original one to make certain mathematical and technical details more digestible.\n\nDevelopment §\n\nNomos DA verifier sketch: We have started putting all pieces in place for getting the DA protocol implemented and integrated in the node. This implies some cleaning and refactoring that have impact in the code base. We have a da-v1 branch where we will be incorporating everything until it is ready and stable to be added to master - PR.\nPublished a draft branch with the first working version of the Nomos DA protocol. This will make a lot of changes including removing of old attempts and experiments. Notice that this branch will hold a lot of changes but that most of them will be incrementally included (and reviewed).\nBranch added: KZG+RS core in rust, bytes_to_polynomial method - not working atm but we are debugging to see what is the issue (looks like roots of unity related).\nBranch added: DA indexer - work in progress, removed all previously proposed mocks and structures as da protocol changed substantially.\n\nCoordination Layer §\nResearch §\n\nTaiga: compiled a report on the current state as part of our research efforts.\nTaiga made the choice to use blake2s for VP commitments and Poseidon for resource commitments. The experiment looks at prover/verify time when blake2s is replaced with Poseidon, and we get a near doubling in performance. More details in our experiment. The details of the Blake2s with Poseidon implementation have been reviewed in this document. As part of examining the usage of Blake2s and Poseidon in the Taiga implementation, a summary providing general information about ZK-friendly hash functions has been prepared.\nThe survey on proof systems is underway: to summarize, Halo2 stands out in implementations for private transactions. Its use of Plonkish arithmetization and consideration of lookup arguments make Halo2 advantageous. As discussed earlier, we prefer not to use a trusted setup-related feature like KZG in the coordination layer. Consequently, proof protocols involving trusted setups, such as Groth16 and Plonk, are less favored. Generally, there are three common polynomial commitment schemes used in existing protocols: KZG, IPA, and FRI. A comparison of these schemes has been added to the report. Even if we don’t use Plonk, the use of Plonk-ish arithmetizations in Halo2 is significant for performance. In addition, Nova’s folding improvement is critical for performance, but it requires the use of R1CS instead of Plonkish. Sangria, a folding scheme using Plonkish methods, is a new design worth exploring. Finally, after outlining the general framework for the coordination layer, we believe that upgrading cryptographic sub-algorithms for performance will not be too challenging.\n\nDevelopment §\n\nNo development updates.\n\nTestnet §\nDevelopment §\n\nNo updates at the moment.\n\nMiscellaneous §\n\nNew blog will be published after reviews - Stake relativization.\nNomos team will be at All-hands next week.\n"},"nomos/updates/2024-04-08":{"title":"2024-01-08 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Note §\n\nThis is a weekly update from the part of the team that didn’t attend the All-Hands Event in Athens.\n\nMixnet (Network Privacy) §\nResearch §\n\nRegarding the current situation with the mixnet and staking, we have decided to focus on the simplest approach, that is only single-staking without stake delegation as suggested for the first iteration of the staking. Due to the simplicity of this approach, we can model it more precisely and learn more of its properties.\nWe have received a couple of comments regarding the mixnet from an external reviewer. The comments and our analysis can be seen in this document.\nReviewed an interesting critique of mixnets and suggestions on their improvements. One of them is the Poisson mixing design choice that is part of Nym and is claimed to be wrong. This led to a discussion on how to design a better mixing mechanism. We don’t know exactly what is broken in the Poisson mix; there are some claims and some proposals on how to solve the problem suggested in the presentation. We have asked for more paperwork supporting their claims and the authors of the presentation are working on it. In the meantime, a proposal has been prepared based on suggestions from the presentation.\nLooked at the Bittensor proposal (especially the idea of treating a node as a learning machine and combining it with a rewarding function), read through all of their papers. If we would like to use a similar approach then we must prove that the outcome of the mechanism cannot be biased - which might be very hard.\nOptimization of mixnets: written the initial specification and some functions for the algorithm which uses the (asymptotic) lower bound on the probability that the fraction of compromised paths belongs to some interval to compute the optimal number of layers. The details are provided in this document.\nAlso, tried to tighten the bound on this probability using the AM–GM and Markov’s inequalities, but trying this approach has not produced any improvements so far. The details are provided in this document.\n"},"nomos/updates/2024-04-15":{"title":"2024-01-15 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Note §\n\nThis is a weekly update from the part of the team that didn’t attend the All-Hands Event in Athens.\n\nMixnet (Network Privacy) §\nResearch §\n\nMixnet mixing problem: Based on the critique of the Loopix mixing design and proposed solutions, we have prepared an updated mixing design.\nWe are going to prepare a Mixnet empirical analysis tool, so that we can make sure that our Mixnet design meets a proper level of anonymity that we expect. This will probably be based on our executable specification, so that anyone in the team can run it easily whenever they want. Based on it, our reference implementation (Rust) will expose similar metrics, so that we can monitor its behavior in the testnet (probably in collaboration with Vac). This will be useful for finding the Poisson problem mentioned in the previous weekly, for example.\nNetwork bootstrapping/node registration: started thinking through the problem of network bootstrapping and the requirement of node registration. Looking for inspiration, details of the very early discussion can be found in this WIP document.\nOptimization of mixnets: derived an upper bound on the probability that the fraction of compromised paths, α, is greater than some threshold 1α1​. This new upper bound is non-asymptotic, i.e., for mixnets of any size n sampled from the population of N nodes, and much simpler to compute numerically than previously considered asymptotic bounds. Initial results of comparing this upper bound with simulations suggest that the bound is “practical”, i.e., can be much smaller than the trivial bound of 1, and can be used in optimization of mixnets. The summary of this work is provided in this document, and the detailed analysis can be found in the Overleaf document. Further simulations and work on the algorithm are currently in progress.\n"},"nomos/updates/2024-04-22":{"title":"2024-01-22 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"Cryptarchia §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMixnet (Network Privacy) §\nResearch §\n\nDefined metrics to be collected for Mixnet (for other components as well, but mainly for Mixnet). This list should be sufficient for now.\nInvestigated which empirical analysis had been done by Loopix paper and another paper, in order to design Nomos empirical analysis soon. When compared to our previous work, it isn’t so different. The main goal would be measuring the probability of linking an output message from a source message correctly. Still remains to determine if this should be for executable spec, or for a real implementation.\nPlanning the first collaboration with DST. This would focus on the Mixnet properties, but only simple metrics as the first step. Before starting the collaboration, we need to check if this list is really reasonable to be offloaded to DST.\nIn consideration on how we can avoid node distinction and registration, and while reviewing the Hopr design an idea arose of changing the layered mix topology (Nym) to a circular one which enables users to extend their number of hops freely, and using gossip pub-sub protocol as an underlying messaging to achieve mixing over P2P. Therefore, we are able to have at the same time privacy (and scalability) optimal layered mix (with flexibility of adjusting the level of anonymity - path length) that does not require registering node long-lasting public identifiers (IPs) and works on top of a P2P network. All this led to a sketch of a new type of a mix, the “Whirl” Mix.\nNew Network Privacy proposal has been made, based on the updated and clear vision/roadmap of Nomos.\nOptimization of mixnets: considered a scenario when all N nodes, where at most M nodes are adversarial, are used to construct the mixnet with L layers. Proved that in this case the fraction of compromised paths 𝛼α is at most (𝑀/𝐿)𝐿(M/L)L which was also verified by simulations. The histogram of 𝛼α obtained in simulations only has a long left tail. Properties of the above mixnet are very different from properties of mixnets of size n sampled from N nodes. Here the fraction of compromised paths is always bounded by 1. This suggests that for small (or moderate) N using all nodes could be more desirable. The summary of this work is provided in Notion while the details of the analysis can be found in Overleaf.\n\nDevelopment §\n\nNo development updates.\n\nData Availability §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nMerged KZG+RS core (implementation of the KZG and RS core methods): PR.\nImplemented and merged DA V1 encoder: PR.\nImplemented and merged DA V1 verifier: PR.\nDA mempool specific functionality for cert to vid conversion: network payload and mempool item in DA mempool now can differ if payload can be converted into the mempool item, PR.\nDA Indexer (WIP): implementation of metadata indexer had to be postponed as it depended on the certificate, vid and metadata definitions added in mempool split PR and da-protocol-v1 branch.\n\nCoordination Layer §\nResearch §\n\nStudied on the proof aggregation methods and also on the Jolt protocol (previously reviewed) for the survey. Added the updates (WIP - the aim is to complete it by the end of this week). A brief explanation about Jolt: It is designed to reduce prover costs by using lookup arguments. The reason for reviewing it is that its implementation was released in the past weeks. This version uses the Hyrax polynomial commitment, which results in higher verifier complexity (which is not ideal for Nomos). However, they mentioned that future versions would support different commitment schemes. Our priority is minimizing verifier costs, but if Jolt can offer good results for both prover and verifier, it might be worth considering. Release post of Jolt on X.\n\nDevelopment §\n\nSplit generic mempool into CL and DA mempools - this was needed as making it completely generic would have been impossible at some point. They are now free to deviate in both typing and behavior without affecting the other. The refactor was done so they can share as many available resources as possible: PR.\n\nTestnet §\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nWIP: Nomos Roadmap and Milestone Execution Plan.\nWealth Concentration in PoS, part 1 - published and posted on X.\nIntroduction to Nomos Architecture - in final stages, will be shared by Wednesday or Thursday.\n"},"nomos/updates/2024-04-29":{"title":"2024-01-29 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nPlanning the Mixnet v2 PoC simulation (WIP): To simulate the behavior of the new design, we need to cover some design options (such as the way of broadcasting, etc.). We’ll create a simulator with these options to find the optimal design.\nResearched the existing Mixnet simulators: They provide Python simulators focusing only on global passive adversaries (GPA) by measuring the Shannon entropy as a metric for anonymity (the uncertainty of linking an output message with a certain input message). We can adopt this practice for GPA analysis. For active adversary analysis, we need to figure out how to simulate tagging attacks and n-1 attacks (if necessary). For tagging attacks, we can probably perform an indirect analysis by measuring how many nodes a block is disseminated in before it’s selected/proposed.\nSummarized the requirements for the Mixing gadget.\nOptimization of mixnets: For a scenario when n nodes, sampled from N nodes with at most M adversarial nodes, we designed an algorithm. Given the number of nodes per layer n_1, the fraction of compromised paths which can be tolerated αm​ax, and the probability that the fraction of compromised paths is greater than 𝛼𝑚𝑎𝑥αm​ax, δ, the algorithm outputs the number of layers L: Summary. The algorithm is implemented in Python, but the code needs further refinement.\nAnalysis of anonymity and communication failures in the mix gadget: Assuming that k nodes are sampled from N nodes, where at most M nodes are adversarial, we derived the probability that all k nodes are adversarial and the probability that at least one node is adversarial. The latter is the probability of communication failure, and the former is the probability of anonymity failure. The probability of anonymity failure decreases with k, and the probability of communication failure increases with k. We derived upper bounds on these probabilities. For large N, the probability of anonymity failure is bounded above by 2(𝑀/𝑁)𝑘/𝜋2(M/N)k/π​, and the probability of communication failure is bounded by 1−𝜋(1−𝑀/𝑁)𝑘/21−π​(1−M/N)k/2. Note that M in the latter corresponds not only to adversarial but also to “slow” nodes or nodes with bad connections. The summary of this work is in progress.\nWork on analysis of the new mix gadget design is currently in progress.\n\nDevelopment §\n\nNo development updates.\n\nData Availability §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nInitial DA protocol benchmarking uncovered 2 performance issues that will be addressed as soon as possible: WIP.\nAdd Cert verification to DA mempool: - Merged payload to item conversion in mempool PR. Added certificate verification in da mempool PR merged.\nDA Indexer service definition: Service that is responsible for DA API functionality, is able to track new blocks and assign metadata to previously attested chunks PR. Note that the service is defined, but other services like storage are not yet integrated. These missing pieces will be the focus of upcoming weeks.\n\nPPoS/Consensus §\nResearch §\n\nWealth concentration document is in the process of reorganization with new studies being according to 8 parameters (see table 1 in the doc - we’re able to use way more realistic numbers as well, because software evolved), 3 classes of stakers (lower, mid, higher - we still lack a precise definition of them); and 3 fork-choice rules (lowest, highest, stochastic).\nThe first study assumes the relative stake is known and compares the 3 classes of stakers when the protocol enforces each of the 3 fork-choice rules under different parametrizations (sensitivity analysis).\nThe second study relaxes the assumption that the relative stake is known. We use and evaluate the impact of David and Alexander’s algorithm.\nThe third study relaxes the assumption that the protocol enforces the fork-choice rule. Each staker is allowed to use the rule of its choice.\nInvestigated the current state of the orphan proofs problem. After internal discussions, it was understood that this is a low priority for now, and we need to evaluate the real impact of this problem and how often it can happen first.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nCompleted the Proof Systems Survey: added updates on aggregation, folding schemes, and some protocols. Also, listed and grouped libraries with existing implementations. This week, there will be more detailed explanations about these libraries.\nCelestia ZK-Research Group messages have been summarized in a document with annotations and discussions around parts that might be important to us.\n\nDevelopment §\n\nNo development updates.\n\nTestnet + Insights §\nResearch §\n\nExtended the metrics and visualizations document by adding a planning block to match with yearly planning and resources.\n\nDevelopment §\n\nNo updates this week.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nLatest discussions triggered the need for yearly planning modifications: Wrote a document explaining year expectations + resources planning.\nCreated an initial Vac QA collaboration document with cross-team interactions plan.\nMilestone Execution plan has been published.\nLogos - Nomos update added - this will be an introductory one with focus on progress of research and engineering in the future.\nNew Nomos blog to be published this week with another to be set to review.\n"},"nomos/updates/2024-05-06":{"title":"2024-05-06 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nTo specify adversary models, we analyzed and summarized two papers: 2013 P. Syverson &amp; 2023 C. Diaz.\nBased on the above research, we defined the adversary model in the Mixnet v2: Proof of Concept, focusing on adversaries with partial visibility. Still, specific attack models must be defined so that we can simulate them. Currently, we are attempting things in reverse: imagining attacks that partially or completely break the protections that our design aims to provide. It’s still a work in progress in the same Notion page. Once this is complete, we can start implementing a simulation.\nBased on the previous week’s observations, we wrote a document containing a discussion on how to make the tagging attack less effective.\nAnalysis of anonymity and communication failures in the mix gadget (summary): Assuming that n nodes sample (with replacement) k nodes from the population with N nodes, where at most M nodes are adversarial, the fraction of k-subsets where all k nodes are adversarial, i.e., “anonymity failure” has occurred, is \\left(\\frac{M}{N}\\right)^k on average. The fraction of k-subsets where at least one node is adversarial, i.e., “communication failure” has occurred, is 1 - \\left(1 - \\frac{M}{N}\\right)^k on average. However, if n &lt; N is finite, then deviation from these averages will be observed. For the fraction of k-subsets with anonymity failure, we derived an upper bound on the probability that the fraction of these k-subsets is greater than the average \\left(\\frac{M}{N}\\right)^k by the factor of 1+γ. The upper bound is decreasing with increasing n and γ. A similar upper bound is derived for the fraction of k-subsets with communication failure. Work on the analysis of these bounds and verification by simulation is currently in progress.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nDA Indexer implementation PR: Implemented AddIndex and GetRange functionality in Indexer service. When a list of VidCertificates is observed in a new Block, AddIndex is used to assign Metadata from VidCertificate to a blob that was attested. - When the user requests Range of Indexes for a given AppId, indexer collects available blobs for indexes and returns them in a list.\nDA Indexer + Mempool + Cryptarchia integration test: DA functionality relies on multiple services working together; a test to see if currently implemented parts are working was created.\nSome ideas and improvements were registered (low priority): Verified Certificate state and Investigate BlobDB storage.\n\nPPoS/Consensus §\nResearch §\n\nWealth concentration update: changes related to the introduction of the study structure, rearrangement based on new sections, and expanded explanations.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nDesigned a bridge withdrawal implementation. In designing, we found some bugs in CL, namely, anoma’s “single logic per resource” design is too limiting; it wasn’t possible to see how to implement a simple withdrawal in that design. The fix that was made was borrowed from Zexe, replacing the single note constraint with two types of constraints: birth and death constraints. There is a single birth constraint and arbitrarily many death constraints. Birth constraints govern how a note from a particular application can be produced. Death constraints are provided by the user and configure how a note can be spent; only one of the death constraints needs to be satisfied in order to spend a note.\nCreated the withdrawal CL test case.\nUpdated the Proof Systems survey according to comments. Explanations have been added to some of the sections. Additionally, existing zkp libraries have been reviewed to identify which proof methods are used.\nCoordination Layer Studies: a separate [section](A separate section for FRI has been added) for FRI has been added.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-05-13":{"title":"2024-05-13 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nClarified the adversary model further (WIP); we’ll develop it more by simulation. Attacks to be simulated are listed here, and are based on the adversary model in the same document. The related studies were referred to, including Waku’s documentation about adversarial models (provided by the Waku team).\nAnalysis of anonymity and communication failures in the mix gadget: Assuming that n nodes sample (with replacement) k nodes from the population with N nodes, where at most M nodes are adversarial, the average number of k-paths with anonymity and communication failures are, respectively, given by n \\left( \\frac{M}{N} \\right)^k and n \\left(1 - \\left(1 - \\frac{M}{N}\\right)^k\\right). Calculated an upper bound on the probability that the number of k-paths with these failures are greater than their respective averages by the factor 1+𝛾1+γ, where 𝛾&gt;0γ&gt;0. compared the above bounds with simulations showing that they are tight. Analysis of different cases of 𝑀/𝑁={½,⅓,¼,1/10}M/N={½,⅓,¼,1/10} suggests that, for reliability purposes, some combinations of n and k could be more advantageous than others. The summary of this work is provided here.\nStarted the investigation of the problem regarding mixing over a broadcasting channel, which is an interesting form of mixing in a sparse network. Using a broadcasting channel makes it impossible for an observer to learn who the recipient of the message is (assuming proper message relaying strategy). Making nodes indistinguishable requires a single cover traffic message per time slot, which is a step closer to ideal privacy. However, this has a great network overhead cost, which limits the scalability of the network significantly assuming a fixed bandwidth requirement per node. Also, made an observation about the impossibility of stake hiding, which is based on the fact that the network behavior of a node is reflected on the ledger and any disturbance of the node behavior must also be seen on the ledger. Document for reference.\n\nDevelopment §\n\nImplemented the simulation of “basic” mixnet behaviors (Modified Sphinx, Cover traffic, Broadcasting). They’re very naive but should be enough for running basic adversary simulations. The simulator is being implemented in the mixnet-v2-sim branch in the nomos-specs repository. Basic usage and development progress can be found in the README, though it’s still heavily WIP. Sphinx size: If the payload size is 330 bytes (32 bytes block hash + 288 bytes validator proof) and an incentive tx is 512 bytes (which may not be enough), and if the number of mix layers is 3, a Sphinx packet is 1937 bytes (subject to change).\n\nData Availability §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nDid benchmarks on DA, lib performance was way below expected and targets. Debugged issues, what was found is that the most problematic is proof generation. Discussed options for improvements: Parallelization (which is not really possible as is internally parallelized already) and amortized proof generation method. Ruse evaluation + Benchmarks can be found here.\n\nPPoS/Consensus §\nResearch §\n\nWealth concentration update: changes related to the introduction of the study structure, rearrangement based on new sections, and expanded/improved explanations.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nStudy on DA fast proof generation: research was conducted on fast proof generation in the DA domain. The Feist-Khovratovich technique was examined, and libraries implementing this method were investigated. The general structure of the method and the approach it attempts to implement are explained here.\nWrote a potential design for Mailboxes &amp; Sovereign Transactions.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-05-20":{"title":"2024-05-20 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nSecurity of mixing over a broadcasting channel (document): We have been able to generalize the stake hiding impossibility observation, discuss a general countermeasure, and add a section on how to practically weaken this impossibility. We have extended the Global View section with more discussion regarding the overhead of broadcasting communication. A practical note regarding mixing failure and a sketch for a mechanism to recover from mixnet failure redundancy have been added. We have also started working on a partial view analysis.\n\nDevelopment §\n\nMixnet v2 Simulation: added adversary simulation. Currently, it includes only a passive adversary with a global view. More realistic adversaries will be added later (low priority for now). The current version of Mixnet v2 simulation can be found here. Please note that this document is WIP and not an experiment report, though it includes some plots. It shows what the simulation can do right now and what’s next. In progress: writing the first simulation result document to be shared internally so that we can plan ahead.\nWe internally agreed to start by simulating the simple behavior first and measuring the bandwidth usage, especially by broadcasting real messages without mixing. After that, we can turn on more complex behaviors (e.g., mixing &amp; cover) and compare the results with the previous ones. This is because the simulation result with the whole set of behaviors may be too complex to analyze at the beginning when not everyone fully understands how the simulation works.\nWe found that the simulation speed is too slow with 100K nodes (not physical ones). The main reason is that the simulation is based on SimPy, which is single-threaded. However, the same poor performance was observed when another simulation framework in Python (Mesa) was tried. There may be some solutions (e.g., multiprocessing), but first, our aim is to produce the first meaningful simulation result with fewer nodes before improving it.\n\nData Availability §\nResearch §\n\nWe reviewed the FK20 algorithm again. Libraries for accelerating DA proof generation were reviewed. It appears there is some room for improvement, but it is not yet at the desired levels. Libraries: Rust-kzg, C-kzg, and Peerdas-kzg.\n\nDevelopment §\n\nDA Verifier service implementation: PR merged: the service for attesting the blobs.\nDA Verifier integration tests: Verifier service expects the DA protocol to implement a couple of traits for serialization, encoding, signing, etc. KZGRS backend is mostly implemented, but still needs some service-related utilities. This work is in the verifier-integration-tests branch.\nKZGRS performance review: as per the previous benchmarks on our KZGRS, we uncovered a few performance flaws. Those were addressed, but even then it did not reach our current targets. We have been checking and comparing with other implementations to see if we were doing anything wrong. We were not.\n\nPPoS/Consensus §\nResearch §\n\nExpanded/improved explanations of the results found in the Wealth Concentration in PoS document.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nStudies on binary field proof systems have been completed and documented. This week, we will also cover and take notes on Stwo (STARK prover) and check which parts we can use for the CL. These structures provide fast prover time. We need to discuss how much we need this on the CL side (because while providing fast prover time, it also increases proof size, which seems more important for us).\nThe Atomic Asset Transfer case has been started, but the text and diagrams lacked rigor. An implementation of the CL executable spec has begun, which can better sanity check the design. Details on Noir ZK language integration with Python: here.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nResearch §\n\nUpdated and improved the “Monitoring, instrumentation, and explorer” document - added a “milestones” section with the targets for the next iterations.\n\nDevelopment §\n\nNo updates this week.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNew blog post has been released: Preventing Wealth Concentration in PoS Systems: The Role of Stake Relativisation.\n"},"nomos/updates/2024-05-27":{"title":"2024-05-27 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nSecurity of Mixing over Broadcasting Channel document has been updated with new details. We mapped the first few cases that we want to analyze through simulations; the Partial View section was added to the document. Analysis of partial view is much more complex than the Global View case, and the Global View does not seem to leak significant information. Thus, the observer in Partial View will need to play a probability game to learn something. However, there are routing attacks that can increase the field of view of the observer, so we should not neglect this case. We have also started working on the analysis of an alternative to broadcasting dissemination—peer to peer.\nAnalysis of random structures generated by the mix gadget, such as properties of hypergraphs, etc. was performed and summary can be found here.\n\nDevelopment §\n\nP2P Privacy Simulation: all simulation reports can be found in P2P Privacy: Simulation Results.\nPosted a report: P2P Privacy: Bandwidth Usage Patterns. Bandwidth was measured for both 1-to-all broadcasting and gossiping, with various parameters (mix layers &amp; cover traffic) changed, so that we can gain insight into how bandwidth increases as parameters change. The document also shows how the simulation works. In short, we now have a framework to measure the performance of the protocol. The next simulation is evaluating anonymity with changing cover traffic patterns to find the optimal cover traffic strategy that guarantees a reasonable level of anonymity in the protocol.\nOne more (WIP) report can be found in (WIP) P2P Privacy: Anonymity. We are currently using the number of messages staying in each node over time as a metric to evaluate the level of anonymity. Although it may not be the best metric, it’s probably the most intuitive one for now.\n\nData Availability §\nResearch §\n\nThe details of the Semi-AVID protocol have been studied, the relevant implementation has been reviewed, and the document prepared.\nThe benchmark document for the results of NomosDA and Semi-AVID has been prepared. Values for Semi-AVID have been calculated and added to the table. We also computed the values for NomosDA. Based on feedback received, the table will be updated and recreated in regard to the latest values.\n\nDevelopment §\n\nKZGRS certificate implementation (PR merged), including: Certificate implementation required for verifier and indexer services, adding of DST tag to Nomos spec and the implementation (Nomos spec PR merged) and VID and Metadata for KZGRS DA protocol.\nAdded DA Verifier service improvements (PR merged).\n\nPPoS/Consensus §\nResearch §\n\nExpanded/improved explanations of the results in the “Does Crypsinous Leader Election Function Lead to Wealth Concentration in PoS” document. Also provided a single Jupyter notebook to replicate all computations.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nCL use case implementation in Python: made some progress towards a 1 input, 1 output test case for CL. PR #93, but it’s not yet working. Certain CL design bugs were found during implementation, which led to changing some parts of the specification.\nMinor crisis on prover key sizes preventing thin clients from generating a transaction. But the general opinion is that what we settled on should work for us (lazy prover key derivation).\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nResearch §\n\nNomos node insights document has been updated with new details.\n\nDevelopment §\n\nNo updates this week.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-06-03":{"title":"2024-06-03 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nContinued with the analysis of random structures generated by the mix gadget and outlined two possible approaches to the analysis of mix gadget.\nExplained how the timing attack by a passive adversary can be simulated: Tracing back message flows. In short, we can simulate an adversary who traces back message flows to identify original message senders (i.e. block proposers) and repeats this multiple times to find senders selected more often. This is not the perfect way, but our opinion is that we can enhance this to simulate more powerful adversaries.\n\nDevelopment §\nData Availability §\nResearch §\n\nDA benchmarks: we are running benchmarks to compare vs SemiAvid - including: updating and running benchmarks according to needed and requested data and creating a calculator for nomos-da benchmark results. The results can be seen here and the DA calculator script can be seen here.\nTo continue on the point above, we have updated the main document and created separate  sub-tables for NomosDA, Semi-AVID, and fk20. Benchmark results were entered into the tables for ANBC, RB, and CT, and general tables were created. Diagrams for the relevant tables were added to the document. Upon rechecking the results, it was observed that the values were consistent within themselves.\n\nDevelopment §\n\nNo updates this week\n\nPPoS/Consensus §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nPoC for CL specification: got the 1-to-1 transfer test running (and passing).\nThe python crypto library we’ve been using so far has been buggy and slow (as in &gt; 1minute startup time and slow ecc math). Tests are very slow to run. Trying to swap it out for some other ecc library, issue is that a lot of the more obscure curves are not well supported in python.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nUpdate current testnet with missing configs for cryptarchia PR merged: After the introduction of Cryptarchia, Nomos testnet was missing some consensus configuration. Also, exposed required configuration as environment variable. We improved docker build times by defining common base image for Nomos node as well. Also included several minor fixes that were required to deploy on testnet.nomos.tech.\nAfter the review and report on the testnet state, refined the plan for this iteration.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-06-10":{"title":"2024-06-10 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nMixnet v2 Simulation: invested time to improve/simplify the passive adversary attacks before running simulations with various parameter sets. Also running the passive adversary simulation with various parameter sets to find the optimal parameters/designs (the result is not posted in Notion yet).\nIntroduced an attack that monitors nodes which emit messages at promised timing (i.e., block interval). The description can be found here. This attack is expected to be disrupted by adding cover traffic. The confirmation of this will come once we run the attack with different cover traffic parameters.\nOptimized the timing attack (tracing back message paths) and quantified its result, as posted here. The confirmation of this will come once we run this simulation with different parameters (number of layers and delays).\nFor the analysis of the mix gadget, we have followed the “conventional” mix model research path: considering the most general scenario when n nodes sample k paths from the set of all nodes in the network [N]. We assumed that each node samples ( r ) of such ( k ) paths. We have shown that a node in a ( k )-path is also participating in other ( r - 1 + c_i ) ( k )-paths. Here ( c_i ) is a random variable from the binomial distribution with parameters ( rn ) and ( \\frac{k}{N} ). For ( k \\ll N ) and ( N ) large, ( c_i ) is a random variable from the Poisson distribution with parameter ( \\frac{k r n}{N} ). On average, a node is participating in ( \\frac{k r n}{N} + r ) ( k )-paths. We calculated an upper bound on the probability that node connectivity deviates from this average by the amount of ϵ\\epsilonϵ. The summary can be found here.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nFinished the benchmark document and all results are documented here. We will continue with NomosDA.\nWe were having an issue with the roots of unity that didn’t allow us to use FFTs. After an org-internal talk, we solved the issue, and now it is working (the problem was that we were using the wrong generator that worked for everything except the FFTs).\nStarted implementing FFT in specs as it is highly needed for FK20.\n\nDevelopment §\n\nNo updates this week.\n\nPPoS/Consensus §\nResearch §\n\nImproved the results in the wealth concentration document.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nStarted to review the Plonky3 details (the notes can be found here). Generally, we can say it’s an improved version of Plonky2 in terms of prover time - meaning we can use it in situations where we need more efficient prover time. Initially, it was more appropriate to use Plonky2 because Plonky3 was still in development, but considering that Risc0 and Succinct have also started using it, we can consider using the Plonky3 protocol as well. In any case, it has advantages over Plonky2.\nOn the other hand, we haven’t found any disadvantages in Plonky3. We thought proof size might be an issue, but they mentioned that they could reduce the proof size using recursion. In this case, it seems logical to use it for inner proof, but the details need to be examined. Perhaps conducting a similar benchmark study for inner and outer proofs as we did for DA would be beneficial.\nAfter discussing the CL Architecture, the most recent design making use of message buffers is now described here: CL Architecture.\nAfter making the decision to rewrite the CL spec in Rust due to the lack of crypto libraries in Python, we decided to halt the spec work in favor of the CL architecture design work that was more pressing.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nResearch §\n\nFinished base insights structure document (after discussion) - for the time being though, since it’s probably going to be a living document.\n\nDevelopment §\n\n(WIP) Tested our GELF tracing subscriber and connected it to Graylog in the testnet: subscriber is implemented and sends logs to the provided Graylog endpoint. However, the Graylog instance is spawned in the testnet, but manual steps need to be taken during every redeployment, which is not acceptable.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-06-17":{"title":"2024-06-17 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nMixnet v2 Simulation: ran the passive adversary simulation and posted the result here. We can see that the accuracy of timing attack (by passive adversary) significantly decreases as the number of mix layers and cover traffic increase. Next, we need to analyze this result along with bandwidth usages to find the optimal parameters of cover traffic and mix layers.\nAnalysis of the mix gadget: For the analysis of random graphs, generated by random sampling of k-paths in the mix gadget, wrote an interpretation of the result of this analysis. Based on this, looked at a more optimal approach for anonymous communication family of random graphs - notes.\nUpdated the sparse network section of the Security of Mixing over Broadcasting Channel document, as well as the models and finished the global view section. In the document, we have discussed what can be observed without cover traffic in our scenario, the cover traffic design, and how the cover traffic impacts on the observer capabilities to link the traffic.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nStudied on the Henosis design and wrote notes on it. It’s a study related to combining heterogeneous proofs in proof aggregation - this may be used as an inspiration in Nomos. The [code](https://github.com/availproject/Henosis/tree/main ”https://github.com/availproject/Henosis/tree/main) is available on GitHub.\nFK20 running specification in python: added tests to double check that generated proofs are the same.\nFK20 implementation in python: implemented FFT methods and added FFT parallelization version.\n\nDevelopment §\n\nDA HTTP API and integration to the node is still in progress.\n\nPPoS/Consensus §\nResearch §\n\nImproved the results in the wealth concentration document.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nWe’ve restarted the CL executable specification in rust (PR). The following parts have been specified: notes, nullifiers, ptx input, ptx output, partial tx. Still remaining to be specified: tx bundle of ptx’s, birth/death constraints, integration with SP1 snarks.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nFinished the tracing subscriber and connected it to Graylog in the testnet: - PR merged.\nImplemented minor changes to the CI for the updated rust version: PR.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-07-01":{"title":"2024-07-01 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nStarted writing the new mixnet executable specs. Completed: Global transmission rate, Peering degree limit, Noise per connection, Gossip-based Sphinx routing. Still to do: Time mixing.\nWIP: Updating mixnet simulation according to the new specs. The plan is to finish the first working version by the end of this week. It’s taking more time than expected because of the attempt to have reusability between specs and simulation. Now the plan is clear.\nGathered the outcome of our discussions and design decisions from the offsite and compiled a document that outlines the design of our mixnet gadget. WIP: work on the queuing mechanism for the mixnet gadget, taking into account what corrupted nodes can learn.\nWith the assumption that the “Are continuous stop-and-go mixnets provably secure?” paper is state of the art, studied it in great depth to find out how anonymity guarantees are usually derived. For our case, the most useful definition from the aforementioned work is user unlinkability. However, it uses two senders and one receiver, but in our case, we have only one sender, i.e., the leader node, and one receiver node. The latter requires a new definition of sender unlinkability. The summary can be found here.\nAssuming that anonymity guarantees and statistical independence of nodes are related, considered an approach that studies various “correlation functions,” such as mutual information, Hamming distance, etc. This work will be carried on in this document.\nWIP: analysis of correlation functions.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nWIP: First iteration of the PoC can be found here. That PR already runs a libp2p inside a very basic DA node. It is important to mention that the very limited py-libp2p is not great software. The last official release is from 2020, and it had to be cloned from GitHub to make it work at all. Then, there was an issue with its internals: it’s highly opinionated. Tried to reuse existing py code from mixnet by using asyncio but py-libp2p would refuse to work with it due to the lib’s internal setup with trio. It is also important to mention that this is an exploration of the libraries; the team is yet to decide whether libp2p will be used at all.\n\nDevelopment §\n\nFinishing FK20 Rust implementation.\nIncluded FK20 in DA encoder (PR).\nAdded Rayon parallelization to DA encoder (PR).\nImplemented cache for Toeplitz part-1 and integrated it into the encoder (PR).\nAdded benchmarks and missing parallelization features (PR).\nDA subnetwork assignment algorithm: Implemented re-hashing algorithm and initial experiments. Tried to implement and improve a few variations of the algorithm, but none of them were better than the original. Ran a few experiments (results and ideas will be shared later on).\nWrapped up DA HTTP endpoints for KZGRS backend PR. Pushed changes related to DA HTTP endpoints. They are generic and should be reused with the updated KZGRS protocol and dispersal as a black box.\n\nPPoS/Consensus §\nResearch §\n\nWIP: produce and analyze more simulation results using the relativization algorithm, as stated in the wealth concentration document.\nThe protocols suggested by Ethereum for the proof of validator protocol have been reviewed. As stated in the article, the use of a Merkle tree could be slow for proof generation. Therefore, a zk-SNARK solution using a lookup table is considered to be more efficient. The related protocols are summarized step-by-step here. Additionally, the SemaCaulk design will also be examined. There is already Rust code available here, but it has not yet been audited. The related protocol will be examined in more detail and feedback will be provided.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nIntegrated the Proof of Equivalence document and validated the design. It seems that we now have a protocol that meets the requirements.\nThe StarkNet DA structure was reviewed again for Proof of Equivalence.\nWIP: continuing with the PoC, understanding whether Risc0 is a viable option (progress).\nIntegration of Risc0 zone PoC into CL note and partial tx model: we have the zone POC hooked into the CL UTXO model, but proof times are not where we want them. We are currently at 8 minutes to generate a proof, almost all of that is coming from the Pedersen commitment to the note value. All the work is being done in this PR.\nWIP: Trying to bring the death constraint proof time down to something manageable.\nEvaluation of SP1’s viability for CL: SP1’s outer proof takes 13 minutes to prove. The numbers were confirmed with SP1 devs. This is too slow for us to use. SP1 devs suggested they may support swapping out plonky3 for groth16; If they do that, we should re-evaluate.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nTestnet updates from the testnet branch now (deployments happen from the testnet branch) - Nomos PR, Infra PR. This is done to have more control over what runs in the testnet.\nEnabling/Disabling tracing using feature flags or config at runtime - PR. Added the ability to build the node without tracing, or toggle tracing via config if built with this feature.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-07-08":{"title":"2024-07-08 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nThe new mixnet executable spec is being updated in the PR #98 but has not been merged yet. The new spec will be reviewed for changes that need to be updated in the executable spec.\nUpdated mixnet simulation is in the branch of nomos-specs, a PR hasn’t been opened yet because additional team discussion is needed to check whether it meets our analysis requirements. A document has been prepared to explain what the simulation can do and how its result can be used. Based on this, we will discuss what needs to be done as the next experiment.\nUpdated mixnet gadget document with queuing designs: added a section about queuing mechanisms. There are two flavors, one is time bounded and another is time unbounded. Time unbounded is better from the privacy perspective as an adversary will not know any upper time limit during which a message is going to be propagated. Also presented two versions of the unbounded with discussion about the design properties and their impact on privacy.\nStarted working on the level 1 noise generation mechanism, it is sketched in the NomMix design already but requires more refinement. In short, the idea is to introduce another type of noise (cover traffic) that will be limited to some threshold (to protect the network from spam) and its generation will be incentivized to encourage nodes to send it.\nDiscussed how to proceed with simulations and analysis of the mixnet. One of the outcomes is a design of a new model that can be used to describe the network which is connection oriented (rather than node oriented) - more details in the point below.\nTo model communication in the network, considered two approaches: the “node-centred” and “connection-centred” . The former assumes that only the state of a node (such as sending, receiving, etc.) is observed and the latter assumes that also connection is observed. Also, considered Hamming distance as a measure of distance between systems with LEVEL 0 and LEVEL 0 + LEVEL 2 noises, i.e. the difference between a system which “communicates” and “doesn’t communicate”. This work is summarised in this document.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nWIP: (DA python PoC) Executor large number of persistent connections to remote host test - During the offsite, there were some concerns raised that the executor might not be able to keep a large number of open connections to remote hosts. A test using a python DA Node and Executor was performed, having the executor connecting to multiple instances of DA Nodes on a remote machine. Results need to be formally documented, but simple tests of pushing data over thousands of persistent TCP connections to a remote host succeeded on commodity hardware.\nWIP: (DA python PoC) PoC of Executor dispersal and sampling protocol for direct connections - A simple executor node is in progress - initially it was used for the connections feasibility test, now it’s developed further to work with the DA Node used in the subnet PoC.\nCreated the Runnable DA PoC Specification.\nUpdated the GitHub repo with current code (Status: Simple python DA nodes and simple python DA Executor implemented; executor can send packets) - WIP PR.\nTweaked the DA encoder benchmark to cross-check data &amp; column sizes.\n\nDevelopment §\n\nNo updates this week.\n\nPPoS/Consensus §\nResearch §\n\nWIP: fixing a bug that was found in the wealth concentration code and producing and analyzing all simulation results again, based on the fix.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nCL PoC plan has been added to Notion.\nDid a few more prover optimizations in this PR.\nSummary of all the CL specs has been created.\nThe Caulk paper is being studied. The protocol is understood in general terms. The SemaCaulk definitions have been reviewed. A general description and protocol steps have been added for the related protocol here. Since KZG is used instead of a Merkle tree, proof calculations are faster. Creating a proof of set membership involves precomputation and quick proof generation. Precomputation can be done early and updated efficiently, while proof generation is fast and constant-time.\nResearch has been done on which other zkVMs could be tested for the CL. Also talked to external contributors to get a second opinion on the topic. Written the initial notes (not very detailed) about the related protocols here.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nPrepared Nomos Explorer architecture document.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-07-15":{"title":"2024-07-15 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nPR #98: Updated/refined the mixnet executable spec according to the newly written (WIP) spec. It’s being reviewed at the moment and is soon to be merged.\nPR #104: Modified the Sphinx encoding to support an arbitrary length of mix route and arbitrary maximum size of payload. Now we can let nodes select the length of mix nodes (not to exceed the max limit) and encapsulate a message larger than 1K (hardcoded in Loopix Sphinx) into a single Sphinx packet, while ensuring that all Sphinx packets have the same size.\nPR #105: Updated the simulation according to the newly written (WIP) spec. Also made it accept different randomness seeds for each module to make each of them deterministic independently. This is the first working version, which we can extend over and over.\nWorked on the level 1 messaging noise generation section, focused mostly on the motivational part at the moment. It’s noteworthy that the effectiveness of the mechanism is tightly coupled with the application of the queuing mechanism. Currently working on a better way of presenting the whole motivation. However, this does not block defining the noise generation mechanism, which is the next thing to do.\nLooked at ways to model the queuing mechanism (temporal mix). Our current approach is to treat it as a timed pool mix, which is well studied and provides us with analytical tools that we can use. However, later on, it was realized that it might not be the best model to use as we are deviating from a general mix to a task-specific mix which we might not be able to reflect using the timed pool mix. Nevertheless, it still looks like a good starting point that we can modify for our particular needs.\nReviewed mixnet gadget specification, and consequently decided on how to move forward with simulations and further implementation.\nStarted an analysis of the queuing system: in particular, considered the random process (outlined in this document) which governs the out-queue of a single connection. The latter is a variant of the pool mix and we have set up an analytical framework, based on previous studies such as the paper “Towards an Information Theoretic Metric for Anonymity,” which will allow us to study statistical properties of out-queues. The summary can be found in this document.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nPR #672: Added the verifier benchmarks. The data from benchmarks can be seen in this Notion document.\nWIP: Started the libp2p nomos DA subnetworks implementation document.\nPR #100, direct DA connection protocol: Defined the executor to DA node direct connection message types using protobuf. The code is targeting the da-poc branch in Nomos Spec to be used with subnets PoC.\nPR #99: Finalized the first version of the Runnable DA nodes PoC (ready for review).\n\nDevelopment §\n\nNo updates this week.\n\nPPoS/Consensus §\nResearch §\n\nAdded the Proof of Leadership specification to Notion. The first implementation in Circom, the one with sha256 (that didn’t take review into account) can’t be executed right now due to hardware requirements—however, this will be solved with the machine the team can now use. The implementation with the Anemoi hash function (that takes reviews into account =&gt; Taylor of order 2, more note inputs etc.) is not released yet.\nWIP: Finalizing studies 1 and 2 of the wealth concentration work. Results and report about wealth concentration can be found here but still not in a readable format.\nWIP: Continued implementing the Python code to analyze the selfish behavior when choosing the fork rule. This is created by adapting the Cryptarchia spec from the nomos-spec repository.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nHad a deep dive into Preconfirmations and Based Sequencing and created this document based on it.\nPR #102: Implemented the nullifier proof (as part of the implementation of the user side of the cross zone atomic transfer PoC).\nPR #103: Set up the infrastructure for using risc0 for CL proofs and integrating the nullifier proof from PR #102 with the CL. The nullifier proof takes about 5 seconds on a local MacBook (without Groth16 wrapping).\nWIP: Started a design of a trustless bridge for user-zone funds.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nPR #673: Added a base debug span, consensus, and da-verifier span for tracing logs.\nInvestigated minor CI issues and made a temporal fix for Nomos Node to build with libp2p and rustls (discussion in the relevant PR #673). For now, the rustls version is pinned, will be reverted after this issue is resolved.\n\nUser Tools §\nResearch §\n\nStarted the nomos-lib document (main document to abstract what we need for different binaries external to the nomos-node).\nStarted the nomos-cli document (first approach to interact with the nomos network).\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nListed future research projects, as Key Differentiators of Nomos vs other projects, document.\nUpdated the nomos-pm repository issues for the insights dashboard.\n"},"nomos/updates/2024-07-22":{"title":"2024-07-22 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nAll new mixnet-related PRs in the nomos-specs have been closed. New PRs will be opened once we’re ready to write the technical specs.\nSimulations are now being added in the nomos-simulations repository.\nPR #6: The initial mixnet simulation is ready to be reviewed. This PR has some missing pieces that will be added in the next PRs (to make the PR smaller and easily check if the simulation works correctly).\nPR #7: Now using gossiping for broadcasting after mix.\nPR #9: Added dissemination time measurement.\nUpdated the Noisy lottery section and worked out the details of the level 1 messaging noise generation mechanism, with a collection of algorithms that gradually build up the complexity.\nAs a result of the process of reducing complexity and clarifying the objectives of what we want to analyze and simulate, written a dictated subsection for simulation and analytics for the queuing mechanism.\nAnalysis of the queuing system in the Nomos Mixnet node: considered a queue of messages where a message is removed with probability q from the queue, i.e. the “coin-flipping”. The number of attempts to remove a message from the queue follows a Geometric distribution with parameter q. The latter was verified by simulation of random sampling. Based on this, it follows that a message is delayed in a node by at least RΔ, where Δ is some constant related to the implementation of the queue, with probability (1-q)^R. The summary can be seen here.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nPR #100: Direct DA connection protocol - added session control message type, simplified Dispersal and Sample error messages. This has been merged into the da-poc branch, it’s now in the nomos-poc repo.\nPR #5: DA feasibility test for a large number of UDP connections - investigated how a large number of connections would affect different network topologies.\nPR #6 (moved from nomos-specs): Finalized and merged the PoC PR. Based on this, the documentation has been updated accordingly.\n\nDevelopment §\n\nNo updates this week.\n\nPPoS/Consensus §\nResearch §\n\nThe first version of the Proof of Validator has been prepared in this document.\nWIP: Finalizing studies 1 and 2 of the wealth concentration work (wasn’t able to do it last week because the simulations took way longer than expected). Results and report about wealth concentration are here but still not in a readable format.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nFinalized the Proof of Leadership specification with error analysis.\nPR #3 added - for Proof of Leadership circuits (in circom).\nPR #106: Defined and implemented the input proof. The input proof verifies the statement that the ptx input has a valid nullifier, the balance commitment was computed correctly, and reveals a death commitment that was used to spend the note.\nPR #4: Balance commitments had a design bug that had broken input/output unlinkability, now resolved.\nPR #7: Transfer PoC. This introduced 2 more types of CL proofs: Output and Bundle proofs. Also built up the proof infra around this to allow constructing a fully proved transfer transaction that could be placed on chain.\nPR #2: Defined and implemented the first version of zone funds death constraints.\nExpanded the Preconfirmations and Based Sequencing document with new research.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nNo updates this week.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-07-29":{"title":"2024-07-29 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nRan the initial simulation to compare queuing mechanisms, but found that it’s better to design a specifically targeted simulation (which focuses only on queuing mechanisms) instead of using the full-cycle simulation (which simulates the full features of the protocol).\nWe prepared the simulation strategy, and simplified the simulator according to the strategy (maximizing code reuse). The simulation results can be found in the Queuing Mechanism: Message Dissemination Time Experiments, though this report is not the final version. The result consists of the largest set of data (It took 48h+). More analysis needs to be done on the result data to make a decision on the queuing mechanism and recommended parameters. So far, we found that the Noisy Coin Flipping Queue shows the optimal dissemination time compared to other queuing mechanisms, but we don’t want to jump to conclusions. Other aspects besides dissemination time need to be tested.\nIn the process of enabling better progress with simulations and analytical work, wrote a methodology document that will guide our efforts in understanding the queueing mechanism’s impact on the network and its general properties.\nAnalysis of the queueing system in the Nomos Mixnet node: considered a message going through k nodes where the queuing system of each node delays the message. Assuming that a message is removed with probability q from the queue, the probability distribution of the total delay is the negative binomial. From this follows that the average total delay is \\frac{k}{q}​. Calculated the upper bound on the probability that the total delay is greater than the average \\frac{k}{q} by the factor 1 + \\epsilon. The upper bound suggests that the mentioned probability is a monotonic decreasing function of k, q, and \\epsilon. The aforementioned work is summarized in Notion.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nDraft version of DA technical specification added.\n\nDevelopment §\n\nPR #678 DA Protobufs: DA Prost integration merged - generates rust structures for protofiles as a build step.\nPR #681 DA Protobufs: DA Network message types merged - Dispersal, Replication, and Sampling protocols defined as protofiles and exposed as a module in nomos-da/network/messages.\nPR #679 CI Improvements - DA Indexer integration tests improvement merged - Integration test now better determines when to expect a specific blob_id in a block received via the network. This test will be used with the new DA dispersal protocol.\nResearching attacks on DAS; understanding better the interactions between DAS and consensus, MEV, and the properties of our current design - summary.\nPR #680 - started implementing DA network stack: sketched up crates, created basic structure for 3 subprotocols (dispersal, replication, sampling), implemented Replication subprotocol (non-working, we have a bug). Also added base contract for the DA networking layer on the nomos node. That way we can start integrating it into the DA services.\nPR #683 - added DA network adapter trait in mempool (first step in adapting the mempool to continuously sample and verify).\n\nPPoS/Consensus §\nResearch §\n\nPR #10 - 1st Proof of Validator PR in Circom with Merkle tree.\nExtended the Proof of Validator specification.\nContinuation on reporting on studies 1 and 2 of the wealth concentration work (also redoing certain figures and improving the way results are compared) - results and report are getting in shape.\nPR #9 - Proof of Leadership spec implementation in risc0.\nWorked on the Caulk library  to understand the details of the Caulk Rust implementation. There was an error when the prover was run multiple times during the proof verification process. This error was fixed. Additionally, benchmarked the proof and verification performances for different elliptic curves. The results are added to the spec document.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nThe circuit design and details used in the Zcash spec were reviewed. Sprout and Sapling circuits are older designs. The Orchard circuit is the most current version, and its cryptographic structure is already the design we are using as a reference. Relevant notes were added to this document.\nPR #8 - Nomos native zone deposit tx.\nWIP: Nomos native zones bridge deposit.\nPR #11 - added death constraints to the transfer scenario; in this scenario, we don’t do any interesting account abstraction so the death constraints are proofs of no-ops. With this change, CL is “feature complete” for the purposes of the PoC.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nPR #682 CI Improvements - Protoc build deps for testnet and Jenkins CI merged.\nPR #684 Rust 1.80 (opened, not merged yet) - added an allow[dead_code] for Nonce in consensus for Clippy. Unused methods in da libp2p will be handled in separate PRs.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-08-05":{"title":"2024-08-05 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nNomos Mix simulations: message dissemination time by queue type - Session 1: Measured message dissemination time using 20~80 number of nodes, for each 5 queue types. Noisy Coin-flipping queue shows the lowest dissemination time when there are less number of real messages flown in the network, but shows the worst, if not. Random Sampling queue or Permuted Coin-flipping queue show around 2x longer dissemination time compared to the Non-mixing queue, but the performance degradation is relatively low, as the number of real messages increase. This is the initial interpretation of the result, which we can’t make a conclusion based on.\nNomos Mix simulations: message dissemination time by queue type - WIP: Session 2: This experiment is still running. This runs more nodes (100~10000) than the session 1, to see how each queue performs in the larger network. Also preparing next experiments: measuring how long messages stay in the queue.\nExtended the methodology document with more parameters for message dissemination experiments. Found one paper that measures properties of the Monero network which also include the node connectivity levels, an extract of it can be found here.\nDesigned another type of experiment, that is devoted to observing the quality of “temporal mixing” for a single node on a single path. The results of which will give us better understanding of the predictability of delaying of each of the queues and guide our decision during the selecting process.\nThe results for the first session of simulations give some intuition about the impact of each of the parameters on the dissemination time. However, it’s too early to conclude as the quality of mixing is another part of the equation and it’s our main focus now.\nStarted looking at the payment mechanism for the mixnet.\nAnalysis of the queueing system in the Nomos Mixnet node: considered the FIFO (First In First Out) attack where two sender nodes send messages through k mix nodes to the receiver node. The latter is controlled by an adversary which is also capable of observing other nodes. For a mix node where a message is removed from its out-queue with probability q, derived an expression for the probability of success of the FIFO attack. This probability can be computed numerically by creating a large population of random variables (wrote a code for the latter). Using this framework, showed that the probability of success of the FIFO attack is a monotonic decreasing function of the number of mix nodes k and is bounded from below by ½. Also showed that having different q parameters for sender and mix nodes can reduce the probability of success of the FIFO attack. Finally, showed that heterogeneous latencies of connections can increase the probability of success of the FIFO attack.\n\nDevelopment §\n\nPrepared the engineering PoC in Notion.\n\nData Availability §\nResearch §\n\nDA technical specification has been updated.\n\nDevelopment §\n\nPR #686: DA BlobInfo instead of Certificate - Removed Certificate and Attestation definitions, introduced DispersedBlobInfo trait and implementations. Also updated the DA mempool, integration tests and other components to use BlobInfo.\n(WIP) DA Mock network service for CLI app: still in progress preparing various components for the updated CLI App.\nPR #685 - finished implementing/fixing the DA network replication layer.\n(WIP) Started implementing the DA network dissemination layer - finished the validator behaviour and started the executor behaviour.\n\nPPoS/Consensus §\nResearch §\n\nFinalized the Proof of Validator specifications.\nPR #10 - 2nd Proof of Validator in Circom with Caulk.\nThe implementation for the Caulk usage scenario was prepared, and the results were added to the document.\nStarted analyzing the usage of the PoL as a PoV.\nFinalizing reports 1 and 2 of the wealth concentration work: the results are mostly in shape.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nPR #17: integrate the zone withdrawal logic with CL ptx/note structure.\nPR #13: users could create as many zero-valued outputs as they’d like without affecting the balance of a partial tx, the implications of this was not clear so we decided to ban zero-valued outputs for now until we understand what is going on.\nPR #14: boilerplate for the user atomic transfer ptx.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nNo updates this week.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-08-12":{"title":"2024-08-12 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nImproved the simulation to avoid out-of-memory (OOM) issues—an unexpected bug. If we run heavy simulations with 90+ processes on the server, the total usage of system memory is very high, and OOM occurs after 10+ hours. We modified the handling of intermediate results to minimize memory usage.\nMeasuring the Message Dissemination Time by Queue Type (Session 2.1) - because the session 2.1 simulations are too slow, we are profiling the internal behaviour of the simulation to find if something is wrong. So far, everything looks fine. The amount of computations looks correct. But, there are still more things that we need to check at the moment.\nWorking on reducing the time complexity of the experiments from the parameters perspective and prepared reduced parameters for session 2, called 2.1. Afterwards, designed Session 3, and Session 4 for evaluating the behavior of a node with non-homogeneous peering degree. Finally, defined experiment 5 which should deprecate all previous experiments as it simulates most closely the behavior of the network. Relevant document.\nDesigned a responsive version (two flavors) of the queuing mechanism, that alters the probability of releasing the message from the queue when the same message is received from another queue by the node. This is a more elegant solution which should deprecate all others if performing well (delay and statistically wise). Relevant document.\nStarted drafting some high-level requirements for the pay-per-mix design. Heavy work in progress - relevant document.\nAnalysis of the queuing system in the Nomos Mixnet node: continued with the analysis of the FIFO (First In First Out) attack where two sender nodes, observed by an adversary, send messages through kkk mix nodes to the receiver node, corrupted by the adversary. Considered a scenario when a message is delayed by the sender node by 1qS\\frac{1}{q_S}qS​1​ (on average) and by the mix node by 1qM\\frac{1}{q_M}qM​1​ (on average). Here qSq_SqS​ and qMq_MqM​ are, respectively, probabilities of removing a message from the out-queue of sender and mix nodes. Computed the probability of success of the FIFO attack for different ratios ρ=qSqM\\rho = \\frac{q_S}{q_M}ρ=qM​qS​​. The probability of success of the FIFO attack approaches the lower bound 12\\frac{1}{2}21​, where the adversary doesn’t have any advantage over random guessing, with an increasing number of mix nodes kkk much faster for higher values of ρ\\rhoρ. However, even for higher values of ρ\\rhoρ the probability of success of the FIFO attack is increasing if the difference in latencies of connections, of two sender nodes to the first mix node, is greater than some threshold. This work is summarized in this document.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nUpdated the DA Technical Specification.\n\nDevelopment §\n\nPR #688 - Finished implementing/fixing the DA network dispersal layer: implemented executor behavior, implemented validator behavior and implemented interaction test for both behaviors.\n(WIP) PR #689 - Finished implementing/fixing the DA network sampling layer.\n(WIP) PR #690 - DA Mock network service for CLI app: all parts (services, adapters, etc.) are defined and interconnected, finishing up mock implementations. Progress is a bit slower than initially anticipated with the CLI App.\n\nPPoS/Consensus §\nResearch §\n\nConcluded that Caulk is not that interesting for improving proof of membership.\nFinalized the section about “Follow the Protocol” on the wealth concentration work.\nDropped the analysis of the PoV based on PoL analysis.\nPoV spec: The main motivation for implementing Caulk was its fast update process. We examined how many operations are required for Merkle-tree updates at specific depths and compared this with point addition and multiplication on the Caulk side. For Caulk, if the updates are to be made, this value is added linearly to the process, whereas this isn’t necessary for Merkle-tree. It was observed that at 2122^{12}212 notes, the values are almost equal, and even at 2202^{20}220 notes, the difference isn’t significant. For this reason, we agreed that itisn’t necessary to spend too much time on Caulk. Additionally, for Caulk, the proof of Pedersen equivalence would also disadvantage us in terms of proof size and constraints. The spec work for PoV has been completed. This is the latest version using a Merkle tree.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nPR #15 - Added strong zone notes validation by zone ID.\nPR #16 - Added metadata to zone notes to allow for correct funds/state note validation.\nPR #19 - Refactored zone auth.\nPR #20 and PR #22 - Added support for atomic transactions.\nCreated a table for notable zkVMs in the literature, currently filling in the details by reviewing the designs.\nAdded the necessary details and definitions for ZCash in the relevant document.\nPR #21 - Integrated the zone deposit scenario.\nPR #23 - User side of the atomic transfer transaction.\nPR #24 - Full atomic transfer transaction.\nWith the previous three PRs (in combination with previous work), we’ve got the full atomic transfer transaction working end-to-end! We still need to do some performance work to ensure executors can build a transaction within the 20s target block time (current proof time is ~400s).\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nNo updates this week.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-08-19":{"title":"2024-08-19 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nRewrote the Queue Mechanism Simulations in Rust to make them much faster even with heavy parameters. This version does not use any bloated simulation framework (previously used in Python) and contains only the core logic we want to test. Result: more than 5x faster than the Python version. This is in the git branch, as a PR hasn’t been opened yet. The entire Mixnet Workgroup will review the new code this week.\nAdded additional experiments: Experiment 5 and Session 3.\nAdded additional queue mechanisms: NoisyCoinFlippingRandomRelease has been added. Two other additional mechanisms will be added this week.\nPlanning the set of experiments that we need to run for the next iteration and decided to improve the way we are scheduling them and keeping track of them.\nMade small tweaks to the parameters set for the sessions 2-4 - decided to use a fixed transmission rate as it does not impact the results of our simulations and reduces the number of experiment cases by 2/3.\nConsidered a node sending a message to all N−1 nodes of the random network: a message traveling from a node to its neighbour is delayed by the amount of time spent in the out-queue + the connection link latency. Assuming that the random network is locally tree-like, which includes networks prescribed by distributions of node connectivities, the time to deliver a message to all N−1 nodes is equal to the maximum delay over all paths from the sending node to a receiving node. For a node sending a message to its neighbours, calculated the distribution of the maximum delay. The summary can be found here. Analysis of a message sent from a node in a random regular graph is currently in progress.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nRefined the DA Technical Specification further; it is in green status now (reached the implementation phase).\n\nDevelopment §\n\nPR #689 - finished implementing/fixing the DA network sampling layer. Had to rewrite a significant portion of it as the underlying protocol didn’t work as expected.\nPR #690 - DA Mock network service for CLI app: implemented dispersal of kzgrs encoded data using DA network service with a mock backend (same service will be used with the libp2p backend that will be worked on this week).\n\nPPoS/Consensus §\nResearch §\n\nDeveloping the code to study the selfish behavior of stakers (within the wealth concentration context).\nConducted more statistical analysis of the “follow the protocol” study.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nBenchmark results for zkVMs have been updated, and additions have been made to the ZkVM document on Notion.\nWhile working on OlaVM, discovered they are working on Brakedown PCS to speed up proof generation in the future. An explanation about Brakedown has been added to the proof survey document. It also appears to be compatible with Plonky3. Relevant developments will be monitored.\nPublished the report on the results of the atomic transfer PoC.\nPublished a writeup on Permissionless Notes. This resolves some of the problems we had with how adversaries had control over nullifiers which could lead to nullifier collisions and unspendable notes. (An adversary could engineer a note that had the same nullifier as a zone note and could make the zone note unspendable).\nPR #27 (PoCs) - implemented collision-resistant nullifier idea from the permissionless note writeup.\nPR #28 (PoCs) - implemented nonce evolution ideas from the permissionless note writeup.\nPR #29 (PoCs) - implemented in-zone signature verification (adds 60s to atomic transfer scenario time). This gets out the PoC to a realistic enough scenario that we can start optimizing.\nPublished several documents as solutions for Immediate Zone Data Availability and for the issues derived from our long finality times: Timely Data Retrieval for Permissionless Executors and Zones, Finality, and Preconfirmations. These topics might require more work, especially as we discuss them and see what impact they bring to the current design.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nNo updates this week.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-08-26":{"title":"2024-08-26 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nMajor effort was devoted to advancing the Ordering Experiments descriptions to cover more complex scenarios, to unblock the progress of simulations. The work was successful and all scenarios have been described, discussed, and implemented. The whole section contains six generalized experiments that cover three different topological settings with two mix node behaviors. The set of parameters was adjusted to be able to finish on time based on a set of benchmarks that we ran. More on that here.\nThe Experiments Tracking document was updated to include new experiments. A decision was made to run experiments from the most comprehensive and computationally heavy (6th) down to the lightest (1st). This way we can consider making an analysis quicker and wait for supportive results.\nImplemented and ran the Ordering Measurements. Implementation can be found at this branch. A PR hasn’t been opened yet since some parts need to be cleaned up, and we wanted to quickly implement the new experiments. However, we took the time to check that the experiments work as intended. Also, ran the benchmark to estimate the duration of experiments.\nWe are currently running all the experiments (in order from heaviest to lightest). All of them are expected to be done by 6th September.\nAnalysis of latency in the Nomos mix network: considered a node sending a message to all N−1 nodes of the random network. A message traveling from a node to its neighbor is delayed by the amount of time spent in the out-queue plus the connection link latency. Defined the distance between nodes i and j as the minimum latency of a message sent from node i to node j. For node 1, the maximum overall distance to N−1 nodes is the latency of broadcast. Using this definition, considered the latency of broadcast on the network with the topology of a complete graph. The latter is a special case of a random regular graph. Developed code to compute the latency of broadcast for networks with the topology of random regular graphs. This work is summarized in this document. Analysis of a message sent from a node in a random regular graph is currently in progress.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nPR #691 (Node) - created the aggregated protocols behavior swarm and implemented the DA network backend with the aforementioned libp2p swarm.\nPR #693 (Node) - updated DaBlob struct and related code to include column index.\nPR #694 (Node) - added an ability to store and load DaBlobs with different column indexes in DA Storage (used by validator, indexer, will be required by the sampling service).\nPR #695 (Node) - implemented the DA network backend with the above libp2p swarm.\nPR #698 (Node) - implemented subnetworks membership algorithms: - v1: filling with available nodes.\nPR #701 (Node) - executor libp2p backend implementation: swarm implementation for Nomos Cli app using libp2p executor behavior- PR #702 (Node) - implemented subnetworks membership algorithms: - v2: filling with available nodes with extra replication on the original data columns subnetworks.\n\nPPoS/Consensus §\nResearch §\n\nContinued development of the code to study the selfish behavior of stakers (within the wealth concentration context).\nIntegrated the statistical analysis of the “follow the protocol” study (within the wealth concentration context).\n\nBlockers: None\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nConcluded the VM analysis: after reviewing the candidate zkVMs, we decided that continuing with Risc0 is the most suitable option at this stage for our Native Zone needs. SP1, Jolt, Cairo-VM, and Nexus will be among the VMs we continue to monitor, but Risc0 appears to be the best choice for now.\nPR #31 and PR #33 (PoCs) - performed optimization of native zones: use basepoint as the blinding point and provide state roots instead of whole state.\nPR #32 (PoCs) - built isolated proof scenarios to aid benchmarking work.\nPR #34 (PoCs) - aggregated input/output proofs into a single partial transaction proof.\nPR #35 (PoCs) - moved the blinding to the partial transaction level instead of blinding each note value individually.\nPR #36 (PoCs) - switched from Pederson balance commitments to hash balance commitments.\nPR #37 (PoCs) - modelled zone transaction log with MMR.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nNo updates this week.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-09-02":{"title":"2024-09-02 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nCurrently in the process of researching a couple of potential designs for pay-per-mix, starting from a form of non-interactive and off-chain rate limiting, then trying to construct a form of payment on top of that. These are considered without compromising the privacy properties of the Nomos Mix. The first version can be seen in this document (WIP).\nConsidered the latency of a broadcast in the high connectivity regime of communication networks. In this regime, a node is connected to a fraction of all nodes in the network. Assumed that a message delay is governed by a Geometric distribution with parameter q, i.e., a message is removed from the out-queue with probability q, and a constant delay in communication links. For this model of delays, the latency of broadcast, computed numerically, converges to 2 units of time as the number of nodes, N, in the network grows. However, the distribution of delays can be very broad for a small q (and small N), suggesting that in a high connectivity regime to have q≥12q \\geq \\frac{1}{2}q≥21​ is more desirable. This work is summarized in this document.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nPR #704 (Node) - added the DA Network to the Nomos Node.\nPR #705 (Node) - finalized Sampling Service PR without backend.\nPR #706 (Node) - fixes and updates to traits, service implementation, and libp2p network backend implementation.\nPR #708 (Node) - (WIP) plugging sampling into consensus.\nPR #709 (Node) - implemented the backend (including tests). Currently in review.\nPR #710 (Node) - implemented a few fixes to the sampling service backend.\nPR #711 (Node) - added integration tests for dispersal using Nomos Cli.\nPR #712 (Node) - added the sampling service rng suggestion to the Nomos Node.\nPR #713 (Node) - added the Verifier and Indexer to the Nomos Node.\n\nPPoS/Consensus §\nResearch §\n\nPR #114 (Nomos-specs) - included the PoL using (using the randomness of the last PoL for the slot) in the code spec.\nConcluded the development required to run selfish behavior simulations. Also ran a few simulations to observe the occurrence of classes of validators, occurrence of blocks, and forks. Based on that, included a few more paragraphs in the Selfish Behavior section and created the PoS model.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nCircle Stark protocol steps and the verification implementation steps for Stwo have been prepared in this (WIP) document (we generated the first Stwo proof using Poseidon hash function for the oracle).\nAdded a report on the Coordination Layer PoC.\nCL Spec has been updated to reflect the changes from PoC.\nAtomic Transfer report has been finished.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nNo updates this week.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nQ4 planning for development is currently in progress - WIP document.\n"},"nomos/updates/2024-09-09":{"title":"2024-09-09 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nOrdering Measurements: Performed experiments 5 and 6 of the ordering measurements (which are the heaviest). Experiment 6 took more time than expected due to randomness in some queue types. We had to lower one parameter (the number of messages generated) to finish the experiment in a reasonable time. Additionally, we implemented an optimization to reduce gossip traffic. As a result, both experiments 5 and 6 were completed by Thursday (2024-09-05).\nOrdering Measurements: Since 2024-09-06, we have been analyzing the results of the latest experiments, focusing on the average number of data messages in queues, the average latency for messages (from sender to receiver), the ordering coefficients (to compare the mix effects), and the calculated outputs: exp5 and exp6. These are not yet nicely visualized reports but can be analyzed in detail by the Mixnet Workgroup. The ordering coefficient for experiment 5 is still being calculated.\nWe identified information leakage in the noisy lottery design, which we started addressing by generalizing the lottery to the l-hop case. Instead of a single hop, we added more hops to better mimic data traffic. This reduced the leakage, but it requires modifications to the payment mechanism for noise generation, which is in progress.\nThe discovery of this issue came while working on the payment mechanism for mixing, which is advancing but requires modifications to align with the noisy lottery. This is not fully documented but can be found here.\nAnalysis of latency in the Nomos mix network: We analyzed the latency of a broadcast in the finite connectivity regime of communication networks. In this regime, a node is connected to a finite number of other nodes in the network. We assumed a network of size NNN has a topology of a random regular graph with connectivity ccc. Message delay is governed by a Geometric distribution with parameter qqq, i.e., a message is removed from the out-queue with probability qqq, and a constant delay in communication links. For this model, the latency of broadcast (divided by log⁡(N)\\log(N)log(N)) converges to some (non-random) value, depending on qqq and ccc, as NNN grows. Furthermore, for small qqq, the latency of broadcast is consistent with 2log⁡(N)(c−1)qc(c−2)\\frac{2 \\log(N)(c-1)}{q c(c-2)}qc(c−2)2log(N)(c−1)​ but deviates for larger qqq. From this, it follows that latency grows as log⁡(N)\\log(N)log(N) with NNN in the finite connectivity regime. This work is summarized here.\n\nDevelopment §\n\nNo updates this week.\n\nData Availability §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nPR #715 (Node) - implemented DA network in the verifier libp2p adapter.\nPR #722 (Node) - implemented trigger sampling from DA mempool.\nPR #723 and PR #725 (Node) - implemented trigger sampling in Node.\nPR #729 (Node) - first attempt at storage relay (closed due to incompatible types).\nPR #730 (Node) - implemented incoming sampling request handling.\nPR #731 (Node) - implemented adding column index in the sample requests.\nPR #732 (Node) - implemented get_blob on sampling RocksDB adapter.\nPR #733 (Node) - implemented minimal correct configuration for two nodes participating in DA network to receive BlobInfo into a mempool, start sampling, propose a block with BlobInfo, and eventually provide available blobs via the indexer API for the requested AppID and range.\n\nPPoS/Consensus §\nResearch §\n\nPR #114 (nomos-specs) - added the first PR for the PoL Python spec.\nThe existing PoE design was reviewed, and pseudocode was prepared.\nFirst attempt branch for PoE spec (working but not acceptable in terms of cycles).\nExtended the PoV specs, which need some discussion and review.\nStarted studying the selfish mining problem in PoW and PoS - notes.\nAdded a few more paragraphs in the Selfish Behavior section.\n\nDevelopment §\n\nPR #718 and PR #721 (Node) - integration of leadership proofs in the node. We have an issue mostly around long CI times, and we might cut some corners at some point to unblock things until we get more powerful runners.\n\nCoordination Layer §\nResearch §\n\nUpdated zkVM benchmarks with a new VM (Lurk that is fast but leads to large proofs).\nPrepared notes from the sources read about Verkle trees and MPC for future studies: Verkle Tree and MPC.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nPR #726 and PR #727 (Node) - CI: Investigated Risc0 installation options. Apart from Metal not being available in GitHub runners, we also ran out of disk space. A self-hosted runner would be a solution - Infra Request.\n\nUser Tools §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/2024-09-16":{"title":"2024-09-16 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nCompleted the simulation: Queuing Mechanism: Ordering Experiments. All core experiments (5 and 6 of the session 1 &amp; 3) have been completed. All results and evaluations have been documented. The results have been discussed within the Mixnet working group, and the PermutedCoinFlippingQueue has been chosen as the first algorithm to be used for the Rust implementation, considering its good balance between latency and mixing quality. The research part has been also preparing further researches to improve it and find better approaches. The code of simulations was pushed to the nomos-simulations repository with detailed manuals.\nProposed a collection of protocols for the pay-per-mix design (we are trying to reward mixing and noise generation). Most of them are based on an assumption of indirect payments and probabilistic rewarding (for active network participants) which is the most respectful approach for upholding user privacy. The protocol complexity rises significantly if we change the assumption to more direct rewarding.\nThe Mixnet Workgroup has went through the experiment results and decided to go with Permuted Coin Flipping queueing mechanism which gives a good combination of latency and mixing properties.\nDefined another type of experiment to look more closely on a scenario where there is even less noise. We are also growing the network a bit so we might also observe the impact of the size of the network in the latency.\nAnalysis of latency in the Nomos mix network: considered the latency of a broadcast in the finite connectivity regime where a network of size N has a topology of random regular graph with connectivity c. Assumed that a message delay is governed by Geometric distribution with parameter q, i.e. a message is removed from out-queue with probability q, and a constant delay in communication links. The average latency of broadcast computed numerically is consistent with the expression 2\\log(N)(c-1)/(q c(c-2)) for small q. For larger values of q, and small connectivity c, the average latency of broadcast is consistent with 2\\log(N)(c-1)/(\\alpha\\log(1+q) c(c-2)) for some \\alpha\\approx 1. However, for the large c the latter holds only for small q. The summary of this point can be found here.\n\nDevelopment §\n\nStarted implementing the new Mixnet protocol in Rust: Discussed internally to determine the approach how to implement the mixnet protocol by following the libp2p way, as done for DA. We are aiming to have the first working version of the base mixnet protocol this week. It will contain only base components (GTR, Queuing, …) that have minimal implementations and can be extended.\n\nData Availability §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nPPoS/Consensus §\nResearch §\n\nStarted studying Deep Selfish Proposing in Longest-Chain Proof-of-Stake Protocols paper. - The paper suggests (i) to disburse block rewards as tx when blocks are proposed, instead of in a later stage (e.g., at the end of the epoch) based on the block ratio, because this prevents attackers from getting more rewards than they should; (ii) the fork choice rule can be “extend the first block the validator heard about”. Notes can be found here.\n\nDevelopment §\n\nPR #721 and PR #736 (Node) - completed the integration of PoL into the node. We now have a simple implementation on the node that would need to be improved for the final testnet. Next, we are looking into other possible options like accumulators, verkle trees, etc.\n\nCoordination Layer §\nResearch §\n\nUpdated the branch for PoE implementation for risc0. We get a proof in less than 2M cycles for 2048 coefficients over BLS scalar field.\nPR #40 (PoCs) - added PoE implementation in Circom to compare with risc0.\nAdded a document explaining PoE improvements in risc0, why we propose to use dedicated PoE not included in the STF of a zone and the results for Circom.\nCreated a private repo for the modified Stwo Wrapper. It can now support Poseidon over BLS scalar field and serialize the produce proof in a json file.\nThe ethSTARK paper was reviewed to understand the details of the Stwo prover.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet + Insights §\nDevelopment §\n\nNo updates this week.\n\nUser Tools §\nResearch §\n\n(WIP) Explorer design is in progress.\n\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nStarted writing NomosDA explainer series - content headers/skeletons for the NomosDA explainer series docs can be found here.\n"},"nomos/updates/2024-09-23":{"title":"2024-09-23 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"P2P Privacy §\nResearch §\n\nAdded a preliminary research note: Nomos Mix on Libp2p.\nStarted a major rewrite of the Nomos Mix design. The motivation for this is that the main document is not well-maintained and has become difficult to read, so there is a need to extract the most important parts of the design and clean up the entire documentation.\nAnalysis of latency in the Nomos mix network: Considered the probability that the latency of a broadcast is greater than some threshold t, i.e., the probability of the upper “tail.” For a network of size N, with a topology of a random regular graph with connectivity ccc, numerical simulations for q=12q=\\frac{1}{2}q=21​ suggest that the probability of the upper tails is a monotonic decreasing function of graph connectivity c. This analysis assumes that message delay is governed by a Geometric distribution with parameter q, meaning a message is removed from the out-queue with probability q, and that there is a constant delay in communication links. Comparing the same probability in networks with topologies of random regular graphs and trees suggests that the latter is an upper bound on the former. This work is summarized here.\n\nDevelopment §\n\nPR #765 (Node) - Implemented the libp2p stack for Nomos Mix. Currently under review.\n\nData Availability §\nResearch §\n\nAdded a NomosDA docs Introduction page draft.\n\nDevelopment §\n\nPR #764 (Node) - Nomos CLI dispersal and sampling testing: finalized sampling testing and added fixes and tests for CLI dispersal code. Nomos CLI acts as one of the nodes in the network using its secure key for DA communications.\nPR #764 (Node) - Replication testing and fixes: piped replicated payloads to the validator. Peers now dial to each other if they are in the same subnet. Integration tests are running 4 subnets with 8 nodes and a replication factor of 2.\n\nPPoS/Consensus §\nResearch §\n\nNotes on the problems encountered with merging blocks and potential solutions have been taken and added here. Due to privacy concerns, the cryptographic solution mentioned in Solution 3 is not feasible.\nNotes about selfish proposing in PoS have been added.\nAnalyzed the token design of comparable projects.\nWrote, shared, and discussed a solution for the “lazy nodes” problem in our consensus.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nMoved the Stwo repo to a dedicated nomos-pocs branch.\nIn the Stwo implementation, work continued on the DEEP FRI details for Circle STARK, specifically for the verifier part. A general note on the structure of the DEEP FRI protocol was added to the document prepared earlier for FRI.\nReplaced Rapidsnark with Tachyon for the Risc0 wrapper. The results were not useful, but they may be improved in the future, allowing us to reuse the implementation. Implementation, measurements, and discussions are available on Notion.\nStarted the Ingonyama Icicle review, identifying potential future improvements for DA.\nThe wrapper SageMath script is running the entire verifier, except for the last remaining part, which is FRI. We added an explanation on the DEEP method used for building the script.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet and Tooling §\nDevelopment §\n\nNo updates this week.\n\nMiscellaneous §\n\nAdded several notes regarding the ecosystem. These will be continuously updated with more content.\n"},"nomos/updates/2024-09-30":{"title":"2024-09-30 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"PPoS / Consensus / DA §\nResearch §\n\nFinished the PoV integration specification.\nStudied a simple model for the tokenomics of a PoS utility token.\nUpdated the Nomos Token Design Canvas.\nAdded more context to the DA dispersal specification.\n(WIP) Continued writing NomosDA explainer series first drafts.\n\nDevelopment §\n\nPR #764 (Node): DA - Finished and merged replication changes.\nKickoff executor binary: We plan to add missing pieces of the architecture for the testnet. The first step is having a running executor. PR #766 (Node) - created the binary crate. PR #768 (Node) - implemented (composed) executor network behaviors and added Swarm. PR #795 (Node) (WIP) - started network service implementation.\n\nMixnet §\nResearch §\n\nIn order to measure the latency and bandwidth of the Mix protocol, we prepared and ran a new experiment by introducing more realistic parameters simulating the behavior of the block leader (20s block time) and cover traffic, which is much lower than in previous experiments (performed to find the primary queuing mechanism) but still provides reasonable quality mixing. The report can be found here. Summary: We can meet the latency requirement (defined by the Nomos consensus protocol) if we limit the size of the Mix network to fewer than 100 nodes. However, the bandwidth consumption is under 80Kbps when the payload size is 320 bytes (i.e., block selection), but it exceeds 500Kbps when the payload size is 3200 bytes (= 100 tx refs * 32 bytes). This shows the difficulty of scaling to a large Mix network. We also need to clearly define the bandwidth requirement by specifying the payload size and related mechanisms.\nFocused on improving documentation. Wrote the following documents, which went through a review (though some sections still require revision): Introduction, Tier 1, Tier 2 (part 1), Tier 2 (part 2). These documents describe the design of the first iteration of the mixnet. The missing documents will add new features on top, such as (Tier 3) cover traffic and (Tier 4) incentivization mechanics.\nBegan estimating the minimal amount of bandwidth required.\nAnalysis of latency in the Nomos mix network: Considered the latency of broadcast in networks of size N with a topology of a random regular graph with connectivity ccc. For large N, a finite neighborhood of any node is a tree with branching factor c−1. Numerical analysis of broadcast latency in networks with topologies of random regular graphs and Cayley trees of various sizes suggests that the latter can be used to construct an upper bound for the former. We showed that broadcast latency on a tree can be computed recursively with numerical complexity O(N), which is better than O(Nlog⁡N) when Dijkstra’s algorithm is used. The recursion on a tree was used to derive a recursive equation for the probability distribution of broadcast latency on trees with branching ratio c−1, i.e., the probability distribution of broadcast latency for a finite neighborhood of large regular graphs with connectivity c. This work is summarized here.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nWe’ve decided to postpone research on the Stwo wrapper for now, and we explained the reasons in this document. In summary: the optimizations in Stwo, which reduce proof size, complicate Merkle proof verification, requiring additional computations by the verifier, which conflicts with the goal of a simpler verification process. Additionally, significant rewriting of the prover is needed for compatibility, and emulating field operations from M31 to BLS could negatively affect performance. The time and effort required for implementation, parameter tuning, and handling Circle STARK verification are much greater than expected. Given these challenges, along with the fact that Risc0 already provides a working wrapper with fewer complications, the anticipated benefits of continuing this work no longer justify the effort.\nTook notes on the ZkVM vs ZK Circuit discussion, shared here for future reference and added them to this document.\n\nDevelopment §\n\nNo updates this week.\n\nZone and Apps §\nResearch §\n\nStarted research on zones, exploring key questions and drafting initial thoughts.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet and Tooling §\nDevelopment §\n\nPR #797 (Node) - KZG-RS global params configuration for the testnet: updated configuration syncing between nodes and added Risc0 dependencies. After review, this can be deployed on testnet.nomos.tech.\nPR #767 and PR #770 (Node) - CI: Jenkins nightly jobs update - Risc0 setup for Jenkins nightlies. Added dissemination test alongside consensus. Docker build job for GitHub PR check to track missing dependencies.\n\nMiscellaneous §\n\nCreated a blog content plan until the end of the year.\n"},"nomos/updates/2024-10-07":{"title":"2024-10-07 Nomos weekly","links":[],"tags":["nomos-updates"],"content":"PPoS / Consensus / DA §\nResearch §\n\nFinished the PoV integration specification (added some details, fixed the validity period of a PoV, and added new diagrams). Currently under review.\nStudied the EIP-1559 papers, focusing on the transaction fee market and block rewards.\nAnalyzed “safety and liveness” in a variant of the Ouroboros consensus algorithm: Identified materials relevant to the “safety” and “liveness” properties of Cryptarchia, a variant of the Ouroboros Crypsinous consensus protocol. In the Ouroboros family (Ouroboros → O. Praos → O. Genesis → O. Crypsinous), the so-called “persistence” and “liveness” properties of the transaction ledger are proven. These properties are variants of the “safety and liveness” typically proven in BFT PoS protocols. The core mathematical tool used in the persistence and liveness proofs involves mapping (forked) chains to trees, which are then converted to a ternary string. This work is summarized in this (WIP) document.\nNomosDA explainer series (draft): Completed the NomosDA docs Encoding page.\nNomosDA explainer series (draft): Continued work on the NomosDA docs Dispersal and Sampling page.\nPCS Comparison for DA blog post is in progress.\nSimulation and analysis of Cryptarchia improvements: We modeled and started analyzing Cryptarchia improvements. The report is available here.\n\nDevelopment §\n\nPR #795 (Node) - Completed the implementation of the Executor network service.\nPR #801 (Node) - DA Executor HTTP API: Implemented the reuse of common parts to handle node-related requests and added the ability to allow custom executor request handling. Also, working on similar changes for node and executor config files.\nPR #805 (Node) - Added a DA Replication Membership test.\nPR #806 (Node) - Implemented the Dispersal service (encoding + dispersal).\nPR #808 (Node) - Implemented the reconstruction algorithm from the original pieces.\n\nMixnet §\nResearch §\n\nHeld internal discussions to define the details of the Nomos Mix protocol, especially regarding the role of Tier-1: Persistent Mix and the range where Tier-2: Temporal Mix is used. The output of the discussion is summarized in the discussion notes. Further discussion is still needed to solidify the first working version with low latency and bandwidth. Because of this, we couldn’t proceed with development as we aimed to clarify the protocol before starting any significant Rust codebase changes. Now that the major components of the Mix protocol are clear, we will begin writing the implementation while improving the specification documents. We will work on both spec writing and implementation in parallel, given our schedule.\nDeveloped a simple “calculator” to show the theoretical limits associated with bandwidth, latency, and network size. Based on the discussions, we decided to increase the mix network’s bandwidth allowance. We also aim to find a “sweet spot” between message dissemination latency, bandwidth, and network size. Additionally, the GTR part of the design needs to be revised in terms of bandwidth and latency.\nPushed the documentation effort forward, completing the last part of the core mix architecture, the cover traffic. The “core” defines the basic mechanisms that make the design work, without any incentives yet.\n\nDevelopment §\n\nNo updates this week.\n\nCoordination Layer §\nResearch §\n\nReviewed current methods for global state representation, including sparse Merkle trees, indexed Merkle trees, Verkle trees, and MMR structures. We prepared this report and concluded that previous schemes were complementary, not concurrent. In cases where the proposer cannot store the entire list of nullifiers, we may use a Bloom filter to check if commitments have already been consumed and apply a specific compression mode, such as Merkle trees, to compress it.\n\nDevelopment §\n\nNo updates this week.\n\nZone and Apps §\nResearch §\n\nNo updates this week.\n\nDevelopment §\n\nNo updates this week.\n\nTestnet and Tooling §\nDevelopment §\n\nPR #804 (Node) - Removed Graylog from Docker Compose configuration as the code will later be updated to use OTLP tracing format. WIP: Refactoring nomos-log to nomos-tracing, which will be composable with different layers: tracing, logging, metrics, and profiling.\n\nMiscellaneous §\n\nNo updates this week.\n"},"nomos/updates/Athens-Offsite-Notes":{"title":"Athens Offsite Notes","links":[],"tags":["nomos-updates","athens-all-hands"],"content":"Research §\nThe Nomos team has attended several meetings with different teams and internally. Most of these have been in terms of finding the right solutions for the Coordination layer, including but not limited to:\n\nProof aggregation techniques\nZK commitment schemes\nCL Inter-zone communication\nBridges\n\nBased on these discussions, we have compiled a preliminary version of the Coordination Layer Specification. There are still unknowns in this line of work, but we are of a unified mind that we are on the right track.\nEngineering §\nAt Nomos, there are some needs that could be covered by Vac. To be more precise: understanding on what Vac provides that could be helpful, understanding what is required for Vac to start on that support, a plan/pipeline for both teams to interact. Some of the proposals:\nDST:\n\nAt the moment, the most prominent project is the analysis of the Nomos mixnet.\nThis will serve as the first project interaction as it is also the highest priority.\nOngoing conversations on what is needed are already in place.\n\nQA:\n\nNomos node is in high need of a testing plan. But no real bandwidth for it.\nVac has specialized people with the experience and the workforce.\nCryptarchia and NomosDA would be the focus. But this is gonna be delayed until seen how the mixnet collaboration goes.\nAs part of this specifications will be reviewed by the Vac team so they can be improved. Eventually specifications will be forked and served as part of Vac too.\n\nComms §\n`Key Market Trends / Research §\nPrivacy Concerns:\n\nBuilding our case for privacy our protection and viability of the project. We need to define the terms of privacy and create that shield. Privacy is necessary for personal items to be possible, health, business, institutions. \n\nTechnical Narratives:\n\nLitenodes. Rules without a ruler\nData Availability Sampling\nRestaking\n\nDecentralisation \n\nWe can be more decentralised than any other blockchain ever. \n\n`Technical Milestones §\nProduct Development\n\n1st Milestone: Dark paper release, with a potential litepaper version.\n2nd Milestone: Testnet\n\n`Growth Plan  §\nTarget Audience: \n\nDegens: Refine for those who care and believers.\nInstitutions: Long term\nDevelopers/Contributors\nNode Operators: Long term.\n\nMovement Building (Community) - Educational Initiatives: \n\nRoles for incentivising culture, memes.\nAmbassador program\nDeveloper Outreach\n\nIncentive Programs \n\nLogos NFTs\nWhen we have zones we can get them to deploy during hackathons?\n"},"nomos/updates/index":{"title":"Nomos Weekly Updates","links":[],"tags":[],"content":"These are all the Nomos weekly updates that are reported to Logos Insight team."},"tags/component":{"title":"Components","links":["creating-components"],"tags":[],"content":"Want to create your own custom component? Check out the advanced guide on creating components for more information."},"tags/vac-updates":{"title":"Vac updates","links":[],"tags":[],"content":"Here are all files that are tagged with #vac-updates"},"terms-of-use":{"title":"Website Terms of Use","links":[],"tags":[],"content":"These terms and conditions (“Website Terms of Use”) are entered into by you and us, and they govern your access and use of the Website, including any content and functionality contained in the Website. \nIt is your responsibility to read the Website Terms of Use carefully before your use of the Website and your use of the Website means you have agreed to be bound and comply with these Website Terms of Use. \nIf you do not agree with these Website Terms of Use, you must not access or use the Website. \nDisclaimers §\nThe Website is provided by us on an ‘as is’ basis and you use the Website at your own sole discretion and risk.\nWe disclaim all warranties of any kind, express or implied, including without limitation the warranties of merchantability, fitness for a particular purpose, and non-infringement of intellectual property or other violation of rights. We do not warrant or make any representations concerning the completeness, accuracy, legality, utility, reliability, suitability or availability of the use of the Website, the content on this Website or otherwise relating to the Website, such content or on any sites linked to this site.These disclaimers will apply to the maximum extent permitted by applicable law. \nWe make no claims that the Website or any of its content is accessible, legally compliant or appropriate in your jurisdiction. Your access or use of the Website is at your own sole discretion and you are solely responsible for complying with any applicable local laws. \nThe content herein or as accessible through this Website is intended to be made available for informational purposes only and should not be considered as creating any expectations or forming the basis of any contract, commitment or binding obligation with us. No information herein shall be considered to contain or be relied upon as a promise, representation, warranty or guarantee, whether express or implied and whether as to the past, present or the future in relation to the projects and matters described herein.\nThe information contained herein does not constitute financial, legal, tax, or other advice and should not be treated as such. \nNothing in this Website should be construed by you as an offer to buy or sell, or soliciting any offer to buy or sell any tokens or any security. \nForward looking statements §\nThe Website may (or as made accessible through this Website) also contain forward-looking statements that are based on current expectations, estimates, forecasts, assumptions and projections about the technology, industry and markets in general.\nThe forward looking statements, which may include statements about the roadmap, project descriptions, technical details, functionalities, features, the development and use of tokens by projects, and any other statements related to such matters are subject to a high degree of risk and uncertainty. The forward looking statements are subject to change and are based on, among other things, market conditions, technical developments, and regulatory environment. The actual development and results, including the order and the timeline, might vary from what is presented. The information contained on this Website is a summary and does not purport to be accurate, reliable or complete and we bear no responsibility for the accuracy, reliability or completeness of information contained herein. Because of the high degree of risk and uncertainty described above, you should not place undue reliance on any matters described in this website or as accessible through this Website.\nWhile we aim to update our website regularly, all information, including the timeline and the specifics of each stage, is subject to change and may be amended or supplemented at any time, without notice and at our sole discretion.\nIntellectual property rights §\nThe Website and its contents are made available under free and open source licences. This means that anyone can use, share, and modify such content, as long as they follow the terms of the applicable licence. \nThird party website links §\nTo the extent the Website provides any links to a third party website, then their terms and conditions, including privacy policies, govern your use of those third party websites. We have no control over such third party websites and will not be liable for your use of or activities on any third party websites accessed through the Website. If you access such third party websites through the Website, it is at your own risk and you are solely responsible for your activities on such third party websites. \nThe Website may embed videos from Youtube, a service provided by Google LLC, using Youtube’s privacy-enhanced mode. When you interact with such videos, Youtube may place cookies on your personal device. The cookies do not directly identify individual users and YouTube will not store information to personalise your experience unless you are logged in to a Google account. We do not have any control over these cookies set by Youtube and it is recommended that you review YouTube’s embedding videos information page. \nLimitation of liability §\nWe will not be held liable to you under any contract, negligence, strict liability, or other legal or equitable theory for any lost profits, cost of procurement for substitute services, or any special, incidental, or consequential damages related to, arising from, or in any way connected with these Website Terms of Use, the Website, the content on the Website, or your use of the Website, even if we have been advised of the possibility of such damages. In any event, our aggregate liability for such claims is limited to EUR 100 (one hundred Euros). This limitation of liability will apply to the maximum extent permitted by applicable law.\nIndemnity  §\nYou shall indemnify us and hold us harmless from and against any and all claims, damages and expenses, including attorneys’ fees, arising from or related to your use of the Website, the content on the Website, including without limitation your violation of these Website Terms of Use. \nModifications §\nWe may modify or replace any part of this Website Terms of Use at any time and without notice. You are responsible for checking the Website periodically for any changes. The new Website Terms of Use will be effective immediately upon its posting on the Website.\nGoverning law §\nSwiss law governs these Website Terms of Use and any disputes between you and us, whether in court or arbitration, without regard to conflict of laws provisions.\nDisputes §\nIn these terms, “dispute” has the broadest meaning enforceable by law and includes any claim you make against or controversy you may have in relation to these Website Terms of Use, the Website, the content on the Website, or your use of the Website \nWe prefer arbitration over litigation as we believe it meets our principle of resolving disputes in the most effective and cost effective manner. You are bound by the following arbitration clause, which waives your right to litigation and to be heard by a judge. Please note that court review of an arbitration award is limited. You also waive all your rights to a jury trial (if any) in any and all jurisdictions. \nIf a (potential) dispute arises, you must first use your reasonable efforts to resolve it amicably with us. If these efforts do not result in a resolution of such dispute, you shall then send us a written notice of dispute setting out (i) the nature of the dispute, and the claim you are making; and (ii) the remedy you are seeking. \nIf we and you are unable to further resolve this dispute within sixty (60) calendar days of us receiving this notice of dispute, then any such dispute will be referred to and finally resolved by you and us through an arbitration administered by the Swiss Chambers’ Arbitration Institution in accordance with the Swiss Rules of International Arbitration for the time being in force, which rules are deemed to be incorporated herein by reference. The arbitral decision may be enforced in any court. The arbitration will be held in Zug, Switzerland, and may be conducted via video conference virtual/online methods if possible. The tribunal will consist of one arbitrator, and all proceedings as well as communications between the parties will be kept confidential. The language of the arbitration will be in English. Payment of all relevant fees in respect of the arbitration, including filing, administration and arbitrator fees will be in accordance with the Swiss Rules of International Arbitration. \nRegardless of any applicable statute of limitations, you must bring any claims within one year after the claim arose or the time when you should have reasonably known about the claim. You also waive the right to participate in a class action lawsuit or a classwide arbitration against us. \nAbout these Website Terms of Use §\nThese Website Terms of Use cover the entire agreement between you and us regarding the Website and supersede all prior and contemporaneous understandings, agreements, representations and warranties, both written and oral, with respect to the Website. \nThe captions and headings identifying sections and subsections of these Website Terms of Use are for reference only and do not define, modify, expand, limit, or affect the interpretation of any provisions of these Website Terms of Use. \nIf any part of these Website Terms of Use is held invalid or unenforceable, that part will be severable from these Website Terms of Use, and the remaining portions will remain in full force and effect. If we fail to enforce any of these Website Terms of Use, that does not mean that we have waived our right to enforce them."},"waku/2024-gantt":{"title":"2024-gantt","links":[],"tags":[],"content":"Waku Roadmap 2024 Gantt Chart §\nStatus short term work only:\n\nreliability for 1:1 chat and communities\nup to 100 communities\n\nColour legend:\n\nRed: engineering work to deliver the feature.\nOther: test and telemetry work to ensure quality\n\nPrefix legend:\n\nTBC: Yet to be scheduled or estimation needs to be locked in.\n\nCompletion dates are delivery of the code + dogfooding.\nIf too hard to read, try to see this file in GitHub.\ngantt\n    dateFormat YYYY-MM-DD\n    axisFormat %d-%b\n    weekday monday\n    \n%% Team legend:\n%% task name: team (accountable person)\n%% - r-*: research (jm-clius)\n%% - t-*: telemetry (fryorcraken)\n%% - n-*: nwaku (ivansete)\n%% - j-*: js-waku (weboko)\n%% - c-*: chat (plopezlpz)\n%% - g-*: go-waku (fryorcraken)\n%% - bd-*: BD (pedro)\n%% - se-*: Solution Engineer (vpavlin)\n    \n%% Milestones overview with deliverables\n    section Store Service Upgrade\n        Store v3 (sync): crit, milestone, after r-storev3sync n-storev3sync, 0\n        DoS protection for req-res protocols: crit, milestone, after n-dosreqres g-dosreqres, 0\n        PostgreSQL maintenance: crit, milestone, after n-pgsql-m, 0\n    section Direct Message Reliability\n        (telemetry) direct message reliability: milestone, after t-d-msg-rel-1 t-d-msg-rel-2, 0\n        Reliability Protocol for Resource-Restricted Clients: crit, milestone, after j-rel-reqres-1 j-rel-reqres-2, 0\n        Review MVDS usage and fail path: crit, milestone, after c-mvds, 0\n        PostgreSQL optimisation - phase 1: milestone, after n-pgsql-opt-1, 0\n    section E2e reliability protocol\n        E2e reliability protocol PoC: milestone, crit, after r-e2e-rel, 0\n        E2e reliability protocol Status integration: milestone, crit, after r-e2e-rel-status c-e2e-rel-status, 0\n    section Static Sharding - dedicated shards\n        (telemetry) Measure Bandwidth: milestone, after t-bandwidth, 0\n        (telemetry) Sharding: milestone, after t-sharding, 0\n        Sharding peer mgmt and discovery hardening: crit, milestone, after n-shard-peer-mgmt g-shard-peer-mgmt, 0\n        (testing) Custom shard impl of Communities: milestone, after c-test-custom-shard, 0\n        PostgreSQL optimisation - phase 2: milestone, after n-pgsql-opt-2, 0\n        Setup Waku Community on dedicated shard with pre-shared key dos protection: milestone, after waku-com, 0\n    section Bandwidth optimisation and Communities protocol review\n        %% For now same person scheduled to do both research and implementation\n        Minimal Community Specification and Implementation: milestone, after r-min-com-spec c-min-com-spec, 0\n        Review usage of content topics in Status Communities protocol: milestone, after r-cont-topic, 0\n        Specify de-MLS over Waku: milestone, after r-demls-spec, 0\n        %% TODO: schedule\n        TBC Telemetry review: milestone, after r-telem-review, 0\n        TBC Minimal solution for greedy messages: milestone, after r-min-sol-com, 0\n        TBC Define long-term solution: milestone, after r-define-com-sol, 0\n    section Nwaku in Status Desktop (Relay mode)\n        Nwaku on Windows: milestone, after n-nwaku-windows, 0\n        Nwaku in Status Desktop: milestone, after n-nwaku-status-desktop, 0\n    section RLN Mainnet\n        Implement RLN smart contract for paid, multilevel memberships: milestone, after r-rln-sc n-rln-sc j-rln-sc, 0\n        Public dogfooding RLNaaS web app: milestone, after j-pub-dogfood-web-app-1 j-pub-dogfood-web-app-2, 0\n    section Scale up number of Communities\n        Usage of rendezvous: milestone, after r-rendezvous, 0\n    section Incentivise running a Waku infrastructure node\n        RLN Relay Incentivisation: milestone, after r-rln-relay-incent, 0\n        Service Incentivisation: milestone, after r-svc-incent, 0\n    section Demonstrate product market-fit\n        Define cost (self-host): milestone, after bd-define-cost, 0\n        Define potential USPs: milestone, after bd-define-usps, 0\n        Define target customers: milestone, after bd-define-custs, 0\n        Customer interviews: milestone, after cust-int, 0\n        Co-design sessions: milestone, after bd-codesign se-codesign, 0\n        Review Waku MVP: milestone, 2025-01-15, 0\n\n%% Tasks\n    section Chat.plopezlpz\n        (testing) Custom shard impl of Communities: c-test-custom-shard, 2024-08-26, 2024-09-30\n        Setup Waku Community on dedicated shard with pre-shared key dos protection: waku-com, after c-test-custom-shard, 2w\n    section Chat.kaichaosun\n        Review MVDS usage and fail path: crit, c-mvds, 2024-08-01, 2024-09-30\n        Minimal Community Specification and Implementation: c-min-com-spec, after c-mvds, 12w\n    section Go.richard-ramos\n        Implement RLN smart contract for paid, multilevel memberships: r-rln-sc, 2024-09-01, 6w\n        Nwaku in Status Desktop: n-nwaku-status-desktop, after n-rln-sc, 2025-01-31\n        Status Support: status-support-rr, 2024-09-01, 2024-12-31\n    section Go.chaitanyaprem\n        DoS Protection for Req-Res Protocols: crit, g-dosreqres, 2024-08-01, 2024-09-15\n        Sharding peer mgmt and discovery hardening: crit, g-shard-peer-mgmt, 2024-08-26, 2024-09-12\n        Review usage of content topics in Status Communities protocol: r-cont-topic, after g-shard-peer-mgmt, 10w\n    section EcoDev.vpavlin\n        (telemetry) direct message reliability: t-d-msg-rel-1, 2024-08-26, 2024-09-25\n        (telemetry) Measure Bandwidth: t-bandwidth, after t-d-msg-rel-1, 8w\n        %% TODO: do bandwidth telemetry?\n        E2e reliability protocol Status integration: crit, c-e2e-rel-status, after r-e2e-rel, 6w\n        %% TODO: fit that properly\n        Specify de-MLS over Waku: r-demls-spec, 2024-10-01, 4w\n        Co-design sessions: bd-codesign, after cust-int, 2024-11-15\n    section Go.adklempner\n        (telemetry) direct message reliability: t-d-msg-rel-2, 2024-08-01, 2024-09-25\n        (telemetry) sharding: t-sharding, after t-d-msg-rel-2, 4w\n    section Test.stubbsta\n        (simulation) Functionality and stress test store v3: sim-storev3, 2024-07-08, 8w\n        (simulation) Functionality and stress test store v3 sync: sim-storesync, 2024-09-01, 10w\n        (simulation) Reliability performance impact: sim-rel, after sim-storesync, 10w\n    section Res.shash256\n        E2e reliability protocol - PoC: crit, r-e2e-rel, 2024-08-01, 2024-09-06\n        E2e reliability protocol Status integration: r-e2e-rel-status, after r-e2e-rel, 10w \n    section Res.sionois\n        %% Only dogfooding remaining\n        Store v3 (sync): crit, r-storev3sync, 2024-08-01, 2024-09-20\n        Store v3 - follow-up: after storev3-r, 8w\n        Peer mgmt - follow-up: after storev3-r, 8w\n        Usage of rendezvous: r-rendezvous, after r-storev3sync, 8w\n    section Res.alrevuelta\n        RLN Relay Incentivisation: r-rln-relay-incent, 2024-09-01, 2024-12-31\n    section Res.s-tikhomirov\n        Implement RLN smart contract for paid, multilevel memberships: rln-sc-d, 2024-09-01, 6w\n        Service Incentivisation: r-svc-incent, 2024-09-01, 2024-12-31\n    section Nim.Ivansete\n        Store v3 (sync): crit, n-storev3sync, 2024-08-15, 2024-09-20\n        PostgreSQL Maintenance: crit, n-pgsql-m, 2024-08-01, 2024-09-18\n        %% TODO review date/estimate\n        PostgreSQL Optimisation - phase 1: n-pgsql-opt-1, after n-pgsql-m, 6w\n        PostgreSQL Optimisation - phase 2: n-pgsql-opt-2, after n-pgsql-opt-1, 8w\n        Nwaku in Status Desktop: n-nwaku-status-desktop-2, after n-pgsql-opt-1, 6w\n    section Nim.NagyZoltanPeter\n        DoS Protection for Req-Res Protocols: crit, n-dosreqres, 2024-08-01, 2024-09-15\n        %% TODO review\n        TBC Store v3-beta + v3 (nwaku hardening): crit, storev3-n, after storev3-df dosreqresn, 3w\n        Nwaku in Status Desktop: n-nwaku-status-desktop-n, after storev3-n, 12w\n    section Nim.gabrielmer\n        Sharding peer mgmt and discovery hardening: crit, n-shard-peer-mgmt, 2024-08-01, 2024-09-12\n    section Nim.darshankabariya\n        %% TODO: review estimate\n        Nwaku on Windows: n-nwaku-windows, 2024-08-15, 6w\n    section Js.weboko\n        Reliability Protocol for Resource-Restricted Clients: crit, j-rel-reqres-1, 2024-08-01, 2024-09-13\n        Public dogfooding RLNaaS web app: j-pub-dogfood-web-app-1, after j-rel-reqres-1, 8w\n        Implement RLN smart contract (js-waku): j-rln-sc, after j-pub-dogfood-web-app-1, 10w\n    section Js.danisharora099\n        Reliability Protocol for Resource-Restricted Clients: crit, j-rel-reqres-2, 2024-08-01, 2024-09-13\n        Public dogfooding RLNaaS web app: j-pub-dogfood-web-app-2, after j-rel-reqres-2, 8w\n    section BD.pedro\n        Define cost (self-host): bd-define-cost, 2024-08-01, 2024-11-30\n        Define potential USPs: bd-define-usps, 2024-09-01, 2024-11-30\n        Define target customers: bd-define-custs, 2024-09-01, 2024-09-30\n        Customer interviews: cust-int, after bd-define-custs, 2024-10-31\n        Co-design sessions: bd-codesign, after cust-int, 2024-11-15\n"},"waku/collaboration/guidelines-for-collaboration":{"title":"Guidelines for Collaboration","links":[],"tags":["waku","collaboration"],"content":"Guidelines for Collaboration §\nVisibility Into Work and Productivity §\n\nDaily Standup The stand-up channel on the Waku Discord server is where core contributors share their daily stand up summarizing their daily planned tasks.\nWeekly Report: Every Friday, all team members must add a comment to the Epic GH issue they own and worked on the past week or planned to work on next week. See Waku project management for more.\nTrack your work with Github issues: Make sure to always have an open Github issue corresponding to your current task. Follow the following post for some insights on how to write good Github issues.\nQuality Github pull requests: Github issues are (typically) followed by one or multiple Github pull requests (PR) to address the task(s) set out in the issue. PRs should be of reasonable size and with proper documentation. All commits within the PR should be signed. Do not forget to request PR review from your peers when your PR is ready. Before merging an open PR, all commits should be rebased on master and squashed into a single commit with a semantic commit message. Use the following guides on how to make a good PR\n\nAnatomy of a perfect pull request\nHow to write a perfect pull request. This post expands on good PR documentation and communication.\n\n\nPR Reviews: Spend a portion (10-20%) of your daily work reviewing other team members’ Pull requests. This will allow a swift and smooth development process.\nSeek feedback Do not hesitate to seek feedback from the senior members of the team, especially those who work closely with you.\nCommunicate effectively: Know the team members that are relevant to your project and get their feedback and comments on your project when need be.\n\nCommunication media §\n\nBasic principle: Waku is an open-source protocols and software. We are part of a wider community. As such, your first instinct should be to communicate as openly as possible in the forum/channel most suited to your query. That said, we have channels for team-internal communications that relate to project management, team travel or other more personal conversations.\nDiscord server: it takes a while to get used to the bewildering number of channels on the Waku Discord server. Here are some guidelines to help you get started:\n\n#intros: a good place to introduce yourself to the community once you’ve joined\n#gm: a quick “good morning” when you start your day adds to a friendly environment and shows other community members that you’re online\n#stand-up: daily one-liners indicating what your focus will be for the day\n#support: general support questions related to Waku protocols or the organisation\n#nwaku-contribute, #go-waku-contribute, #js-waku-contribute: discussions related to the nim, go and JavaScript Waku v2 clients respectively\n#team-pm-private: team-internal discussions related to Waku Product project management.\nWe maintain various team-internal channels, including #afk, #watercooler, #events, and more, which facilitate sharing while we work\n\n\nExamples:\n\nYou’re getting started and have a question related to the nwaku codebase: ask away in the open #nwaku-contribute channel. Feel free to tag specific people that you think may help, but don’t be too surprised if other community members jump in with an answer.\nWhile reading a Waku RFC you have a suggestion on how to improve the protocol: ping the team on the open #support channel for general question about protocols, or #rfc if it is about phrasing or clarity in the RFC. You could also create a GH issue in the vacp2p/rfc repository.\nYou want to inform the team that you’re off sick: use the team-internal #afk channel.\n\n\n\nAutonomy and Motivation §\n\nAlignment with principles: Waku follows a set of principles as described in https://status.im/about/, a good understanding of those is vital to making a meaningful contribution to the team. Should you have any questions regarding the principles, do not hesitate to reach out to your team members for more insights and explanations.\nFamiliarize yourself with relevant tools and tech Your work involves knowledge of the basics of Git and Github e.g., creating issues, pull requests (PRs), branches, merging, rebasing, etc. Spend some time and familiarize yourself with these concepts.\n"},"waku/collaboration/nwaku-release-process":{"title":"nwaku Release Process","links":["waku/collaboration/test-nwaku-on-status"],"tags":["waku","collaboration","nwaku"],"content":"Testing week §\nOn each release, we establish a testing period of one week, when we lock the waku.test fleet so that it only runs the target version. During that period, we need to continuously stress that fleet from the sandbox machine, for example.\nIt is important to make sure the waku-simulator works as expected and the nodes can establish connections among themselves.\nDuring that week, the release owner needs to check the Kibana logs from the previous month (since the last release was deployed) looking for possible crashes or errors in waku.test &amp; waku.sandbox. These are the most relevant logs to check:\n\n(fleet: &quot;waku.test&quot; OR fleet: &quot;waku.sandbox&quot;) AND message: &quot;SIGSEGV&quot;\n\nMake sure that Status client works properly when connected to a fleet running on the release candidate version. For it, please follow its corresponding guide.\nRelease Calendar §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNameDateRelease Ownernwaku-versionwakuv2.test deployment2024-01-15SP0.24.0wakuv2.prod deployment2024-01-22SP0.24.xwakuv2.test deployment2024-02-12Zoltan0.25.0wakuv2.prod deployment2024-02-19Zoltan0.25.xwaku.test deployment2024-03-11Zoltan0.26.0waku.sandbox deployment2024-03-18Zoltan0.26.xwaku.test deployment2024-04-15Gabriel0.27.0waku.sandbox deployment2024-04-22Gabriel0.27.xwaku.test deployment2024-05-13Gabriel0.28.0waku.sandbox deployment2024-05-20Gabriel0.28.xwaku.test deployment2024-06-10Ivan0.29.0waku.sandbox deployment2024-06-17Ivan0.29.xwaku.test deployment2024-06-24Ivan0.30.0waku.sandbox deployment2024-06-26Ivan0.30.xwaku.test deployment2024-07-22Ivan0.31.0waku.sandbox deployment2024-07-24Ivan0.31.xwaku.test deployment2024-08-26Zoltan0.32.0waku.sandbox deployment2024-08-28Zoltan0.32.xwaku.test deployment2024-09-23Zoltan0.33.0waku.sandbox deployment2024-09-25Zoltan0.33.xwaku.test deployment2024-10-28Gabriel0.34.0waku.sandbox deployment2024-10-30Gabriel0.34.x"},"waku/collaboration/onboarding-guide":{"title":"Onboarding Guide","links":[],"tags":["waku","collaboration"],"content":"Onboarding guide §\nWelcome to Waku! There’s quite a lot to learn so take your time. Here are a few links and some things to start with.\nVac &amp; Waku §\nVac is a wide team that builds public good protocols for the decentralized web - vac.\nWaku originated as an incubation project within Vac with the goal of defining and implementing decentralized communication protocols. We have since evolved into a standalone team, while maintaining close collaboration with Vac, which continues to facilitate the RFC process - waku.\nAt Waku, each team member may split their working hours between research and sw development, depending on the team goals and personal interests.\n\nResearch: describe protocols in a formal/scientific way - https://github.com/waku-org/research.\nSW development: materialization of the protocols into software components - https://github.com/waku-org.\n\nCollaboration Guideline §\nHave a read at our Collaboration Guidelines to acquaint yourself with our collaboration best practices.\nStarter tasks §\n\n\nComplete the BambooHR tasks (can be followed in parallel with other tasks.).\n\n\nTry out the Status app\n\n\nGet familiar with Nim.\nRecommendations:\n\nStatus Nim Style Guide\nNim Language\n“Nim in Action” book (Dominik Picheta)\n“Mastering Nim” book (Andreas Rumpf)\nExercism course on Nim\n“Computer Programming with the Nim Programming Language” book (Stefan Salewski)\n\n\n\nMeet the Waku specification\nWaku is a communication layer for Web3.\nThere are three main Waku-client implementations:\n\nnwaku: Nim implementation aimed to be used by the infrastructure nodes.\ngo-waku: Golang implementation aimed to be used by the Desktop app.\njs-waku: JavaScript implementation designed to be run by web browsers.\n\nAside from the Waku project, Vac also gives a big contribution in the next ones:\n\nLogos, a Blockchain protocol whose clients would be built in Nim and Rust - Logos.\nCodex, a decentralized storage protocol (IPFS) - code-research, nim-codex.\n\n\n\nBuild nwaku. We encourage all core contributors to run a long-lived nwaku node as an operator. More details here.\nUseful resources:\n\nExamples\nDocs\n\n\n\nSkim specs (primarily Vac, but also Status) and try to get a picture of how things fit together. You do not have to read all the specifications all at once (it may get a bit confusing). We suggest start reading them in the following order, it is just a suggestion, feel free to do it the way you want!:).\n\n\nWhile reading RFCs note that there are two versions of WAKU namely WAKU1 and WAKU2. Vac RFCs related to WAKU2 are WAKU2 prefixed whereas other ones are prefixed by WAKU or WAKU1. For example, 8/WAKU-MAIL and 13/WAKU2-STORE are RFCs for WAKU1 and WAKU2, respectively.\n- 1/COSS\n- 10/WAKU2\n- 16/WAKU2-RPC\n- 11/WAKU2-RELAY | 14/WAKU2-MESSAGE | 23/WAKU2-TOPICS | 26/WAKU2-PAYLOAD\n- 12/WAKU2-FILTER\n- 19/WAKU2-LIGHTPUSH\n- 13/WAKU2-STORE\n- 18/WAKU2-SWAP\n- 27/WAKU2-PEERS\n- 15/WAKU2-BRIDGE\n\nJoin the Vac, Waku, and Nimbus Discord servers and say hi!\nRecommended: go through the list of existing open issues in the project repo (nwaku, go-waku or js-waku) you’ll mostly be working on and familiarise yourself with the current state of the project. This may take a while, but is an excellent exercise to get acquainted with some important conversations and project history. We encourage new contributors to ask questions in the comment sections of any past issues. You could even self-assign some issues that’s currently unassigned which you’d like to tackle! For this, the good-first-issue tag on Github may come in as a handy filter.\n\nResources §\nVac §\n\nVac overview\nVac.dev writeups\nVac RFCs/Specs\nCOSS process\n10/WAKU2 main spec\nVac forum\nVac 2021 Q3 priorities\nWaku v2 training session\nVac Sustainability and business workshop\n\nStatus §\n\nStatus whitepaper\nStatus principles\nStatus main client spec\nStatus specs\nStatus Discuss\nNimbus team\nnim-libp2p\n\nEcosystem §\n\nEthereum\nlibp2p\nlibp2p specs\n"},"waku/collaboration/test-nwaku-on-status":{"title":"Test nwaku on Status","links":[],"tags":["waku","status","collaboration","nwaku"],"content":"This document is based on the following recorded session\nIn order to test Nwaku on Status, you need to first deploy your release candidate to the shards.staging fleet. You will also need to build status-desktop by following the instructions here.\nOnce we are able to run status-desktop locally, run\nmake run ARGS=&quot;--enable-fleet-selection --datadir=./datadir1&quot;\nThis will open Status Desktop. Create a new account, and once logged in go to Settings-&gt;Advanced-&gt;Fleet and select shards.staging\n\nAfter selecting the fleet, Status Desktop will close and you will need to run again\nmake run ARGS=&quot;--enable-fleet-selection --datadir=./datadir1&quot;\nLog in with the password you set previously, and check thatshards.staging is configured\n\nIn the Advanced section again, please enable the following options:\n\nFull developer mode\nDebug\nNode Management\nEnable creation of sharded communities\nEnable Community Creation\n\nSome of these options might also close your Status Desktop window. If so, run again Status Desktop with the same command as before and check that all the above configurations are enabled.\nNow, open a new terminal and run a new instance of Status Desktop using a different directory for its database. For example\nmake run ARGS=&quot;--enable-fleet-selection --datadir=./datadir2&quot;\nFollow the same steps as with the other Status Desktop instance, only changing the datadir flag\nWith the previous step completed, enter the Node Management section and check that both instances are connected to peers\n\nIn one of the accounts, copy the link to its profile\n\nAnd then, in the other account, send it a contact request\n\nMake sure you get a notification for it in your other window and accept the contact request\n\nChat between both accounts and check that messages get delivered properly\n\nFinally, test that the Store nodes work properly.\nFor it, close one of the windows and from the open window send messages to it.\nRe-run the Status Desktop instance you just closed and check that you receive the messages sent to you when you were offline.\nSome extra operations that we can run to double check everything is ok are:\n\nIn Node Management run the RPC method {&quot;method&quot;:&quot;settings_nodeConfig&quot;} and check in the output that you are connected to the right fleet\nSimilarly, you can run the RPC method {&quot;method&quot;:&quot;wakuext_peers&quot;} to get the list of peers\nCheck in Settings→Advanced→History nodes the history nodes we are connected to\n\nTo do: define how to test Status Communities"},"waku/index":{"title":"Waku Roadmap","links":["waku/waku-milestones","tags/waku-updates","waku/process","waku/reports","waku/collaboration"],"tags":["waku","roadmap","overview"],"content":"Roadmap Overview §\nTo learn more about Waku please visit the website, github, and docs.\n\nMilestones\nWeekly updates\nProcess\nReports\nCollaboration\n"},"waku/milestones/closed/2023-milestones":{"title":"2023 Milestones","links":[],"tags":[],"content":"Milestone: Waku Network can Support 1 Million Users §\nLink: https://github.com/waku-org/pm/milestone/4\nDue by: 2023-11-30\nEpic: Cater for professional operators (Status Communities)\n\nLink: https://github.com/waku-org/pm/issues/92\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1929\nhttps://github.com/fryorcraken/milestone-update/\n\n\n\nEpic: Simulation with 10k nodes\n\nLink: https://github.com/waku-org/pm/issues/85\nIssues in Epic:\nhttps://github.com/vacp2p/research/issues/191\n\nEpic: PostgreSQL in service node: Further optimisations\n\nLink: https://github.com/waku-org/pm/issues/84\nIssues in Epic:\nhttps://github.com/waku-org/nwaku/issues/1894\nhttps://github.com/waku-org/nwaku/issues/1893\nhttps://github.com/waku-org/nwaku/issues/1888\nhttps://github.com/waku-org/nwaku/issues/1885\nhttps://github.com/waku-org/nwaku/issues/1842\nhttps://github.com/waku-org/nwaku/issues/1841\nhttps://github.com/waku-org/nwaku/issues/1840\nhttps://github.com/waku-org/nwaku/issues/1604\n\nMilestone: Waku Network Gen 0 §\nLink: https://github.com/waku-org/pm/milestone/1\nDue by: 2023-12-01\nEpic: 3.4: Production and memberships on mainnet\n\nLink: https://github.com/waku-org/pm/issues/87\n\nEpic: 3.4: Further memberships\n\nLink: https://github.com/waku-org/pm/issues/72\n\nEpic: 3.3: Membership for Status Communities\n\nLink: https://github.com/waku-org/pm/issues/71\n\nEpic: 3.2: Basic DoS protection in production\n\nLink: https://github.com/waku-org/pm/issues/70\nIssues in Epic:\n\nhttps://github.com/waku-org/go-waku/issues/732\nhttps://github.com/waku-org/go-waku/issues/731\nhttps://github.com/waku-org/go-waku/issues/655\n\n\n\nEpic: 1.5: Launch and dogfood integrated public Waku Network MVP\n\nLink: https://github.com/waku-org/pm/issues/68\nIssues in Epic:\n\nhttps://github.com/waku-org/research/issues/1\n\n\n\nEpic: 1.4: Sharded peer management and discovery\n\nLink: https://github.com/waku-org/pm/issues/67\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1941\nhttps://github.com/waku-org/nwaku/issues/1940\nhttps://github.com/waku-org/js-waku/issues/1505\nhttps://github.com/waku-org/js-waku/issues/1504\nhttps://github.com/waku-org/go-waku/issues/727\nhttps://github.com/waku-org/go-waku/issues/680\nhttps://github.com/waku-org/go-waku/issues/679\nhttps://github.com/waku-org/go-waku/issues/678\n\n\n\nEpic: 1.3: Node bandwidth management mechanism\n\nLink: https://github.com/waku-org/pm/issues/66\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1947\nhttps://github.com/waku-org/nwaku/issues/1946\nhttps://github.com/waku-org/nwaku/issues/1945\nhttps://github.com/waku-org/nwaku/issues/1938\nhttps://github.com/waku-org/js-waku/issues/1503\nhttps://github.com/waku-org/go-waku/issues/677\n\n\n\nEpic: 1.2: Autosharding for autoscaling\n\nLink: https://github.com/waku-org/pm/issues/65\nNo issues in Epic description.\n\nEpic: 2.3: Basic distributed Store services\n\nLink: https://github.com/waku-org/pm/issues/64\n\nEpic: 2.2: Sharded capability discovery for light protocols\n\nLink: https://github.com/waku-org/pm/issues/63\nIssues in Epic:\n\nhttps://github.com/waku-org/js-waku/issues/1506\n\n\n\nEpic: 2.1: Production testing of existing protocols\n\nLink: https://github.com/waku-org/pm/issues/49\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1950\nhttps://github.com/waku-org/nwaku/issues/1948\nhttps://github.com/waku-org/nwaku/issues/1888\nhttps://github.com/waku-org/js-waku/issues/1463\nhttps://github.com/waku-org/js-waku/issues/914\n\n\n\nEpic: Dogfood RLN in production\n\nLink: https://github.com/waku-org/pm/issues/51\nNo issues in Epic description.\n\nEpic: Open membership mechanism\n\nLink: https://github.com/waku-org/pm/issues/52\n\nEpic: RLN validation in production\n\nLink: https://github.com/waku-org/pm/issues/55\n\nEpic: Autosharding - dogfooding\n\nLink: https://github.com/waku-org/pm/issues/58\n\nMilestone: Quality Assurance processes are in place §\n-Link: https://github.com/waku-org/pm/milestone/3\nDue by: 2024-03-31\nEpic: Comprehensive Dev Testing\n\nLink: https://github.com/waku-org/pm/issues/90\nIssues in Epic:\n\nhttps://github.com/fryorcraken/milestone-update/\nhttps://github.com/waku-org/js-waku/issues/1589\nhttps://github.com/waku-org/js-waku/issues/1435\nhttps://github.com/waku-org/js-waku/issues/337\nhttps://github.com/waku-org/js-waku/issues/1595\nhttps://github.com/waku-org/js-waku/issues/1597\n\n\n\nEpic: Automated Release processes\n\nLink: https://github.com/waku-org/pm/issues/86\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1889\nhttps://github.com/waku-org/js-waku/issues/1543\nhttps://github.com/waku-org/waku-rust-bindings/issues/67\n\n\n\nEpic: End-to-end testing\n\nLink: https://github.com/waku-org/pm/issues/34\nIssues in Epic:\n\nhttps://notes.status.im/s/iylE6wdli#\nhttps://github.com/waku-org/go-waku/issues/608\n\n\n\nMilestone: Support Many Platforms §\nLink: https://github.com/waku-org/pm/milestone/2\nDue by: 2024-04-30\nEpic: Ship RLN as part of non-native SDKs\n\nLink: https://github.com/waku-org/pm/issues/88\nIssues in Epic:\n\nhttps://github.com/waku-org/go-zerokit-rln/issues/5\nhttps://github.com/waku-org/go-waku/issues/732\nhttps://github.com/waku-org/nwaku/issues/2033\nhttps://github.com/fryorcraken/milestone-update/\n\n\n\nEpic: REST API service node\n\nLink: https://github.com/waku-org/pm/issues/82\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1988\nhttps://github.com/waku-org/nwaku/issues/1985\nhttps://github.com/waku-org/nwaku/issues/1910\nhttps://github.com/waku-org/nwaku/issues/1909\nhttps://github.com/waku-org/nwaku/issues/1872\nhttps://github.com/waku-org/nwaku/issues/1652\nhttps://github.com/waku-org/nwaku/issues/1214\nhttps://github.com/waku-org/nwaku/issues/1076\nhttps://github.com/waku-org/nwaku/issues/938\nhttps://github.com/waku-org/go-waku/issues/264\n\n\n\nEpic: NodeJS Library\n\nLink: https://github.com/waku-org/pm/issues/81\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1332\n\n\n"},"waku/milestones/closed/2023-quality-assurance-processes":{"title":"Quality Assurance processes are in place","links":[],"tags":["waku-milestone"],"content":"Link: https://github.com/waku-org/pm/milestone/3\nDue by: 2024-03-31\nEpic: Comprehensive Dev Testing §\n\nLink: https://github.com/waku-org/pm/issues/90\nIssues in Epic:\n\nhttps://github.com/fryorcraken/milestone-update/\nhttps://github.com/waku-org/js-waku/issues/1589\nhttps://github.com/waku-org/js-waku/issues/1435\nhttps://github.com/waku-org/js-waku/issues/337\nhttps://github.com/waku-org/js-waku/issues/1595\nhttps://github.com/waku-org/js-waku/issues/1597\n\n\n\nEpic: Automated Release processes §\n\nLink: https://github.com/waku-org/pm/issues/86\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1889\nhttps://github.com/waku-org/js-waku/issues/1543\nhttps://github.com/waku-org/waku-rust-bindings/issues/67\n\n\n\nEpic: End-to-end testing §\n\nLink: https://github.com/waku-org/pm/issues/34\nIssues in Epic:\n\nhttps://notes.status.im/s/iylE6wdli#\nhttps://github.com/waku-org/go-waku/issues/608\n\n\n"},"waku/milestones/closed/2023-support-1-million-users":{"title":"Support 1 Million Users","links":[],"tags":["waku-milestone"],"content":"Link: https://github.com/waku-org/pm/milestone/4\nDue by: 2023-11-30\nEpic: Cater for professional operators (Status Communities) §\n\nLink: https://github.com/waku-org/pm/issues/92\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1929\nhttps://github.com/fryorcraken/milestone-update/\n\n\n\nEpic: Simulation with 10k nodes §\n\nLink: https://github.com/waku-org/pm/issues/85\nIssues in Epic:\n\nhttps://github.com/vacp2p/research/issues/191\n\n\n\nEpic: PostgreSQL in service node: Further optimisations §\n\nLink: https://github.com/waku-org/pm/issues/84\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1894\nhttps://github.com/waku-org/nwaku/issues/1893\nhttps://github.com/waku-org/nwaku/issues/1888\nhttps://github.com/waku-org/nwaku/issues/1885\nhttps://github.com/waku-org/nwaku/issues/1842\nhttps://github.com/waku-org/nwaku/issues/1841\nhttps://github.com/waku-org/nwaku/issues/1840\nhttps://github.com/waku-org/nwaku/issues/1604\n\n\n"},"waku/milestones/closed/2023-support-many-platforms":{"title":"Support Many Platforms","links":[],"tags":["waku-milestone"],"content":"Link: https://github.com/waku-org/pm/milestone/2\nDue by: 2024-04-30\nEpic: Ship RLN as part of non-native SDKs §\n\nLink: https://github.com/waku-org/pm/issues/88\nIssues in Epic:\n\nhttps://github.com/waku-org/go-zerokit-rln/issues/5\nhttps://github.com/waku-org/go-waku/issues/732\nhttps://github.com/waku-org/nwaku/issues/2033\nhttps://github.com/fryorcraken/milestone-update/\n\n\n\nEpic: REST API service node §\n\nLink: https://github.com/waku-org/pm/issues/82\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1988\nhttps://github.com/waku-org/nwaku/issues/1985\nhttps://github.com/waku-org/nwaku/issues/1910\nhttps://github.com/waku-org/nwaku/issues/1909\nhttps://github.com/waku-org/nwaku/issues/1872\nhttps://github.com/waku-org/nwaku/issues/1652\nhttps://github.com/waku-org/nwaku/issues/1214\nhttps://github.com/waku-org/nwaku/issues/1076\nhttps://github.com/waku-org/nwaku/issues/938\nhttps://github.com/waku-org/go-waku/issues/264\n\n\n\nEpic: NodeJS Library §\n\nLink: https://github.com/waku-org/pm/issues/81\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1332\n\n\n"},"waku/milestones/closed/2023-waku-network-gen-0":{"title":"Waku Network Gen 0","links":[],"tags":["waku-milestone"],"content":"Link: https://github.com/waku-org/pm/milestone/1\nDue by: 2023-12-01\nEpic: 3.4: Production and memberships on mainnet §\n\nLink: https://github.com/waku-org/pm/issues/87\n\nEpic: 3.4: Further memberships §\n\nLink: https://github.com/waku-org/pm/issues/72\n\nEpic: 3.3: Membership for Status Communities §\n\nLink: https://github.com/waku-org/pm/issues/71\n\nEpic: 3.2: Basic DoS protection in production §\n\nLink: https://github.com/waku-org/pm/issues/70\nIssues in Epic:\n\nhttps://github.com/waku-org/go-waku/issues/732\nhttps://github.com/waku-org/go-waku/issues/731\nhttps://github.com/waku-org/go-waku/issues/655\n\n\n\nEpic: 1.5: Launch and dogfood integrated public Waku Network MVP §\n\nLink: https://github.com/waku-org/pm/issues/68\nIssues in Epic:\n\nhttps://github.com/waku-org/research/issues/1\n\n\n\nEpic: 1.4: Sharded peer management and discovery §\n\nLink: https://github.com/waku-org/pm/issues/67\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1941\nhttps://github.com/waku-org/nwaku/issues/1940\nhttps://github.com/waku-org/js-waku/issues/1505\nhttps://github.com/waku-org/js-waku/issues/1504\nhttps://github.com/waku-org/go-waku/issues/727\nhttps://github.com/waku-org/go-waku/issues/680\nhttps://github.com/waku-org/go-waku/issues/679\nhttps://github.com/waku-org/go-waku/issues/678\n\n\n\nEpic: 1.3: Node bandwidth management mechanism §\n\nLink: https://github.com/waku-org/pm/issues/66\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1947\nhttps://github.com/waku-org/nwaku/issues/1946\nhttps://github.com/waku-org/nwaku/issues/1945\nhttps://github.com/waku-org/nwaku/issues/1938\nhttps://github.com/waku-org/js-waku/issues/1503\nhttps://github.com/waku-org/go-waku/issues/677\n\n\n\nEpic: 1.2: Autosharding for autoscaling §\n\nLink: https://github.com/waku-org/pm/issues/65\nNo issues in Epic description.\n\nEpic: 2.3: Basic distributed Store services §\n\nLink: https://github.com/waku-org/pm/issues/64\n\nEpic: 2.2: Sharded capability discovery for light protocols §\n\nLink: https://github.com/waku-org/pm/issues/63\nIssues in Epic:\n\nhttps://github.com/waku-org/js-waku/issues/1506\n\n\n\nEpic: 2.1: Production testing of existing protocols §\n\nLink: https://github.com/waku-org/pm/issues/49\nIssues in Epic:\n\nhttps://github.com/waku-org/nwaku/issues/1950\nhttps://github.com/waku-org/nwaku/issues/1948\nhttps://github.com/waku-org/nwaku/issues/1888\nhttps://github.com/waku-org/js-waku/issues/1463\nhttps://github.com/waku-org/js-waku/issues/914\n\n\n\nEpic: Dogfood RLN in production §\n\nLink: https://github.com/waku-org/pm/issues/51\n\nEpic: Open membership mechanism §\n\nLink: https://github.com/waku-org/pm/issues/52\n\nEpic: RLN validation in production §\n\nLink: https://github.com/waku-org/pm/issues/55\n\nEpic: Autosharding - dogfooding §\n\nLink: https://github.com/waku-org/pm/issues/58\n"},"waku/milestones/open/2024-acquire-first-10-customers":{"title":"Acquire first 10 customers","links":[],"tags":["waku-milestone"],"content":"Milestone: Acquire first 10 Customers §\nOnboard Waku first 10 customers. Customers are projects using Waku for their peer-to-peer communication stack.\nFirst 10 customers assume involvement from the engineering team to get things right and help co-design.\nStatus, Railgun, TheGraph and Portrait should count as the first four.\nDeliverable: 5-10 Highly qualified leads §\nIdentify 5-10 leads that have strong chances to go with Waku:\n\nHow many recurring co-design meetings have been scheduled.\nHow many collaboration Discord bridges have been setup\nMoved to the Solutioning column in IFT BD CRM.\n\nDeliverable: Review current integrations §\nOrganise monthly catch-up calls with Railgun, TheGraph, Portrait and any other integrated customers to review their usage of Waku. Discuss their current problems and future goals.\nCover latest Waku development, including RLN mainnet contract parameters."},"waku/milestones/open/2024-bandwidth-optimization-and-protocol-review":{"title":"Bandwidth optimization and protocol review","links":[""],"tags":["waku-milestone"],"content":"Milestone Bandwidth optimization and Communities protocol review\nEstimated Date of Completion: Q2 2025, Precise date to be provided as part of 2024 H1 planning.\nOnce completed, further specification and analysis of Status Communities and some chat protocols will be available; as well as a recommendation on how Status Communities protocol should use Waku in a scalable and bandwidth efficient manner.\nMoreover, low hanging-fruits and temporary solutions to improve bandwidth consumption would have been implemented.\nDeliverable: Minimal Community Specification and Implementation §\n\nSpecify community procedures, including the encryption, reliability and functional scope of each. This forum post serves as a starting point.\nUsing spec from (1) as a basis, define message flows to be moved to separate shards (e.g. community control + content messages). Extracting community messages off the common open shard (also used by 1:1 chats) should be considered.\n\nAs well as other low-hanging fruit improvements previously identified.\nBreaking changes and migration plans, if necessary, should be specified as part of this output.\nFinally, proceed with the implementation of (2).\nDeliverable: Telemetry review §\nUsing the output of Telemetry: Measure Bandwidth and Minimal Community Specification and Implementation (traffic separated by shards), analyse the distribution of traffic on relay, and data in store. Providing a report in terms of Status Chat functionality.\nDeliverable: Minimal solution for greedy messages §\nBased on telemetry review, specify and implement a workaround solution (light push + store) that removes most data greedy functionality from the relay network.\nAt the time of writing, we assume that self-addressed messages (backup/sync) and community description messages would be affected by this change.\nDeliverable: Define long-term solution §\nThe output of this deliverable is to compile a list of recommendations, for Waku, Status Communities and chat protocols. This should include potential benefits of changes and enable scheduling the work between Status and Waku teams.\nDecision on the work to be done and planning it should be part of the output of this deliverable.\nThe recommendation should be grounded in the output of the previous deliverables of this milestone.\nThe recommendation is unlikely to encompass the entire chat protocol, and all status message types due to the amount of work it would entailed. Instead, an empirical approach should be taken where changes are prioritised based on the user impact, known limitations and functionalities (e.g. profile backup and device pairing usage of Waku), and telemetry metrics.\nThis would impact any current usage of Waku by the Status app. Which does include communities, 1:1 chat but profile back and device pairing.\nThis could include review of discv5 implementation in go-waku and nwaku if bandwidth usage is excessive.\nDeliverable: Review usage of content topics in Status Communities protocol §\nThe usage of content topics in Status is aligned with Wakuv1. Waku v2 comes with a new recommended format that enables auto-sharding.\nMoreover, single Status users currently use a high number of content topics, which may have an impact on performance of req-res protocols such as store and filter.\nSuch impact is to be measured in a previous milestone by Vac DST.\nThe output of this deliverable should be an RFC update on how content topics should be used, backed with simulations when performance improvement is expected.\nIt should include migration strategy and potential impact on the product."},"waku/milestones/open/2024-demonstrate-product-market-fit":{"title":"Demonstrate product market-fit","links":[],"tags":["waku-milestone"],"content":"Milestone: Demonstrate product market-fit §\nTo demonstrate the viability of Waku as a self-sustainable independent project, user traction and market fitness must be proven. Validation against the market of Waku’s technology and potential USP is needed.\nSuch validation can enable prioritisation of work and potentially dropping undesired features.\nDeliverable: Define cost (self-host) §\nCost of using Waku needs to be assessed to enable projects, including Status, to understand the potential ROI in using Waku.\nThe output of this deliverable should provide an estimate, in terms of infrastructure costs of using Waku for running:\n\nStatus 1:1 chats\n\nAlso cover RPC API prices\n\n\na community (whether done by Status or an external community owner)\n\nAlso cover RPC API prices\n\n\nvanilla Waku, by using existing integration (e.g. railgun or the graph) as a reference.\nall the above, adding RLN cost\n\nNote: depends on PostgreSQL Optimisation - phase 2 deliverable for infrastructure costs.\nDeliverable: The Waku Whitepaper §\nWrite an academically rigorous whitepaper explaining the what, why and how of Waku protocols and ensure the coherence of the Waku technology.\nAs set out in research#7. The document itself may source from one or more academic papers published and presented throughout the year. Total length should be around 15 pages.\nDeliverable: Define potential USPs §\nDefine Waku products and features, and potential problems they may solve. Some of it is already captured in the validation matrix.\nThis can be used as a basis when proceeding with market and product research.\nItems can be validated, invalidated or new items can be recorded as part of research.\nThis deliverable includes an update of the waku.org website to ensure that the USPs are clear to potential customers.\nDeliverable: Define target customers §\nTarget customers and segments have been identified and presented in Athens all-hands.\nA more formal capture should be done, with tracking in IFT CRM (using Segment attribute for example). IFT’s recommendation suggested a focus on the DeFi segment; experience has shown that intent and AI inference networks are promising.\nA document should capture:\n\nCustomer segments\nMarket size of each segment\nPotential problems and Waku USPs potentially relevant to segment\nCompetitors to Waku, other solutions in use\nLearning so far, including interviews (next deliverable)\nRational in favour/against pursuing segment\n\nThis document + IFT CRM + Validation matrix are the core material for Waku GTM.\n~5 segments must be identified to proceed with customer interviews.\nDeliverable: Customer Interviews §\nProceed with ~10 interviews of current and interested customers, spread across the ~5 identified segments.\nUnderstand their problems around peer-to-peer networking and capture in the validation matrix which of Waku’s offering may be of interest, or new problems related to peer-to-peer networking to be covered by Waku.\nInterviews should have a dedicated ~5 questions to get answers:\n\nRole of p2p network protocol\nCurrent problems\netc.\n\nTo help establish the product-fit and identify potential blockers. This is should be detached from Waku, more about discussing p2p network and messaging role in the project’s protocol and their challenges.\nWhen synthesising the interviews, a review of segments should be done to select and focus on segments with most potential.\nDeliverable: Co-design sessions §\nAt Devcon 2024, organise 3-4 co-design sessions to sit down to discuss potential Waku  integration in more detail. Targeting customers in most promising segments deduced from customer interviews. This acts as a follow-up to the customer interviews deliverable and will require Waku engineers to attend.\nDeliverable: Review Waku MVP §\nBased on customer interviews and co-design sessions, identify the Waku USPs with most potential and outline an MVP.\nBased on Waku’s current state and roadmap, review if additional deliverables to fill technical gaps (if any) are needed, or what currently planned deliverables must be completed.\nCommunicate with targeted customers on MVP."},"waku/milestones/open/2024-direct-msg-reliability":{"title":"Direct Message Reliability","links":[],"tags":["waku-milestone"],"content":"Milestone Direct Message Reliability\nEstimated Date of Completion: 2024-10-30\nWith this milestone, connectivity issues in Status Mobile and Desktop are solved and tested.\nUsage of store v3-beta casts a wide net on potential message loss, at the cost of bandwidth overhead (but still lower than current usage of storev2).\nReview of MVDS usage for all direct messages is done to ensure that critical messages (request to join, contact request, 1:1 messages, private group) are delivered.\nDeliverable: Enable testing of direct messages §\nProduce a CLI that enables black-box testing of the Waku integration in status-go. Focus should be on direct messages, including peer management and strategies when network connectivity is lost. This is to enable (1) of the Vac/QA dependencies. Note the CLI should sit under the Status Communities logic layer and focus on message delivery.\nDirect messages are used for critical chat features: contact request, community join request and response, 1:1 chat and private group.\nCurrently, if the connection is dropped, the recovery strategies implemented in status-go often fail.\nThe Waku team would provide a set of binaries to enable Vac/QA team to setup non-regression functional test (black box/e2e) as well as Vac/DST to run simulations in unreliable environments (latency, connection drop) to ascertain the reliability of the software, before it is touched by Status QA team.\nThe API of such binaries would be defined based on the needs from the Vac/QA-DST team.\nVac QA team is not expected to proceed with an extensive testing of the Communities functionality, but instead proceed with testing of direct message sending/reception considering various potential network faults.\nDeliverable: Review connection management strategy and back-off and fix long disconnection issues §\nReview disconnection and peer management in status-go and go-waku for both relay and light client protocols.\nEnsure that broken scenarios from dogfooding and Vac/QA testing are covered. Including but not limited to desktop sleep/hibernate and failure to send messages after current backoff strategy.\nThis includes moving peer management logic from status-go to go-waku for better separation of concerns.\nDeliverable: Tooling: filter and light push protocols §\nImplement a testing telemetry tool, a.k.a. lite-protocol-tester, that can measure the reliability of light push and filter from nwaku PoV. That tool should enable injecting messages, and produce the right logging. DST’s log tracing tool can then be used to create reports. This will help us to measure the current estate and evolution of the upcoming enhancements.\nDeliverable: Telemetry: fleet logging §\nEnsure that nwaku nodes in the status fleet log messages to enable traceability on both relay and filter/light push. Also ensure that sync (store v3) does highlight missed messages and related time to enable investigation on why 2 nodes were not synced.\nDeliverable: Telemetry: direct message reliability §\nReview and ensure the telemetry service can provide accurate statistics on message reliability with a mix of online presence report, message sending and receiving.\nThe measurement should be specific to direct messages to ensure that deliverables above do improve reliability in real usage.\nThis should include content topic data, to be used for later optimization.\nFor both Desktop and Mobile. Telemetry service should also be updated to ensure it covers the disconnection scenario for itself.\nNote that from Status’ team experience, the telemetry statistics have usually been more optimistic than reality, especially when there is a full network drop (ie, no messages going out).\nDeliverable: Reliability Protocol for Relay §\nDefine a protocol that leverages store v3-beta, to improve reliability when using Waku Relay, for both delivery and reception of messages.\nThis enables a local node to ensure it has the same view of the network as its peers.\nDeciding on how store v3-beta queries should be triggered and how often should be part of the protocol specifications.\nNote this does not provide end-to-end delivery as it only permits a local node to verify that its view of the network is similar to connected peers (and not peers further away in the network).\nThe reference implementation will be done in nwaku: The API should be simple and remove the need for protocol knowledge by the developer (e.g. send/receive verbs).\nThis should also be used by the light push and filter service (as service nodes).\nA similar logic should be implemented in Golang and used in status-go. RFC and collaboration with the nwaku team is expected to ensure similar implementation in both languages.\nDeliverable: Reliability Protocol for Resource-Restricted Clients §\nDefine and implement a protocol that improves reliability in web and mobile environments.\nIn this particular instance, js-waku will be the reference implementation of the designed protocol to enable focus of the js-waku team on resource-restricted environment and of the nwaku team on relay and service node matters/usage.\nThis deliverable includes the implementation of this protocol in go-waku (nwaku excluded). Work should be done in parallel and feed from each other.\nThe intent is to compose light push, filter and store v3-beta in combination.\nDeliverable: PostgreSQL Optimisation phase 1 §\nContinue work to improve PostgreSQL query performance. Focus on queries with direct impact on UX. E.g. hash query to get store message confirmation.\nStress-testing of store queries by the Waku testing engineer has started and can be used as a baseline. Also, a dashboard will be built to better track store performance over time.\nFollowing activities will be performed:\n\nReview of store stressing test results and tackle inconsistency and poor performance\nReview with PostgreSQL expert (IFT CC) potential improvements and implement them\n\nStress testing of Waku Store can be used as a base to measure the gains from the optimization. Two phases are expected:\n\nPreliminary work with IFT CC to cover basis and prepare for consultation (phase 1)\nConsultation with an external agency for fine tuning. (phase 2, separate deliverable and milestone)\n\nDeliverable: Dogfooding app PoC §\nNote: new deliverable, stemmed from discussion with js-waku team who have been working on resource-restricted reliability since earlier this year. Yet to be estimated and planned.\nJustification: testing and simulations have limitations in the context of heterogeneous network behaviour. The best testing comes from the real world/network environment, with real users.\nIt is expected that not all users will enable opt-in telemetry and that there will be a delay between library improvements and roll out.\nDeliverable: Review MVDS usage and fail path §\nReview MVDS usage for direct messages and ensure that the fail path is handled correctly with either feedback on the UI or automated retries.\nMVDS protocol is already in use for some direct messages. Ensure it is the case for contact requests, join requests, 1:1 chat and private groups.\nAlso review the fail path for MVDS (are messages retried later or is there feedback/retry on the UI)?\nThe output of this is likely to include GUI change recommendations to add retry buttons or just simply retry indefinitely (for contact requests etc) in addition to some logic change (e.g. ensure the retry happens after reconnection)."},"waku/milestones/open/2024-e2e-reliability-protocol":{"title":"End-to-end reliability protocol","links":[],"tags":["waku-milestone"],"content":"Milestone End-to-end reliability protocol §\nEstimated Date of Completion: 2024-11-25\nTo solve reliability is to solve two problems:\n\nHigh heuristic that messages are received and sent\nAbility to know whether messages are received or sent\n\nProblem (1) can never be 100% reliable in a network environment. The previous milestones focused on it.\nTo solve (2), is to create an end-to-end protocol, sender to recipient, that enables the ability to know whether recipient(s) have received messages.\nWith this milestone, we design and deliver a first PoC for an end-to-end reliability protocol.\nThis protocol will be specified and implemented in the Status app for Status Communities chat rooms.\nDeliverable: End-to-end reliability protocol - PoC §\nDesign a protocol that enables end-to-end reliability for Status Communities channels.\nThe output is an agnostic RFC and a reference implementation in Golang (similar to MVDS library). However, it should take in account the context of Status Communities and leverage related properties (e.g. mostly online community owner nodes).\nThis deliverable does not include the integration in status-go, but it should provide enough information to then review with the Status app team how this protocol should be used in Status Communities. Parameters such as bandwidth usage and reliability level (e.g. N% of users acks) can then be discussed with the app team before implementation, as well as the type of messages that need such functionality (e.g. status update vs chat message in channel).\nDeliverable: End-to-end reliability protocol - Status integration §\nIntegrate the previously designed protocol in status-go with parameters agreed with the Status product team. Provide the right REST API (if needed) to ensure this is tested by Vac/QA.\nHarden the library as needed."},"waku/milestones/open/2024-incentivise-running-infra-node":{"title":"Incentivise running a Waku infrastructure node","links":[],"tags":["waku-milestone"],"content":"Milestone: Incentivise running a Waku infrastructure node §\nBy the end of this milestone, we will have defined a roadmap and implemented a working proof of concept to incentivise node operators running Waku infrastructure for shared shards. In general, Waku infrastructure consists of RLN Relay nodes both forming the decentralised routing backbone for Waku messages and providing a set of services on top of Waku that might be useful for applications. A sustainable Waku infrastructure is necessary within Status to achieve scalability for 1:1 chats and permissionless communities. These Status features use RLN rate-limiting on shared shards as supported by the RLN relay nodes and require a set of decentralised services for Status Mobile and resource-restricted clients, including RLN proofs as a service, Store, Filter and Lightpush. This milestone encapsulates the efforts to distribute rewards for running RLN Relay nodes and getting paid for providing Waku services. This is the first step to providing a sustainable way to scale the Status application.\nDeliverable: RLN Relay Incentivisation - Distribute RLN fees PoC §\nProof of concept mechanism for distributing RLN membership fees to RLN relay nodes based on an on-chain consensus mechanism for routed messages. Publishers over an RLN-controlled network pay membership fees, which entitle them to send a given amount of messages per unit of time while the membership remains active. Currently these membership fees are not used and are simply returned on membership expiry. These fees can be used to incentivise the RLN relay nodes that support the rate-limited infrastructure by routing and validating messages.\nDeliverable: RLN Relay Incentivisation - RLN fee sharing roadmap &amp; spec §\nBased on learnings from the PoC, formalise a basic specification for RLN fee sharing and message consensus. The specification should be published alongside an implementation roadmap that makes the next steps clear.\nDeliverable: Service Incentivisation - Pay for RLN provision PoC §\nProof of concept of paying for RLN provision to a light client by a service node.\nA POC payment mechanism that incorporates PoC versions of the three Waku service marketplace elements:\n\na price offer/negotiation mechanism\na proof of payment system\na local reputation mechanism to distinguish between “good” and “bad” service nodes\n\nSuch a PoC would enable discussion with the Status app team on a potential way to provide a paid tier to 1:1 chats users.\nDeliverable: Service Incentivisation - Service incentivisation roadmap &amp; spec §\nBased on learnings from the PoC, formalise a basic specification for general service incentivisation. The specification should be published alongside an implementation roadmap that makes the next steps clear."},"waku/milestones/open/2024-nwaku-in-status-desktop":{"title":"Nwaku in Status Desktop","links":[""],"tags":["waku-milestone"],"content":"Milestone Nwaku in Status Desktop (Relay mode)\nEstimated date of delivery: 2025-01-31\nThere is work duplication in go-waku and nwaku due to the common area of concern: relay usage and native library.\nWith this milestone, Status Desktop builds can use nwaku instead of go-waku. However, it should be seen as a MVP as further hardening and implementation of light client mode will be missing.\nGo-waku will still be used for Status Mobile.\nThis strategy enables concrete steps toward sunsetting go-waku in a short period of time, avoiding a perpetual prototyping phase where many high risk problems (e.g. mobile bundle size, etc) have to be solved before the switch can be made.\nThe next milestone will then focus on hardening the nwaku Desktop build and implement missing features such as Reliability Protocol for resource-restricted. Once done, it will reduce the scope of go-waku maintenance to light clients only and drastically reduce the duplicate work done between nwaku and go-waku.\nNote that we want to draw the line to RLN in terms of go-waku maintenance, meaning that if Status were to use RLN (see Scale 1:1 chat messages PoC), then it should happen with nwaku.\nDeliverable: Nwaku on Windows §\nEnsure that nwaku can build and run on Windows. This includes regular PR CI and test run done on Windows environments.\nDeliverable: Nwaku in Status Desktop (Relay) §\nUse nwaku instead of go-waku in Status Desktop and produce a working and distributable special (no light client) build for Linux and Mac OS environments.\n“Light client” mode should be disabled for this build as only relay protocols are implemented.\nWindows builds are also out of scope.\nThis includes an abstraction layer to enable the other builds to still use go-waku:\n\nDesktop Windows\nDesktop “prod” (with both light client and relay modes, via go-waku)\nMobile\n\nCLIs created for Vac/QA should also be produced with nwaku to enable QA and DST to run tests/simulations."},"waku/milestones/open/2024-rln-mainnet":{"title":"RLN Mainnet","links":[],"tags":["waku-milestone"],"content":"RLN Mainnet §\nEstimated date of Completion: 2024-12-31\nOnce complemented, the economical behaviour of RLN will have been specified, implemented and discussed with the Status team.\nAn implementation of RLN for light clients will also be done, to demonstrate RLN’s UX with onchain Merkle tree.\nFinally, the smart contract will be deployed on mainnet.\nIt will be then possible to design the usage of RLN in Status 1:1 chats.\nDeliverable: RLNv2 in nwaku §\nImproved flexibility of the rate limit (from 1 msg/epoch to N msg/epoch), providing better dimensioning for bandwidth capping.\nMoving from RLNv1 to RLNv2 to allow better bandwidth dimensioning in the network. This will allow a message allocation per hour or day per registered publisher, providing better statistical guarantees for network bandwidth usage.\nNote this only concerns native libraries using nwaku.\nDeliverable: Maturing RLN variables/parameters revision (staking, contract/chain, token) - roadmap §\nA review of RLN security parameters and functionality in preparation for mainnet deployment.\nAnalyse RLN deployment in the Waku proto-network and evaluate its DoS protection performance as well as review with the Status app team the potential cost mode of RLN:\n\nShould staking be introduced, especially to improve resilience against adversarial membership registrations?\nShould slashing be introduced or does the existing gossipsub scoring method provide enough protection?\nWhich chain or L2 should we target for memberships?\nWhat token should be used?\nDo we need a combination of msg/sec and msg allocation/day rate limiting?\n\nDeliverable: Provision RLN for light push clients POC §\nDesign and implement a protocol that attaches RLN proof for messages received by light push services, enabling light clients to use the network without RLN.\nWith this deliverable, nwaku nodes deployed as service nodes lend their RLN memberships to light clients. Enabling Status app to offer a free tiers usage of RLN Relay for 1:1 chat messages.\nThis is a first PoC, learnings around RLN rate limit parameters, need of multiple RLN managements and service capability are expected to drive further development.\nDeliverable: Implement RLN smart contract for paid, multilevel memberships §\nThis deliverable is an output of Maturing RLN variables/parameters revision (staking, contract/chain, token) - roadmap.\nOnce we have matured the RLN parameters and specified a minimal set of (smart contract) features for a production-ready membership mechanism, the proposed smart contract changes must be implemented. This also implies implementing each feature in the different Waku clients as needed.\nInitial discussion indicates that our minimal feature set include:\nPaid RLN memberships\nRLN memberships at different rate-limit tiers\nExpiry of memberships to prevent hogging\nSupport for RLN in resource-restricted clients, i.e. lightweight proof generation and validation\nThe exact set of features is to be defined in a RFC, as output of Maturing RLN variables/parameters revision (staking, contract/chain, token) - roadmap.\nDeliverable: RLN contract revision and audit §\nOnce a minimal set of smart contract features for RLN has been implemented, the contract needs to be thoroughly revised (and possibly audited) by a group of experts before it can be used in production.\nThe Waku team will rely on Vac/SC to proceed/organise the smart contract review and audit\nDeliverable: Deploy RLN smart contract to a L2 mainnet §\nThe RLN smart contract should be deployed to a Layer 2 mainnet.\nA first step here may be to deploy to a Layer 2 testnet first. However, we could deploy a test contract to a Layer 2 mainnet directly if it’s easier. (A contract used for testing does not have to be productionised/audited before deployment to mainnet.)\nThis deliverable tracks all steps to deployment of a production version of the contract to a L2.\nDeliverable: Public dogfooding RLNaaS web app §\nSecond part of original scope of dogfooding web app.\nOne of the proposed strategies to roll out RLN for Status 1:1 chats is to use RLNaaS where a service node attaches RLN proof for light clients. This would enable a roll out of RLN without impacting UX or UI.\nHowever, this would decrease the security that RLN brings, so we need to further test this topology to better under risks and mitigate them, or drop this approach.\nDeliver a gamified web app to allow further dogfooding of RLN. This should build on the previously delivered (internal) web app to collect reliability and performance metrics.\nThis may include capturing new metrics from the fleets to gather data and assess the viability of RLNaaS from this experiment."},"waku/milestones/open/2024-scale-number-of-communities":{"title":"Scale up number of Communities","links":[],"tags":["waku-milestone"],"content":"Milestone Scale up number of Communities\nEstimated Date of Completion: 2024-11-30\nProceed with next steps to scale up the number of communities with a focus on testing and configure rendezvous which would enable a large number of communities on their own shard, with the caveat of a more federated global topology.\nThe rendezvous nodes of a community would be a centralised infra to a community.\nAlso proceed with enhancing of the current decentralised discovery protocol to pave the way towards less centralised topology.\nDeliverable: Usage of rendezvous §\nTest libp2p rendezvous in nwaku (server) and go-waku (client) to have it ready as a replacement of discv5 to enable over 100 communities.\nThis should mainly be around configuration, testing and potential bug fixing.\nRendezvous discovery is federated-like and non-private. It is an existing libp2p protocol.\nDeliverable: DoS protection for req-res protocols and metrics (go-waku as service node) §\nReplicate the DoS protection (local rate limit) logic from nwaku to go-waku as Status Desktop do serve filter and light push node.\nIf Desktop nodes get DoS via light push/filter service, then it can be disabled, however this may compromise scalability of mobile and would involve deploying more fleet.\nAs the desktop/mobile ratio is uncertain, best to have this implemented."},"waku/milestones/open/2024-static-sharding-dedicated-shards":{"title":"Static Sharding - dedicated shards","links":[],"tags":["waku-milestone"],"content":"Milestone Static Sharding - dedicated shards §\nEstimated Date of Completion: 2024-12-31\nCreating a new community on its dedicated shard would be tested and working, including assigning a pre-shared key for opt-in message signing (weak DoS protection).\nCommunity creation on a default shard (32) to remain (up to app team to hide button or not) to enable mass creation of communities on shared shard for QA testing purposes.\nVac QA and DST are asked to look at Status Communities behaviour, whereas previously the focus was on direct messages reliability (one layer lower).\nFinally, telemetry service will be updated to include bandwidth usage statistics, with a fine breakdown to understand top bandwidth consumers (control msg, chat msg, etc). Additionally, the DST team is asked to run simulations with a focus on bandwidth usage.\nDeliverable: Telemetry: Measure Bandwidth §\nAdd bandwidth measurements to the self-report (opt-in) telemetry service, including a message type breakdown (ctrl, chat, etc) when possible as well as other protocols such as discovery.\nUsage of non-waku bandwidth should also be considered (bittorrent, RPC) to have a full picture in case of report of high bandwidth usage by users.\nDeliverable: Telemetry: Sharding §\nImprove telemetry service to capture shard information. Particularly relevant for discovery and connection.\nImprove API to display shard information to users in the node management tab, to provide more accurate health metrics.\nDeliverable: Sharding peer management and discovery hardening §\nFurther testing and improvement of peer management in the context of sharding in all Waku implementations. The aim is to ensure that nodes are connected to other nodes of interested shards. As the number of shards (several communities) increase, some improvement on the logic should be needed.\n(1) nwaku and go-waku need to follow the same pattern here in terms of relay peer management. For Relay peer management:\n\nremove named sharding to simplify peer management\nreview per-shard peer management metrics (e.g. mesh health per subscribed shard)\nmonitor and adapt peer management strategy across both go-waku and nwaku for various shard subscription scenarios (e.g. up to 100 pubsub topic subscriptions) in an integrated deployment\n\n(2) go-waku and nwaku should also follow the same patterns in terms of managing filter/ligh tpush clients (i.e. always keep a predictable amount of open slots for clients) with similar steps to the above to harden the strategy\n(3) go-waku and js-waku should follow the same patterns in terms of managing service peers within clients.\n(4) Capture recommendations in an RFC and use it as a discussion and decision medium across implementations.\nDeliverable: Enable testing of custom shard implementation for Communities §\nCreate/update CLI with REST API to enable creation and usage of static communities on own dedicated shard for Vac/QA to proceed with testing of various scenarios.\nThis CLI should also enable running simulations of bandwidth usage by communities, including ctrl messages.\nThis includes the setup of a pre-shared key to protect the shard and fixing any bug reported.\nNote that the ability to create communities on a custom shard and assign a pre-shared key for DoS protection is already implemented in status-go.\nNote that telemetry service should include shard specific reports.\nDeliverable: Setup Waku Community on dedicated shard with pre-shared key dos protection §\nCreate a Waku token-gated community on its own dedicated shard to further dog food sharding, find and fix any Waku related bugs as well as providing support to the Status app team.\nThe outputs of this deliverable are:\n\nWaku token-gated community created on dedicated shard. While this community may not be advertised publicly at first, it will be set up as if, with Waku CC and IFT CCs roles being defined etc.\nDocument that summarises the steps to setup a dedicated community, where IFT devops are provisioning the new shard, and setting pre-shared key in coordination with community owner.\n\nDeliverable: PostgreSQL Optimisation phase 2 §\nWith phase 1, feedback from test stressing and IFT CC has been tackled.Preparation has been done to consult an external agency to fine tune PostgreSQL setup.\nPhase 2 tracks the consultation with the external agency and follow-up work:\n\nOnce all suggestions from IFT PostgreSQL expert are implemented, setup an agreement with consulting agency specialised in PostgreSQL performance to improve performance\n\nThis should include a better understanding of hardware requirements expectations to run Waku infra for Status."},"waku/milestones/open/2024-store-service-upgrade":{"title":"Store Service Upgrade","links":[],"tags":["waku-milestone"],"content":"Milestone Store Service Upgrade\nEstimated date of completion: 2024-09-20\nWith this milestone, the store protocol becomes more easily usable for reliability purposes.\nMoreover, nwaku PostgreSQL implementation will enable better disk space management and enable operators to hard cap the used disk space.\nDeliverable: Store v3-beta - Message Hashes §\nEnable the Waku Network to provide distributed and synchronised store services.\nAn improved version of the Store protocol, marking a crucial increment towards a synchronisation protocol:\n\nintroduces the concept of deterministic message hashes to index messages\nconsiders the Store as a key-value store\nallows for querying a list of keys (message hashes) from the Store\nallows for querying for the full message content (values) of a set of keys from the Store\nkeeps all previous value-based filtering (e.g. content topic, timestamp) in place\n\nDeliverable: Store v3 - store synchronisation §\nUpgrade the Store service capability in the network from a collection of local, unsynchronised,\nsemi-centralised (trusted) service nodes to a decentralised service capability in the network with inter-node synchronisation.\nBuilding on Store v3-beta, this version of Store includes basic synchronisation between nodes. This will probably include:\n\na protocol/heuristic to resume store services after an offline period\na protocol/heuristic to periodically compare local key-value store with other nodes and find missing keys\na protocol/heuristic to periodically download the messages (values) for missing keys from other store nodes\n\nDeliverable: DoS protection for req-res protocols and metrics §\nAdd local DoS protection service nodes by applying request rate limitation on non relay protocols, including store.\n\nApply some limited bandwidth limitation on service protocols\nProvide failsafe mechanisms to third party apps / client side help for request rejection mechanisms\n\nDeliverable: PostgreSQL Maintenance §\nProvide a solution on how to best handle PostgreSQL database growth and pruning, so that node operators can predict database size and avoid disruptions due to full disk space.\nDeliverable: Metric: Count store messages §\nMessage-finder is used to compare the number of Status messages across Status nodes to understand the potential discrepancies and odd behaviour of messages being inserted in the past in a given channel.\nThis deliverable captures the message count on all Waku fleets to use as a metrics of the efficacy of store sync."},"waku/monthly-reports/2023-aug":{"title":"2023-aug","links":[],"tags":[],"content":"Waku Monthly Report - August 2023 §\nEpics and Milestones §\n\n\nWaku Network Can Support 10K Users\n\nPostgreSQL integration for improved performance\nSetting up a staging fleet for Status to try static sharding\nStress testing and performance comparisons between SQLite and PostgreSQL\n\n\n\nLight Protocols and Status MVP\n\nLight push and filter protocols available in Status Mobile and Desktop\nPeer Exchange supported and used by default in js-waku\nSome light dogfooding has started\n\n\n\n1 Million Users / Public Waku Network\n\nCompleted Autosharding v1 for nwaku\nTask breakdown and assignment for the epic\nStarted work on Waku Network RFC\n\n\n\nQuality Assurance and Maintenance\n\nImproved release processes for nwaku\nEnhanced test coverage for go-waku\nMaintenance work on js-waku, including dependency upgrades\n\n\n\nRLN (Rate Limiting Nullifier) Improvements\n\nPost-Testnet3 improvements in go-waku\nRLN enabled by default in go-waku\n\n\n\nPeer Management\n\nIntroduced peer management in go-waku\nImplemented sharded peer management and discovery in nwaku\n\n\n\nClient Updates §\nnwaku §\n\nCompleted Autosharding v1 implementation\nProgress on PostgreSQL integration and stress testing\nImprovements in HTTP REST API support\nEnhancements in C-bindings and thread safety\nSetting up static sharding fleet for Status\n\njs-waku §\n\nPeer Exchange supported and used by default\nMaintenance work, including dependency upgrades\nImprovements in developer experience\nProgress on covering multiple environments in testing\n\ngo-waku §\n\nRLN enabled by default and running on all configured topics\nImplemented core logic for Autosharding v1\nIntroduced and improved peer management\nEnhanced test coverage\nMaintenance work, including metrics refactoring\n\nResearch and Documentation §\n\nBreakdown and assignment of tasks for the 1 million users/public Waku Network epic\nStarted work on Waku Network RFC\nAdvanced documentation for js-waku, including debugging guides and NodeJS support\n\nEcosystem Development §\n\nIncreased Twitter followers by 20%\nParticipated in web3conf with talks, side events, and swag distribution\nInitiated migration of eco-dev elements from GitHub to Notion\nPlanning for upcoming events like ETHRome hackathon\n\nChallenges and Next Steps §\n\nContinue refining and implementing the 1 million users/public Waku Network plan\nFurther stress testing and optimization of PostgreSQL integration\nDogfooding new peer management with Status\nExpanding test coverage across all clients\nFinalizing and deploying the static sharding fleet for Status\nAdvancing the Waku Network RFC\nContinuing ecosystem growth through events and community engagement\n\nThe Waku team has made significant progress across multiple fronts in August, with notable advancements in scalability, light protocols, and quality assurance. The focus on supporting 10K users and laying groundwork for 1 million users demonstrates the project’s commitment to growth and adoption."},"waku/monthly-reports/2023-sept":{"title":"2023 September Monthly Waku Report","links":["vac/dst/","vac/dst/wakurtosis/vac/retrospective-rlog","waku/updates/2023-09-04","waku/updates/2023-09-11","waku/updates/2023-09-18","waku/updates/2023-09-25"],"tags":["monthly-report","waku"],"content":"Executive Summary §\nThe month of September saw an agreement and solidification of the Waku roadmap which defines the process of launching the Waku Network as an independent piece of infrastructure the broader ecosystem can rely upon. Along with this, a revamp of the process in which work is labeled and tracked was performed which has an automated part and is generally more in line with the requests from the Insights team.\nWork continues in the scaling and productionization efforts across the clients. Work previously done to enables PostgreSQL engine for WAKU-STORE in nwaku is being locally stress tested, further stress test using dev fleet is expected to be finalized next month. A Waku static sharding strategy is being integrated into Status to accommodate the first growth milestones of the re-release and adaptive sharding research and implementation is close behind.\nLocal simulation of RLN-RELAY has enabled the discovery of minor bugs which are fixed in the latest release of zerokit and nwaku and the study of the affect of RLN on performance.\nKurtosis as a platform was found to be insufficient for modeling a Waku network at the scale we wish, and the Vac team is pursuing an alternative strategy and writing up learnings from the boundaries were able to push.\nQuality Assurance practices are scheduled throughout the next year to keep all client implementations up to a threshold of continuous quality.\nThe process to add native integration APIs to nwaku is underway such that the default native library moves from go-waku to nwaku.\nKey Updates §\nPersonnel §\n\naddition of\n\nAaron as Project Manager\nSergei as Researcher\nGabriel as nwaku Engineer\n\n\nSeveral Jobs Descriptions have been reviewed this month to be opened shortly:\n\nGrowth Lead/Marketing strategist to drive Waku’s growth and liaise with Comms Hubs\nBusiness Development Lead, to further develop partnership with ecosystem projects\nSolution Engineer, to provide technical support to projects integrating Waku\n\n\nA core contributor to lead the Waku Chat SDK team has been secured, with start date in November.\n\nMilestones §\nA lot of work has been put into coalescing and finalizing the development tracking process that is in line with the Insight Reporting requirements, and Aaron’s addition to the team this month as pushed it over the edge to completion. Much of this has gone into automating the weekly reporting process via GitHub labels and comments on issues.\nFor tracking Waku maintains these Milestones in the waku-org/pm repo. Within each milestone description, you’ll find the corresponding Epics. Every Epic is distinctly labeled, and this label is affixed to each issue associated with that particular Epic. The labels are managed by the labels.yaml file located in the waku-org/pm repo.\nGiven the expansive nature of Waku and its various repositories working towards the milestones, the labels established in the labels.yaml file are replicated across each respective waku-org repo. This structure allows for seamless navigation, starting from top-level milestones down to the most granular issues.\nWaku is broken out into the following four Milestones, with Epics associated with them:\n\nWaku Network Gen0\nWaku Network Can Support 1MM Users\nQuality Assurace Processes in Place\nSupport Many Platforms\n\nMore details on the structure and progress of all Waku work can be tracked in their PM repository, specifically the milestone page. The following sections are highlighted updates on what happened this month.\nWaku Network Gen0 §\nThe Waku Network RFC was created and published on Vac as RAW which details the ideas and architecture of the Waku Network. The next version of RLN was also published on Vac as RAW.\nA benchmark of RLN was conducted and the results were discussed in a Logos Research Call presentation (See waku-org/research#23 for details). The tl;dr is copied here for convenience:\n\n\n                  \n                  TLDR: \n                  \n                \n\nProof generation is constant-ish. 0.15 second for each proof\nProof verification is constant-ish, 0.012 seconds. In a network with 10k nodes and D=6 this would add an overhead delay of 0.06 seconds.\nGossipsub scoring drops connections from spammer peers, which acts as the punishment (instead of slashing). Validated in the simulation.\nRLN doesn’t have any impact on memory consumption.\n\n\nBased on these two specification publications and other associated work, efforts have begun to launch the first dev-testnet in time for the DevConnect event in November 2023.\nAll launch critical work for autosharding has been done in terms of RFC and nwaku.\nWaku Network Can Support 1MM Users §\nSignificant work was completed on the PostgreSQL integration and setup within nwaku, which supports the data retention and retrieval of Waku archival nodes. The implementation is currently being stress-tested to ensure production performance metrics are met.\nThe efforts in simulating a Waku Network of 10k users within a single shard continues and is tracked within Vac DST Roadmap. The performance of Wakurtosis (Kurtosis backend) was found to be insufficient for our requirements for scaling simulations. The creation of a Kubernetes orchestration tool, written in Python, has begun construction. This tool is heavily architected to mimic what Codex has created. It was chosen to reproduce this tooling in Python in order to increase usability and ease of maintenance/contribution as C# is a less known language within the org. The reasoning for this development can be tracked in retrospective-rlog.\nThe effort to understand a “professional Waku node operator” has begun and initial notes can be tracked within this minutes doc.\nA “static sharding” fleet was setup to test sharding and PostgreSQL by Waku team.\nSetup of a similar fleet dedicated to Status Communities is in progress (the first fleet may be used in the interim).\nQuality Assurance Processes in Place §\nThis milestone was created to ensure preparedness for the upcoming production client needs (specifically Waku Network Gen0 and Status Communities). A list of required processes in place was constructed and tasked out so that all implementations of Waku go through a standardized production release cycle.\nThis work is coordinating with the new Vac DST additions focused on testing rubrics for Logos Projects. This milestone is expected to be completed by Q1 2024.\nWork has started to use the js-waku CI as an integration test suite for nwaku and go-waku. This test suite can now easily be run for either client as part of their release process.\nSupport Many Platforms §\nThis is a large milestone created last month that tracks Waku’s “integration landscape” and attempting to ensure any developer seamlessly is able to integrate Waku.\nIt has started to list the work required for completion but more detail is needed to be fleshed out on prioritization and estimated resource needs. Currently, it is slotted for completion by April 2024.\nMuch of the work this month was fleshing out the available REST APIs of nwaku.\nA poll was created to query what language priority we should have was gone. They’ll be published on socials next month to boost engagement and feedback. This poll will assist with priorities for this milestone.\nPerceived Changes in Project Risk §\n\nWaku doing most integration of Waku into status-go consumes a lot of Go-related developer resources.\n\na list of needed work is tracked here\n\n\nThere effort to convert nwaku to the main native integration client requires a large effort in the implementations of C-bindings in Nim and has some unknowns associated with it. Furthermore this additional effort and uncertainty doesn’t directly contribute to the current critical path of development.\nThe first main application of the milestone reorganization within the project has made the milestones associated with it clear, thus allowing the Waku Network MVP target setup to be tracked well\n\nFuture Improvement Plans §\nInsight §\nThe insight team plans to further evaluate the value the reporting process implemented by Waku as it pertains to use within the other projects under Logos. It is expected that next month it will be finalized and ready for review by other teams to see if they’d like to adopt it.\nOne side effect of the automated reporting process is that the associate issue labels are already compatible with our data lake ingestion that was initiated by the Status project. This will allow us to create more useful dashboards and monitoring that take into account accurate development activity.\nProject §\nAs the milestones continue to be fleshed out and detailed, the ability to show progress over time will improve.\nSources and Useful Links §\nWeekly Reports\n\n2023-09-04\n2023-09-11\n2023-09-18\n2023-09-25\n"},"waku/process":{"title":"Process","links":[],"tags":["waku"],"content":"Resources §\n\nWaku Github: https://github.com/waku-org/\nEngineering Processes: https://github.com/waku-org/pm/blob/master/PROCESS.md\n\nMotivation and Goal §\nImplement the following attribute when delivering:\n\nClear tracking of work across the teams so that when we says that a milestone is delivered, then:\n\nit is usable by all types of users (operators, web devs, system devs).\nIt is documented (docs, dev rel)\nIt is of high quality (QA, Dogfooding)\n\n\nItems (epic, milestones) can be easily be closed and marked as complete thanks to:\n\nMinimal external dependencies\nMinimal intra-team dependency\nFinite, well-define scope.\n\n\nEach milestone and the effort needed to achieve it has a clear value thanks to a well-defined, value-driven, minimal, scope.\n\nTerminology and Scope §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNameNumber ofTimeframeTeam ScopeOwnerDescriptionMilestone?Pencilled for the year, planned for 2 quartersMost subteamsWaku LeadA, or cohesive set of, feature(s).EpicSeveral per milestoneSet for a milestoneUsually one subteam or external team (e.g. DST)Subteam Lead or MemberMilestone work for a given subteam.TaskMany per EpicSet monthly-ish, delivered weeklyOne subteam or individualTeam MemberMay be one or several piece of work, client specific.\nMilestone Definition §\nA Milestone:\n\nProvides a tangible user benefit: The milestone should aim to provide a distinct benefit or feature to the user, whether they are end users, operators or developers. In some case, a milestone may be a bundle of small features. The bundle of features should be cohesive and the benefit to the users should be easy to summarize. Most likely, a bundle milestone will be scoped to a given track.\nMinimal Scope: The milestone should be trimmed to a minimal scope, encompassing only what is just enough to assess the potential impact of these features on the project’s metrics (e.g. number of users, revenue). This means descoping any advanced features and aiming for a MVP-level delivery.\nTransversal: While the vertical scope of a milestone should be minimal, the delivery should be complete in terms of research, engineering, QA, documentation and dev rel assets so that the feature can be pushed to users once the milestone is marked as complete. Feedback loops should be as small as possible to ensure the value of a milestone is measured in a timely manner.\nAttached Estimate: An estimate should be associated with the milestone to facilitate the measurement of potential ROI. Additionally, tracking the estimate versus the actual progress is crucial for identifying any deviation and making informed decisions (e.g., deciding whether to continue if we learn the estimate is likely to be overrun).\n\nMilestone scoping process flow §\nPhase 1: Waku lead defines the scope within the Milestone. The scope is then discussed asynchronously in the comments of the GitHub issue by relevant subteams and stakeholders, scope of Epics and subtasks are defined.\nPhase 2: During a Waku PM call, the team reviews the Milestone to confirm scope or identify areas that require additional scoping.\nPhase 3: If the scope is agreed upon, the team can proceed to create Epics and schedule work for kickoff.\nEpics and Workflow §\nA milestone is divided in Epics. Each epic is assigned to a given subteam.\nEach Waku subteam lead (or selected member) is accountable for the delivery of their epic.\nTypically, each milestone will be divided in the following epics:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEpic Label PrefixOwner Sub-teamOutputDescriptionE:researchWaku ResearchPoC, RFC, Protocol Simulations/StudiesInitial work done by the research team to create or change a protocol. Engineering-only Milestones may not have such epicE:nwakunwakuMVP quality softwareBring software to MVP level, proceed with re-architecture of PoC if needed, ensure functionality is usable, refine APIs, auto-generated/API documentation, ensure interoperability worksE:js-wakujs-wakuMVP quality software, including all supported env (e.g. React Native &amp; Web)Implement protocol in js-waku, same as nwaku.E:bindingsnwakuMVP quality software for supported bindings (WIP)Expose new protocol/features on binding APIs.E:go-wakugo-wakuMVP quality software, include all supported bindings (i.e. C and Rust)Implement protocol in go-waku, only if needed by Status app.E:qaVac/DSTRFC-based + functionality based tests, both unit and integration tests.Test engineers take over and complete unit tests + add scenarios in integration test framework. In future, also add scenario to benchmark suite.E:dogfoodjs-waku, nwaku, bindingsLab example updates, own nodes updated, etc.Each dev team proceed by dogfooding the feature/API by using it themselves. Whether it is running their own node, or updating a selected number of examples. Go-waku can dogfood directly in status-go.E:docsDocDocumentation (not auto-generated)Document the new feature across all implementations, using the dogfooding output as handover material from engineering teams. This includes both coding guides but also a presentation ready visual documentation of the protocol behaviour.E:eco-devEco DevDev Rel assets (examples, video tutorial, etc), comms plan (X threads, blog posts)Dev Rel can now prepare assets to push the feature to developers, comms can prepare copies to communicate about it, BD can push it to projects and partners.\nflowchart LR\n    subgraph milestone [Milestone]\n      scope[Define scope and estimate]    \n    end\n    subgraph researchE [E:research]\n      scope--&gt;research[RFC + Protocol Simulation + PoC]    \n    end\n    subgraph nwakuE [E:nwaku]\n      research-- Handover --&gt;nwaku[MVP, API, Code doc, unit test]\n    end\n    subgraph js-wakuE [E:js-waku]\n      research-- Handover --&gt;js-waku[MVP, API, Code doc, unit test]\n    end\n    subgraph go-wakuE [E:go-waku]\n      research-- Handover --&gt;go-waku[MVP, API, Code doc, unit test]\n    end\n    subgraph go-wakuE [E:bindings]\n        research-- Handover --&gt;go-waku[API, Code doc, unit test]\n    end\n    subgraph qaE [E:qa]\n      nwaku--Handover--&gt;QA[QA, extended, interop and RFC-based testing]\n      js-waku--Handover--&gt;QA\n      go-waku--Handover--&gt;QA\n    end\n    subgraph dogfoodE [E:dogfood]\n      nwaku--&gt;Dogfooding[Developer use new software and API, interoperability]\n      js-waku--&gt;Dogfooding\n      go-waku--&gt;Dogfooding\n    end\n    subgraph docsE [E:docs]\n      Dogfooding-- Handover --&gt;Docs[Update and create guides and protocol documentation]\n    end\n    subgraph ecodevE [E:eco-dev]\n      Dogfooding-- Handover --&gt;Eco-Dev[Dev Rel and BD assets, plan Comms]\n      Docs--&gt;Eco-Dev\n    end\n\nEngineering-Only Milestones §\nSome milestones may not involve the Waku Research team. In this case, the flow still applies but E:research is skipped.\nChat SDK and other Special SDK Work §\nThe Chat SDK team is focusing on go-waku integration in status-go and follows Status’ PM for issues and labelling.\nOnce the team starts building an independent Chat (or other) SDK, the flow will be as above but with research handled by VAC/ACZ and only one dev team:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEpic PrefixOwner Sub-teamOutputDescriptionE:aczVac/ACZRFCRFC describing a specific, likely agnostic protocolE:chat sdkChat SDKPoC and then MVP quality software, Application RFCImplement the ACZ RFC, define API and application protocol\nHandover to QA, Docs, Eco Dev with MVP quality software is still expected down the track but may be pending growing teams.\nAccountability §\nEach epic should have an owner per subteam.\nMost epics will have a unique owner (e.g. a Waku Research team member owns a E:research epic).\nFor Dogfood and QA epics, one owner per client should be set.\nThe epic owner is responsible for breaking down the work in smaller issues in the related repo.\nFor research team, it is expected that most of the research work is done by the epic owner, which includes:\n\nCapturing problem statement\nDesigning protocol/solution\nImplementing PoC in reference implementation\nRunning tests/simulations to confirm behaviour (to be offloaded to test engineer)\n\nFor development teams, it is expected that design/break down is done by the epic owner.\nBut actual work can be picked up by other team member.\nEpic owner must:\n\nUnderstand the change and its implications,\nLiaise with researcher for any doubt or questions or design issues related to specific client/use case,\nCreate issues (Tasks) to break down work in client repo, include an acceptance criteria in each issue to ensure that the objective/end goal/behaviour is clearly described.\n\nIt is likely that the epic owner will do the core change or first change for a given epic.\nHowever, subsequent/other changes may be picked up in parallel or sequentially by other team members.\nHence:\n\ndependencies must be clearly stated in Task issue description\nTeam members must assign Task issues to themselves when work starts\nTeam members must update issues to track progress\n\nThe program manager should ensure that epics are getting the right assignee in a timely fashion.\nFor example, when research work starts for a given milestone, epic owners from development team should be assigned, so they know to participate in discussions.\nProgram manager should also ensure that issues are being created in a timely fashion,\nan is encouraged to use client PM call as a forum to check epics to be assigned, for example when a given epic is near completion.\nHandovers §\nThe following handovers are defined:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHandoverExpectations when handing overExpectations when accepting handoverResearch to development teams- RFC PR is merged  - PoC PR is merged- RFC content and PoC are reviewed  - Own code and functionality  - Own minor RFC changesDevelopment teams to QA- Happy path and selected error path tests exist  - APIs are implemented to enable interop testing- Review RFC  - Review existing testsDevelopment teams to Docs- Working usage of API is provided  - Auto-generated documentation for public API is present- Review examples  - Understands functionality Docs to Eco Dev- Docs PR is merged with functioning code- Understands functionality  - Execute guides\nThe group or person handing over is expected to initiate a sync (meeting) or async (chat or GitHub) discussion to go through the output and overview.\nOnce the handover is accepted, the given epic can be closed.\nGitHub Usage §\nA Milestone:\n\nMUST have a matching GitHub issue in the https://github.com/waku-org/pm repo with milestone label assigned.\nMUST have a GitHub Milestone in https://github.com/waku-org/pm repo, to which relevant Epics are added.\nThe GitHub milestone MUST be used to track progress.\n\nAn Epic:\n\nMUST have a matching GitHub issue in the https://github.com/waku-org/pm repo.\nMUST have a label with format E:&lt;prefix&gt; &lt;epic name&gt;.\nSHOULD be added to a GitHub Milestone.\nSHOULD have a Planned Start and Due Date set (these are GitHub projects fields you can find in the Projects section of the issue view sidebar).\nMAY list Tasks present in other repos.\nMUST have assignee(s), who represent the epic owner (see accountability)\n\nA Task:\n\nMAY be tracked as a todo item in a GitHub Issue (Task or Epic),\nOR MAY be tracked as a single GH issue\n\nthat MUST be labelled with related Epic label (E:...),\n\n\nOR MAY be tracked as a GH Pull Request\n\nthat MUST have a reference to the related GitHub Task or Epic issue\n\n\nMUST have an acceptance criteria and/or a list of tasks (that can be other GH issues).\n\nFinally, for Tasks that do not belong to a given Epic or Milestone:\n\nMUST have either labels:\n\nbug: This is a bug, likely reported by a user\nenhancement: This is an enhancement out of the scope of the technical roadmap, likely reported by a user\n\nMajor enhancements should be carefully reviewed and prioritized.\n\n\ndocumentation: Documentation improvement or correction.\ndependencies: Upgrade dependencies in a timely manner to avoid time wasting when the dependency upgrade becomes critical.\n\n\n\nWhich means, in terms of navigation:\n\nWork for a Milestone is described in the related GitHub issue and tracked in the GitHub milestone.\nIn the GitHub milestone, we have a list of Epics to be achieved, the Epics are being closed as the work is done and handed over.\nTo look at remaining work for an Epic, one need to look at all issues (Tasks) with the corresponding Epic label (E:...)\n"},"waku/reports":{"title":"Waku Reporting","links":["waku/monthly-reports/2023-sept","waku/monthly-reports/2023-oct"],"tags":["wakureporting"],"content":"Overview §\n\nDaily standups are posted in the team discord.\nWeekly progress reports are submitted as comments on open issues in any public waku-org github repository. A script compiles the relevant comments and prepares for publication.\n\nWeekly updates pertaining to progress made toward active Epics and Milestones can be found here.\n\n\nMonday all-team PM meetings are held three times to accommodate all time zones.\nWaku client-team PM meetings are held throughout the week depending on the general timezone and schedules of the team.\nWeekly highlights are derived from the weekly dev updates and compiled for publication by the Comms team via the “Waku Wednesday” series on X.\n\n\nMonthly Reports §\n\n2023 September\n2023 October\n"},"waku/templates/weekly-update-template":{"title":"TEMPLATE 2024-MM-DD Waku Weekly","links":[],"tags":[],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\nnext:\nblockers:\n\n\n\nStore v3 - store synchronisation\n\nachieved:\nnext:\nblockers:\n\n\n\nDOS protection for req-res protocols and metrics\n\nachieved:\nnext:\nblockers:\n\n\n\nPostgreSQL Maintenance\n\nachieved:\nnext:\nblockers:\n\n\n\nMetric: Count store messages\n\nachieved:\nnext:\nblockers:\n\n\n\nMilestone - Direct Message Reliability §\n\n\nEnable testing of direct messages\n\nachieved:\nnext:\nblockers:\n\n\n\nReview connection management strategy and back-off and fix long disconnection issues\n\nachieved:\nnext:\nblockers:\n\n\n\nTooling: filter and light push protocols\n\nachieved:\nnext:\nblockers:\n\n\n\nTelemetry: fleet logging\n\nachieved:\nnext:\nblockers:\n\n\n\nTelemetry: direct message reliability\n\nachieved:\nnext:\nblockers:\n\n\n\nReliability Protocol for Relay\n\nachieved:\nnext:\nblockers:\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\nnext:\nblockers:\n\n\n\nUser apps for large scale dogfooding\n\nachieved:\nnext:\nblockers:\n\n\n\nReview MVDS usage and fail path\n\nachieved:\nnext:\nblockers:\n\n\n\nMilestone - End-to-end reliability protocol §\n\n\nTelemetry: multicast message reliability\n\nachieved:\nnext:\nblockers:\n\n\n\nEnd-to-end reliability protocol - PoC\n\nachieved:\nnext:\nblockers:\n\n\n\nEnd-to-end reliability protocol - Status integration\n\nachieved:\nnext:\nblockers:\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\n\nTelemetry: Measure Bandwidth\n\nachieved:\nnext:\nblockers:\n\n\n\nSharding peer management and discovery hardening\n\nachieved:\nnext:\nblockers:\n\n\n\nEnable testing of custom shard implementation for Communities\n\nachieved:\nnext:\nblockers:\n\n\n\nMilestone - RLN Mainnet §\n\n\nRLNv2 in nwaku\n\nachieved:\nnext:\nblockers:\n\n\n\nMaturing RLN variables/parameters revision\n\nachieved:\nnext:\nblockers:\n\n\n\nProvision RLN for light push clients PoC\n\nachieved:\nnext:\nblockers:\n\n\n\nPay for RLN provision first PoC\n\nachieved:\nnext:\nblockers:\n\n\n\nPublic dogfooding RLNaaS web app\n\nachieved:\nnext:\nblockers:\n\n\n\nImplement RLN smart contract for paid, multilevel memberships\n\nachieved:\nnext:\nblockers:\n\n\n\nMilestone - Scale up number of Communities §\n\n\nUsage of Rendezvous\n\nachieved:\nnext:\nblockers:\n\n\n\nDoS protection for req-res protocols and metrics (go-waku as service node)\n\nachieved:\nnext:\nblockers:\n\n\n\nMilestone: Nwaku in Status Desktop §\n\n\nNwaku in Golang: Desktop\n\nachieved:\nnext:\nblockers:\n\n\n\nNwaku in Golang: Relay\n\nachieved:\nnext:\nblockers:\n\n\n\nNwaku in Status Desktop\n\nachieved:\nnext:\nblockers:\n\n\n\nNwaku on Windows\n\nachieved:\nnext:\nblockers:\n\n\n\nMilestone: Incentivise running a Waku infrastructure node §\n\n\nRLN Relay Incentivisation - Distribute RLN fees PoC\n\nachieved:\nnext:\nblockers:\n\n\n\nRLN Relay Incentivisation - RLN fee sharing roadmap &amp; spec\n\nachieved:\nnext:\nblockers:\n\n\n\nService Incentivisation - Pay for RLN provision PoC\n\nachieved:\nnext:\nblockers:\n\n\n\nService Incentivisation - Service incentivisation roadmap &amp; spec\n\nachieved:\nnext:\nblockers:\n\n\n\nMilestone: Bandwidth optimization and protocol review §\n\n\nStatus usage of Waku scaling and bandwidth optimization recommendation\n\nachieved:\nnext:\nblockers:\n\n\n\nReview usage of content topics in Status Chat and Communities protocol\n\nachieved:\nnext:\nblockers:\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\nnext:\nblockers:\n\nMaintenance §\n\nachieved:\nnext:\nblockers:\n\nBugs §\n\nachieved:\nnext:\nblockers:\n\nMilestone: Demonstrate product-market fit §\n\n\nDefine cost (self-host)\n\nachieved:\nnext:\nblockers:\n\n\n\nThe Waku Whitepaper\n\nachieved:\nnext:\nblockers:\n\n\n\nDefine potential USPs\n\nachieved:\nnext:\nblockers:\n\n\n\nDefine target customers\n\nachieved:\nnext:\nblockers:\n\n\n\nCustomer Interviews\n\nachieved:\nnext:\nblockers:\n\n\n\nCo-design sessions\n\nachieved:\nnext:\nblockers:\n\n\n\nReview Waku MVP\n\nachieved:\nnext:\nblockers:\n\n\n\nMilestone: Acquire first 10 customers §\n\n\n5-10 Highly qualified leads\n\nachieved:\nnext:\nblockers:\n\n\n\nReview current integrations\n\nachieved:\nnext:\nblockers:\n\n\n"},"waku/updates/2023-07-24":{"title":"2023-07-24 Waku weekly","links":[],"tags":["waku-updates"],"content":"Disclaimer: First attempt playing with the format. Incomplete as not everyone is back and we are still adjusting the milestones.\n\nDocs §\nMilestone: Foundation for Waku docs (done) §\nachieved: §\n\noverall layout\nconcept docs\ncommunity/showcase pages\n\nMilestone: Foundation for node operator docs (done) §\nachieved: §\n\nnodes overview page\nguide for running nwaku (binaries, source, docker)\npeer discovery config guide\nreference docs for config methods and options\n\nMilestone: Foundation for js-waku docs §\nachieved: §\n\njs-waku overview + installation guide\nlightpush + filter guide\nstore guide\n@waku/create-app guide\n\nnext: §\n\nimprove @waku/react guide\n\nblocker: §\n\npolyfills issue with js-waku\n\nMilestone: Docs general improvement/incorporating feedback (continuous) §\nMilestone: Running nwaku in the cloud §\nMilestone: Add Waku guide to learnweb3.io §\nMilestone: Encryption docs for js-waku §\nMilestone: Advanced node operator doc (postgres, WSS, monitoring, common config) §\nMilestone: Foundation for go-waku docs §\nMilestone: Foundation for rust-waku-bindings docs §\nMilestone: Waku architecture docs §\nMilestone: Waku detailed roadmap and milestones §\nMilestone: Explain RLN §\n\nEco Dev (WIP) §\nMilestone: EthCC Logos side event organisation (done) §\nMilestone: Community Growth §\nachieved: §\n\nWrote several bounties, improved template; setup onboarding flow in Discord.\n\nnext: §\n\nReview template, publish on GitHub\n\nMilestone: Business Development (continuous) §\nachieved: §\n\nDiscussions with various leads in EthCC\n\nnext: §\n\nBooking calls with said leads\n\nMilestone: Setting Up Content Strategy for Waku §\nachieved: §\n\nDiscussions with Comms Hubs re Waku Blog\nexpressed needs and intent around future blog post and needed amplification\ndiscuss strategies to onboard/involve non-dev and potential CTAs.\n\nMilestone: Web3Conf (dates) §\nMilestone: DeCompute conf §\n\nResearch (WIP) §\nMilestone: Autosharding v1 §\nachieved: §\n\nrendezvous hashing\nweighting function\nupdated LIGHTPUSH to handle autosharding\n\nnext: §\n\nupdate FILTER &amp; STORE for autosharding\n\n\nnwaku (WIP) §\nMilestone: Postgres integration. §\nachieved: §\n\nnwaku can store messages in a Postgres database\nwe started to perform stress tests\n\nnext: §\n\nAnalyse why some messages are not stored during stress tests happened in both sqlite and Postgres, so maybe the issue isn’t directly related to store.\n\nMilestone: nwaku as a library (C-bindings) §\nachieved: §\n\nThe integration is in progress through N-API framework\n\nnext: §\n\nMake the nodejs to properly work by running the nwaku node in a separate thread.\n\n\ngo-waku (WIP) §\n\njs-waku (WIP) §\nMilestone: Peer management §\n_achieved: §\n\nspec test for connection manager\n\nMilestone: Peer Exchange §\nMilestone: Static Sharding §\nnext: §\n\nstart implementation of static sharding in js-waku\n\nMilestone: Developer Experience §\nachieved: §\n\njs-lip2p upgrade to remove usage of polyfills (draft PR)\n\nnext: §\n\nmerge and release js-libp2p upgrade\n\nMilestone: Waku Relay in the Browser §\n"},"waku/updates/2023-07-31":{"title":"2023-07-31 Waku weekly","links":[],"tags":["waku-updates"],"content":"Docs §\nMilestone: Docs general improvement/incorporating feedback (continuous) §\nnext: §\n\nrewrite docs in British English\n\nMilestone: Running nwaku in the cloud §\nnext: §\n\npublish guides for Digital Ocean, Oracle, Fly.io\n\n\nEco Dev (WIP) §\n\nResearch §\nMilestone: Detailed network requirements and task breakdown §\nachieved: §\n\ngathering rough network requirements\n\nnext: §\n\ndetailed task breakdown per milestone and effort allocation\n\nMilestone: Autosharding v1 §\nachieved: §\n\nupdate FILTER &amp; STORE for autosharding\n\nnext: §\n\nRFC review &amp; updates\ncode review &amp; updates\n\n\nnwaku §\nMilestone: nwaku release process automation §\nnext: §\n\nsetup automation to test/simulate current master to prevent/limit regressions\nexpand target architectures and platforms for release artifacts (e.g. arm64, Win…)\n\nMilestone: HTTP Rest API for protocols §\nnext: §\n\nFilter API added\ntests to complete.\n\n\ngo-waku §\nMilestone: Increase Maintability Score. Refer to CodeClimate report §\nnext: §\n\ndefine scope on which issues reported by CodeClimate should be fixed. Initially it should be limited to reduce code complexity and duplication.\n\nMilestone: RLN updates, refer issue. §\nachieved:\n\nexpose set_tree, key_gen, seeded_key_gen, extended_seeded_keygen, recover_id_secret, set_leaf, init_tree_with_leaves, set_metadata, get_metadata and get_leaf\ncreated an example on how to use RLN with go-waku\nservice node can pass in index to keystore credentials and can verify proofs based on bandwidth usage\n\nnext: §\n\nmerkle tree batch operations (in progress)\nusage of persisted merkle tree db\n\nMilestone: Improve test coverage for functional tests of all protocols. Refer to [CodeClimate report] §\nnext: §\n\ndefine scope on which code sections should be covered by tests\n\nMilestone: C-Bindings §\nnext: §\n\nupdate API to match nwaku’s (by using callbacks instead of strings that require freeing)\n\n\njs-waku §\nMilestone: Peer management §\nachieved: §\n\nextend ConnectionManager with EventEmitter and dispatch peers tagged with their discovery + make it public on the Waku interface\n\nnext: §\n\nfallback improvement for peer connect rejection\n\nMilestone: Peer Exchange §\nnext: §\n\nrobusting support around peer-exchange for examples\n\nMilestone: Static Sharding §\nachieved: §\n\nWIP implementation of static sharding in js-waku\n\nnext: §\n\ninvestigation around gauging connection loss;\n\nMilestone: Developer Experience §\nachieved: §\n\nimprove &amp; update @waku/react\nmerge and release js-libp2p upgrade\n\nnext: §\n\nupdate examples to latest release + make sure no old/unused packages there\n\nMilestone: Maintenance §\nachieved: §\n\nupdate to libp2p@0.46.0\n\nnext: §\n\nsuit of optional tests in pipeline\n\n"},"waku/updates/2023-08-06":{"title":"2023-08-06 Waku weekly","links":[],"tags":["waku-updates"],"content":"Milestones for current works are created and used. Next steps are:\n\nRefine scope of research work for rest of the year and create matching milestones for research and waku clients\nReview work not coming from research and setting dates\nNote that format matches the Notion page but can be changed easily as it’s scripted\n\nnwaku §\nRelease Process Improvements {E:2023-qa}\n\nachieved: fixed a bug in release CI workflow, enhanced the CI workflow to build and push a docker image on each PR to make simulations per PR more feasible\nnext: document how to run PR built images in waku-simulator, adding Linux arm64 binaries and images\nblocker:\n\nPostgreSQL {E:2023-10k-users}\n\nachieved: Docker compose with nwaku + postgres + prometheus + grafana + postgres_exporter https://github.com/alrevuelta/nwaku-compose/pull/3\nnext: Carry on with stress testing\n\nAutosharding v1 {E:2023-1mil-users}\n\nachieved: feedback/update cycles for FILTER &amp; LIGHTPUSH\nnext: New fleet, updating ENR from live subscriptions and merging\nblocker: Architecturally it seams difficult to send the info to Discv5 from JSONRPC for the Waku app.\n\nMove Waku v1 and Waku-Bridge to new repos {E:2023-qa}\n\nachieved: Removed v1 and wakubridge code from nwaku repo\nnext: Remove references to v2 from nwaku directory structure and documents\n\nnwaku c-bindings {E:2023-many-platforms}\n\nachieved:\n\nMoved the Waku execution into a secondary working thread. Essential for NodeJs.\nAdapted the NodeJs example to use the libwaku with the working-thread approach. The example had been receiving relay messages during a weekend. The memory was stable without crashing.\n\n\nnext: start applying the thread-safety recommendations https://github.com/waku-org/nwaku/issues/1878\n\nHTTP REST API: Store, Filter, Lightpush, Admin and Private APIs {E:2023-many-platforms}\n\nachieved: Legacy Filter - v1 - interface Rest Api support added.\nnext: Extend Rest Api interface for new v2 filter. Get v2 filter service supported from node.\n\n\njs-waku §\nPeer Exchange is supported and used by default {E:2023-light-protocols}\n\nachieved: robustness around peer-exchange, and highlight discovery vs connections for PX on the web-chat example\nnext: saving successfully connected PX peers to local storage for easier connections on reload\n\nWaku Relay scalability in the Browser {NO EPIC}\n\nachieved: draft of direct browser-browser RTC example https://github.com/waku-org/js-waku-examples/pull/260\nnext: improve the example (connection re-usage), work on contentTopic based RTC example\n\n\ngo-waku §\nC-Bindings Improvement: Callbacks and Duplications {E:2023-many-platforms}\n\nachieved: updated c-bindings to use callbacks\nnext: refactor v1 encoding functions and update RFC\n\nImprove Test Coverage {E:2023-qa}\n\nachieved: Enabled -race flag and ran all unit tests to identify data races.\nnext: Fix issues reported by the data race detector tool\n\nRLN: Post-Testnet3 Improvements {E:2023-rln}\n\nachieved: use zerokit batch insert/delete for members, exposed function to retrieve data from merkle tree, modified zerokit and go-zerokit-rln to pass merkle tree persistence configuration settings\nnext: resume onchain sync from persisted tree db\n\nIntroduce Peer Management {E:2023-peer-mgmt}\n\nachieved: Basic peer management to ensure standard in/out ratio for relay peers.\nnext:  add service slots to peer manager\n\n\nEco Dev §\nAug 2023 {E:2023-eco-growth}\n\nachieved: production of swags and marketing collaterals for web3conf completed\nnext: web3conf talk and side event production. various calls with commshub for preparing marketing collaterals.\n\n\nDocs §\nAdvanced docs for js-waku {E:2023-eco-growth}\n\nnext: create guide on @waku/react and debugging js-waku web apps\n\nDocs general improvement/incorporating feedback (2023) {E:2023-eco-growth}\n\nachieved: rewrote the docs in UK English\nnext: update docs terms, announce js-waku docs\n\nFoundation of js-waku docs {E:2023-eco-growth}\nachieved: added guide on js-waku bootstrapping\n\nResearch §\n1.1 Network requirements and task breakdown {E:2023-1mil-users}\n\nachieved: Setup project management tools; determined number of shards to 8; some conversations on RLN memberships\nnext: Breakdown and assign tasks under each milestone for the 1 million users/public Waku Network epic.\n\n"},"waku/updates/2023-08-14":{"title":"2023-08-14 Waku weekly","links":[],"tags":["waku-updates"],"content":"2023-08-14 Waku weekly §\n\nEpics §\nWaku Network Can Support 10K Users {E:2023-10k-users}\nAll software has been delivered. Pending items are:\n\nRunning stress testing on PostgreSQL to confirm performance gain https://github.com/waku-org/nwaku/issues/1894\nSetting up a staging fleet for Status to try static sharding\nRunning simulations for Store protocol: Will confirm with Vac/DST on dates/commitment and probably move this to 1mil epic\n\n\nEco Dev §\nAug 2023 {E:2023-eco-growth}\n\nachieved: web3conf talk, swags, 2 side events, twitter promotions, requested for marketing collateral to commshub\nnext: complete waku metrics, coordinate events with Lou, ethsafari planning, muchangmai planning\nblocker: was blocked on infra for hosting nextjs app for waku metrics but migrating to SSR and hosting on vercel\n\n\nDocs §\nAdvanced docs for js-waku\n\nnext: document notes/recommendations for NodeJS, begin docs on js-waku encryption\n\n\nnwaku §\nRelease Process Improvements {E:2023-qa}\n\nachieved: minor CI fixes and improvements\nnext: document how to run PR built images in waku-simulator, adding Linux arm64 binaries and images\n\nPostgreSQL {E:2023-10k-users}\n\nachieved: Learned that the insertion rate is constrained by the relay protocol. i.e. the maximum insert rate is limited by relay so I couldn’t push the “insert” operation to a limit from a Postgres point of view. For example, if 25 clients publish messages concurrently, and each client publishes 300 msgs, all the messages are correctly stored. If repeating the same operation but with 50 clients, then many messages are lost because the relay protocol doesn’t process all of them.\nnext: Carry on with stress testing. Analyze the performance differences between Postgres and SQLite regarding the read operations.\n\nAutosharding v1 {E:2023-1mil-users}\n\nachieved: many feedback/update cycles for FILTER, LIGHTPUSH, STORE &amp; RFC\nnext: updating ENR for live subscriptions\n\nHTTP REST API: Store, Filter, Lightpush, Admin and Private APIs {E:2023-many-platforms}\n\nachieved: Legacy Filter - v1 - interface Rest Api support added.\nnext: Extend Rest Api interface for new v2 filter. Get v2 filter service supported from node. Add more tests.\n\n\njs-waku §\nMaintenance {E:2023-qa}\n\nachieved: upgrade libp2p &amp; chainsafe deps to libp2p 0.46.3 while removing deprecated libp2p standalone interface packages (new breaking change libp2p w/ other deps), add tsdoc for referenced types, setting up/fixing prettier/eslint conflict\n\nDeveloper Experience (2023) {E:2023-eco-growth}\n\nachieved: non blocking pipeline step (https://github.com/waku-org/js-waku/issues/1411)\n\nPeer Exchange is supported and used by default {E:2023-light-protocols}\n\nachieved: close the “fallback mechanism for peer rejections”, refactor peer-exchange compliance test\nnext: peer-exchange to be included with default discovery, action peer-exchange browser feedback\n\n\ngo-waku §\nMaintenance {E:2023-qa}\n\nachieved: improved keep alive logic for identifying if machine is waking up; added vacuum feature to sqlite and postgresql; made migrations optional; refactored db and migration code, extracted code to generate node key to its own separate subcommand\n\nC-Bindings Improvement: Callbacks and Duplications {E:2023-many-platforms}\n\nachieved: PR for updating the RFC to use callbacks, and refactored the encoding functions\n\nImprove Test Coverage {E:2023-qa}\n\nachieved: Fixed issues reported by the data race detector tool.\nnext: identify areas where test coverage needs improvement.\n\nRLN: Post-Testnet3 Improvements {E:2023-rln}\n\nachieved: exposed merkle tree configuration, removed embedded resources from go-zerokit-rln, fixed nwaku / go-waku rlnKeystore compatibility, added merkle tree persistence and modified zerokit to print to stderr any error obtained while executing functions via FFI.\nnext: interop with nwaku\n\nIntroduce Peer Management {E:2023-peer-mgmt}\n\nachieved: add service slots to peer manager.\nnext: implement relay connectivity loop, integrate gossipsub scoring for peer disconnections\n\n"},"waku/updates/2023-08-21":{"title":"2023-08-21 Waku weekly","links":[],"tags":["waku-updates"],"content":"2023-08-21 Waku weekly §\n\nEco Dev §\nAug 2023 {E:2023-eco-growth}\n\nachieved: +20% increase on twitter followers and had a discussion with digital comms team regarding improving Waku’s metrics on social handles. Migration of all ecodev elements from github to notion has also been initiated.\nnext: publish the metrics dashboard after call with Vaclav and publish draft for advocates program. Also coordinate with Lou regarding ETHRome hackathon.\nblocker: none\n\n\nDocs §\nAdvanced docs for js-waku\n\nachieved: added guide for js-waku debugging and running in NodeJS - PR111\nnext: js-waku encryption guides\n\n\nResearch §\n1.1 Network requirements and task breakdown {E:2023-1mil-users}\n\nachieved: Breakdown and assign tasks under each milestone for the 1 million users/public Waku Network epic.\nnext: Refine/discuss task breakdown. Start working on Waku Network RFC.\n\n\nnwaku §\nSharded peer management and discovery {E:2023-peer-mgmt}\n\nachieved: discv5 ENR update &amp; filter predicate run-time updating\nnext: PRs feedback updates\n\nAutosharding v1 {E:2023-1mil-users}\nachieved: Complete! FILTER, LIGHTPUSH and RFC merged.\nHTTP REST API: Store, Filter, Lightpush, Admin and Private APIs {E:2023-many-platforms}\n\nachieved: Legacy Filter - v1 - interface Rest Api support added. V2 implementation done wait for PR review\nnext: Testing and add even more tests for failure cases.\n\n\njs-waku §\nMaintenance {E:2023-qa}\n\nachieved: breaking change for @noble/secp256k1 PR in progress, redo trailing commas PR\n\nDeveloper Experience (2023) {E:2023-eco-growth}\n\nachieved: set default fallback fro NodeRequirements\n\nPeer Exchange is supported and used by default {E:2023-light-protocols}\n\nachieved: peer-exchange included by default (PR opened)\nnext: tasks breakdown and followup from dogfooding feedback\n\n\ngo-waku §\nRLN enabled by default {E:2023-rln}\n\nachieved: removed registration capability from the wakunode and created a separate subcommand to do the registration\nnext: run rln-relay on all configured pubsub topics and content topics\n\nMaintenance {E:2023-qa}\n\nachieved: refactored wakuv2 metrics to make each protocol responsible for registering and defining its own metrics\n\nRLN: Post-Testnet3 Improvements {E:2023-rln}\nachieved: interop with nwaku.\n\nIntroduce Peer Management {E:2023-peer-mgmt}\n\nachieved: implement relay connectivity loop, log reachability status reported with help of AutoNAT service, local testing using waku simulator and bug fixes\nnext: work towards dogfooding new peer mgmt with Status\n\n"},"waku/updates/2023-08-28":{"title":"2023-08-28 Waku weekly","links":[],"tags":["waku-updates"],"content":"2023-08-28 Waku weekly §\n\nEpics §\nStatus MVP: Status Core Contributors use Status Mobile {E:2023-light-protocols}\nLight push and filter protocols are available in Status Mobile and Desktop. Some light dogfooding has started.\n\nResearch §\n1.1 Network requirements and task breakdown {E:2023-1mil-users}\n\nachieved: Further task refinement and assigning ownership. Visibility and traceability via GH issues.\nnext: Start working on Waku Network RFC.\n\n\nnwaku §\nsetting up static sharding fleet for Status {E:2023-10k-users}\n\nachieved: final infra definition, including generated keys and shards, specified in infra-status issue\nnext: ensure fleet gets deployed as specified\n\nRelease Process Improvements {E:2023-qa}\n\nachieved: added a CI job to notify on unexpected config option or DB schema changes\nnext: document how to run PR built images in waku-simulator, adding Linux arm64 binaries and images\n\nPostgreSQL {E:2023-10k-users}\n\nachieved: new docker compose in test-waku-query that allows to quickly compare insert and query performance between SQLite and Postgres.\nnext: Carry on with stress testing &amp; follow-up of the Postgres addition to wakuv2.shards by the infra team.\n\nnwaku c-bindings {E:2023-many-platforms}\n\nachieved: Started applying thread-safe recommendations, making the Waku Node instance to be created within the Waku Thread itself.\nnext: Carry on with the thread-safety recommendations: avoid using Channel to communicate main thread and the Waku Thread.\n\nHTTP REST API: Store, Filter, Lightpush, Admin and Private APIs {E:2023-many-platforms}\n\nachieved: Legacy Filter - v1 - interface Rest Api support added. V2 implementation done wait for PR review\nnext: Finish rebase to master, manual adapt of autoshard feature into Filter v2.\n\n\njs-waku §\nMaintenance {E:2023-qa}\n\nachieved: store protocol refactor for readability\n\nPeer Exchange is supported and used by default {E:2023-light-protocols}\n\nachieved: break down dogfooding into tasks for peer-exchange\n\nCover Several Environments As Part of Testing {E:2023-qa}\n\nachieved: created front-end app to be run in a pipeline\nnext: complete app and run in the pipeline, figure out next steps to run Firefox\n\n\ngo-waku §\nRLN enabled by default {E:2023-rln}\n\nachieved: run rln-relay on all configured pubsub topics and content topics, added metrics, made RLN database aware of chainID and contract address, refactored keystore.\nnext:  test keystore interop with nwaku, integrate waku rln registry, and restore valid roots from DB\n\nAuto-sharding v1 {E:2023-1mil-users}\n\nachieved: Implemented core logic for autosharding\nnext: API changes for autosharding\n\nImprove Test Coverage {E:2023-qa}\n\nachieved: Improved test coverage in utils.\n\nIntroduce Peer Management {E:2023-peer-mgmt}\n\nachieved: Raised PR in status-go to use this version in order to dogfood. Local testing with status desktop\nnext: Dogfood changes with Status desktop and mobile using Waku CC’s\n\n"},"waku/updates/2023-09-04":{"title":"2023-09-04 Waku weekly","links":[],"tags":["waku-updates"],"content":"2023-09-04 Waku weekly §\n\nEpics §\n1.1 Network requirements and task breakdown {E:2023-1mil-users}\n\nachieved: Started working on Waku Network RFC. Visibility and traceability in GH improvements.\nnext: Continue working on Waku Network RFC.\n\n\nnwaku §\nsetting up static sharding fleet for Status {E:2023-10k-users}\n\nachieved: negotiation with infra to improve fleet definition, clarify postgresql deployment\nnext: ensure fleet gets deployed as specified\n\nRelease Process Improvements {E:2023-qa}\n\nachieved: minor fixes in GH action workflows, building experimental (i.e. RLN enabled) image per-PR to simlify RLN testing/simulations\nnext: document how to run PR built images in waku-simulator, adding Linux arm64 binaries and images\n\nPostgreSQL {E:2023-10k-users}\n\nachieved: Download and start configuring jmeter to have a variable number of clients sending concurrent Store requests.\nnext: Carry on with stress testing &amp; follow-up of the Postgres addition to wakuv2.shards by the infra team.\n\nnwaku c-bindings {E:2023-many-platforms}\n\nachieved: Merged PR that made the Waku Node to be created within the Waku Thread. Submitted a PR that aims to make a safer the communication between the main thread and the Waku Thread.\nnext: Merge the PR to enhance communication between threads and start extracting the thread context outside the library (comment: https://github.com/waku-org/nwaku/pull/1865#discussion_r1282722954).\n\nHTTP REST API: Store, Filter, Lightpush, Admin and Private APIs {E:2023-many-platforms}\n\nachieved: Legacy Filter - v1 - interface Rest Api support added. V2 implementation done wait for PR review\nnext: Complete Filter v2 PR foundings fixes.\nblocking: PR review found a design flow, need a little redesign.\n\n\njs-waku §\nMaintenance {E:2023-qa}\n\nachieved: @chainsafe/libp2p-gossipsub is updated\n\nDeveloper Experience (2023) {E:2023-eco-growth}\n\nachieved: pre-emptive stream creations for light protocols, using lowest latency peers for light protocols (WIP)\nnext: merging lowest latency peer PR\n\nWaku Relay scalability in the Browser\n\nachieved: complete PoC of Waku Relay over WebRTC using circuit relay\nnext: pause this to prioritize Waku Network milestone\n\nCover Several Environments As Part of Testing {E:2023-qa}\n\nachieved: finishing testing against chrome and react;\nnext: investigate other adding browsers;\n\n\ngo-waku §\nRLN enabled by default {E:2023-rln}\n\nachieved: test keystore interop with nwaku, integrate waku rln registry, and restore valid roots from DB\nnext:  ordered validator execution, bandwidth validation, upgrade zerokit\n\nMaintenance {E:2023-qa}\n\nachieved: allow mixing named and static shards, logs successful message pushes, concurrency fixes for filterv2\n\nAuto-sharding v1 {E:2023-1mil-users}\n\nachieved: Implemented new config for autosharding and ENR updates with shard info\nnext: update various protocols to autoshard\n\n"},"waku/updates/2023-09-11":{"title":"2023-09-11 Waku weekly","links":[],"tags":["waku-updates"],"content":"2023-09-11 Waku weekly §\nResearch §\n1.1 Network requirements and task breakdown {E:1.1 Network requirements and task breakdown}\n\nachieved: Opened first raw version of Waku Network RFC for review.\nnext: Address any feedback on the Waku Network RFC and complete under-defined sections.\n\n\nDocs §\nReview Usage and Metrics 2023 Q3 {E:Define network and community metrics}\n\nachieved: published the language/SDK poll on Discord\nnext: publish the poll on socials for more visibility and responses\n\nDocs general improvement/incorporating feedback (2023)\n\nnext: refactor the layout of the docs to match the new designs\n\n\nnwaku §\nfeat(rest): Add /health endpoint to rest api {E:REST API service node}\n\nachieved: Feature /health endpoint added. PR merged: https://github.com/waku-org/nwaku/pull/2011\n\nfeat: Autosharding API for (relay) subscriptions {E:1.2: Autosharding for autoscaling}\n\nachieved: Refactored and simplified the core logic\nnext: More PR feedback\n\nRelease Process Improvements {E:Automated release processes}\n\nachieved:  execute js-waku tests from nwaku workflows against PRs, nightly and release candidates\nnext: adding Linux arm64 binaries and images\n\nPostgreSQL {E:2.1: Production testing of existing protocols}, {E:PostgreSQL}\n\nachieved:\n\nCreated a jmeter test plan to stress Store queries through REST Store. As a conclusion, the node with Store Postgres showed worse performance than the one with SQLite.\nhttps://github.com/waku-org/test-waku-query/pull/5\nAdded reconnection feature. If the connection with Postgres is lost, the nwaku node tries to reconnect again. https://github.com/waku-org/nwaku/pull/1997\nThe wakuv2.shards fleet had been de-prioritized in favor of the status.shards one.\nhttps://github.com/status-im/infra-nim-waku/issues/74#issuecomment-1710514544\n\n\nnext: Optimize database so that the Store requests behave better with Postgres.\n\nchore: do not advertise MAs with port 0 {bug}\n\nnext: analyze and fix issue\n\nfeat: HTTP REST API: Filter support v2 {E:REST API service node}\n\nachieved: PR tracking is https://github.com/waku-org/nwaku/pull/1890\nReview is done, various fixes upon applied\nnext: Last, agreed interface change to be done to complete.\n\nchore: update resolved enr ip when using dns4-domain-name flag {enhancement}\n\nnext: analyze and fix issue\n\nbug: 0.0.0.0 included in listenAddrs of identify message {bug}\n\nachieved: fixed bug, updated tests according to new fixes and raised PR\n\nnwaku c-bindings (NodeJS + Python) {E:NodeJS Library}\n\nachieved: improved the thread safeness communication.\nhttps://github.com/waku-org/nwaku/pull/1978\nnext: Once the above PR is merged, avoid the use of global variables, to enhance the thread-safeness ( see https://github.com/waku-org/nwaku/pull/1865#discussion_r1282722954 )\n\nHTTP REST API: Store, Filter, Lightpush, Admin and Private APIs {E:REST API service node}\n\nachieved: Legacy Filter - v1 - interface Rest Api support added. V2 implementation done wait for PR review, /health rest api added to check (currently) RLN readiness\nnext: Last round of Filter v2 PR review with finalized re-worked push handler part.\nblocking: /health endpoint come in and Filter v2 work was down prio till.\n\n\njs-waku §\nMaintenance {E:2023-qa}\n\nachieved: updated typescript + plugins to major versions, waiting to merge for release\n\nDeveloper Experience (2023) {E:2023-eco-growth}\n\nachieved:\n\ninvestigation of go-waku interop test that is failing - ongoing, fixing next release\nprotocols now use lowest latency peer instead of a random peer\n\n\nnext: root cause go-waku interop test failure, release next tag on master merge\n\nPeer Exchange is supported and used by default {E:2023-light-protocols}\n\nachieved: Peer Exchange is now merged included in defaultBootstrap\nnext: followup on browser investigation and confirm if the EPIC can be safely closed\n\nCover Several Environments As Part of Testing {test}, {E:2023-qa}\n\nachieved: browser testing is redone and opening for review\nnext: integrate with release process - rather quick follow up, revisit current epic\n\n\ngo-waku §\nRLN enabled by default {E:3.2: Basic DoS protection in production}\n\nachieved:\n\nordered validator execution, upgrade zerokit, append rln proofs when posting msgs in rest/rpc, clean up nullifier table, automatically use key from keystore if only a single credential is available, validate credential using onchain query\nrln membership registration logic refactoring and fixing bugs. Added test for membershipFetcher. Added code for mock_blockchain and mock_client to test membershipFetcher.\n\n\nnext:  bandwidth validation, rln isReady verif in /health endpoint, subcommand to list credentials\n\nMaintenance {E:2023-qa}\n\nachieved:\n\nfix panic observed in peer-manager, update filter protocol as per rfc.\nadd tls/ws to address factory and log ENRs only after they have been setup\nrefactoring and some bug fixes in peermanager and read rfcs and docs\n\n\nnext: increase test coverage and read more code.\n\nImprove Test Coverage {test}\n\nachieved: build examples as part of CI to capture compile errors\n\n"},"waku/updates/2023-09-18":{"title":"2023-09-18 Waku weekly","links":[],"tags":["waku-updates"],"content":"2023-09-18 Waku weekly\n\nEpics §\n1.1 Network requirements and task breakdown {E:1.1 Network requirements and task breakdown}\n\nachieved: Further specifications added for RLN. Merged and published first version of RFC\nnext: Define first launchable (sub)network for Devconnect.\n\n\nDocs §\nAdvanced docs for js-waku\n\nachieved: added guide for local development with nwaku\n\nNode operator doc - cloud and advanced options\n\nachieved: added guide on advanced nwaku and WebSocket configurations\nnext: add guide for enabling node monitoring\n\n\nResearch §\nRLN Key Benchmarks {E:3.2: Basic DoS protection in production}\n\nachieved: benchmark rln, see issue with report.\n\n\nnwaku §\nfeat: HTTP REST API: lightpush  {E:REST API service node}\n\nachieved:\nnext: LightPush REST endpoint will be implemented fully and put on PR review\nblocking:\n\nbug: wrong user_version in sqlite database that blocks the run of a Waku node {bug}\n\nachieved: bug fix that prevented a Store nwaku to start if the SQLite db was created with versions [0.14.0 - 0.18.0]\n\nfeat: Autosharding API for (relay) subscriptions {E:1.2: Autosharding for autoscaling}\n\nachieved: many PR fixes,\nblocker: explicit subscriptions in js-waku tests\n\nchore(rln-relay): Requirements to consider RLN ready (non experimental) {E:3.1: DoS requirements and design}\n\nachieved: waku rln is not an experimental feature anymore, and is part of nwaku code base. from now on experimental features are hidden behind a flag and not in different build\n\nchore: do not advertise multiaddr with port 0 {bug}\n\nachieved: tested two different solutions: updating the port with an addressMapper, and not allowing the user to use port 0. Analyzed and discussed technical implications of both solutions. Initially followed decision to proceed with 2nd solution for now, with intention of implementing the first solution in the future.\n\nOpened a draft PR and updated tests for the solution of not allowing the user to choose port 0.\n\n\nnext: after further feedback received today, we have to complete the discussion of how to move forward and either review and proceed with current PR, or plan and implement solution that updates all the data structures consistently across the node\n\nfeat: HTTP REST API: Filter support v2 {E:REST API service node}\n\nachieved: Filter v1 &amp; v2 REST API endpoints merged to master\nnext: LightPush REST endpoint\n\nchore: update resolved enr ip when using dns4-domain-name flag {enhancement}\n\nachieved: implemented solution that does DNS IP resolution during node bringup when no external IP is found but a DNS address is provided.\n\nValidated and tested “happy paths” of the solution, raised draft PR and got feedback about the solution\n\n\nnext: discuss and define the system’s behavior on errors, implement error handling and adding tests for this feature.\n\n\njs-waku §\nMaintenance {E:2023-qa}\n\nachieved: added logs, investigated issues reported\nnext: approach reported issues, add preventative measures\n\nCover Several Environments As Part of Testing {test}, {E:2023-qa}\n\nachieved: got reviews on playwrights tests\nnext: maybe add bounty, check Karma testing\n\n\ngo-waku §\nfeat: discovery &amp; peer management for static shards {E:1.4: Sharded peer management and discovery}\n\nachieved:  Update WakuPeerStore to store pubSubTopics for a peer.\nnext:  Sharded Peer Management considering static sharding for Status communities.\n\nRLN enabled by default {E:3.2: Basic DoS protection in production}\n\nachieved: isReady verif in /health endpoint,  make RLN available in service nodes and library usage by default, update docs and docker image, use zerokit 0.3.4, allow running service node with no RLN credentials\nnext:  bandwidth validation, subcommand to list credentials\n\nMaintenance {E:2023-qa}\n\nachieved: CommonService for embedding lifecycle operation in lightpush,discv5,filter,peerConnector etc.\nnext: after discussion with richard prem, use create 2 different types of commonService. Change nameServer flag functionality in go-waku to nwaku. And work on newly created tasks.\n\nImprove Test Coverage {test}\n\nachieved: replace golint by revive, and add make lint-full target to run linting with many more rules enabled\n\n"},"waku/updates/2023-09-25":{"title":"2023-09-25 Waku weekly","links":[],"tags":["waku-updates"],"content":"nwaku §\nfeat: RLN support for Nwaku-Compose {E:3.2: Basic DoS protection in production}\n\nachieved: added RLN flags run_node.sh (including the optional ones), added RLN related environment variables to docker-compose.yml, added RLN metrics’ visualizations to Grafana and updated the README to account for the new changes. Improved implementation based on feedback.\nnext: test the use of optional parameters, get feedback for new version, and merge as soon as all the comments get addressed\n\nchore: bump vendor dependencies for 0.21.0 {dependencies}\n\nachieved: Bumped all dependencies and prepared to 0.21.0. We will start doing this regularly after each release.\n\nfeat: HTTP REST API: lightpush  {E:REST API service node}\n\nachieved: Lightpush REST API endpoint merged to master\nnext: Admin REST endpoint, extended health endpoint, Full swagger doc of nwaku rest API interface\n\nfeat: Service peer selection on specific shards {E:1.4: Sharded peer management and discovery}\n\nachieved: peer manager can filter peer by shard, filter discv5 bootstrap nodes by shard, external APIs moved out of node folder\nnext: refactor APIs handlers to discover peers if none is found in peer manager with the required capability\n\nfeat: Autosharding API for (relay) subscriptions {E:1.2: Autosharding for autoscaling}\n\nachieved: fixed js-waku nwaku interop test\nblocker: js-waku PR not merged\n\nchore: update resolved enr ip when using dns4-domain-name flag {enhancement}\n\nachieved: added error handling and tests, received new feedback and addressed the comments\nnext: get the new version reviewed and merge if approved\n\nchore: update resolved enr ip when using dns4-domain-name flag {enhancement}\n\nachieved: implemented solution that does DNS IP resolution during node bringup when no external IP is found but a DNS address is provided.\nValidated and tested “happy paths” of the solution, raised draft PR and got feedback about the solution\nnext: discuss and define the system’s behavior on errors, implement error handling and adding tests for this feature.\n\nnwaku c-bindings (NodeJS + Python) {E:NodeJS Library}\n\nachieved: Use of ‘ThreadSignalPtr’ instead of loop to handle req/resp.\nhttps://github.com/waku-org/nwaku/pull/2045\nnext:  Avoid the use of global variables, to enhance the thread-safeness ( see https://github.com/waku-org/nwaku/pull/1865#discussion_r1282722954 )\n\n\njs-waku §\nPeer Exchange is supported and used by default {E:2.1: Production testing of existing protocols}\n\nachieved: The Peer Exchange Epic is now completed &amp; closed\n\nCover Several Environments As Part of Testing {test}, {E:Comprehensive dev testing}\n\nachieved: improved karma testing, added testing in browser\n\n\ngo-waku §\nfeat: discovery &amp; peer management for static shards {E:1.4: Sharded peer management and discovery}\n\nachieved: handle dynamic topic sub/unsub and update peerMetadata.\nnext: relay peer mgmt for static/auto sharding\n\nfeat: Autosharding API for req-resp protocols {E:1.2: Autosharding for autoscaling}\n\nachieved: Completed Filter API and lightClient changes for autosharding\n\nAdd postgresql to the unit tests {test}\n\nachieved: Add test for store query creation functionality, and change store test to use postgres. Add tests for postgres module.\n\n"},"waku/updates/2023-10-02":{"title":"2023-10-03 Waku Weekly","links":[],"tags":["waku-updates"],"content":"waku-rust-bindings §\nfeat: filterv2 support {E:RLN non-native SDKs}\n\n\nachieved: added support for unsubscribe, ping and unsubscribe_all filterv2 functions of go-waku c-bindings\n\n\nnext: add support to subscribe\n\n\n\nnwaku §\nfeat: Implement /admin Rest Api endpoint\n\n\nachieved:\n\n\nnext: /admin rest endpoint feature is on PR review will be merged next week. Restructure openapi descriptions and producing swagger ui like live document of all rest interfaces.\n\n\nblocking: There are two build issues. libwaku cannot build on Fedora (RedHat) distros. Second, Abhi reported a build issue with wakunode2 - nim compiler crash under some circumstances.\n\n\nfeat: RLN support for Nwaku-Compose {E:3.2: Basic DoS protection in production}\n\n\nachieved: finished addressing feedback\n\n\nnext: task is blocked until there’s an easier method for users to register RLN credentials\n\n\nfeat: Service peer selection on specific shards {E:1.4: Sharded peer management and discovery}\n\n\nachieved: newly refactored STORE REST API handler that trigger discv5 peer search when needed.\n\n\nnext: refactor other APIs\n\n\nPostgreSQL {E:2.1: Production testing of existing protocols}, {E:PostgreSQL}\n\n\nachieved:\n\n\nBetter dburl parse that accepts host names with dashes and dots.\n\n\nProperly set the compilation flag -d:postgres so Docker images are compiled with support to Postgres (with libpq5 dependency.)\n\n\nDuring the stress testing, I discovered that the max throughput seems not to be directly related to Postgres. If I make the code to ignore Postgres and return immediately a mocked response, then the throughput is even lower.\n\n\nnext: Carry on with “select” performance analysis and analyze it directly from a Store client, rather than having REST &lt;-&gt; Store_Client &lt;-&gt; Store_Server. By ignoring the REST layer we will have a better insight into the actual Store protocol, as @jm-clius recommended to me some time ago.\n\n\nchore: add retention policy with GB or MB limitation {enhancement}, {E:PostgreSQL}\nAdded the new retention policy based on DB size.\nUsers can provide the size such as &lt;size_number&gt;&lt;case_insenstive_gb_or_mb&gt; ex. 30gb (which is also the default)\n--store-message-retention-policy=size:25GB\n--store-message-retention-policy=size:25gb\n--store-message-retention-policy=size:250MB\n--store-message-retention-policy=size:250mb\nTest case also added.\nOutdated messages/rows are deleted to suffice the size limit, with 20% size reduction upon overflowing.\nchore: update resolved enr ip when using dns4-domain-name flag {enhancement}\n\n\nachieved: addressed feedback and merged\n\n\nchore: improve test coverage on NetConfig generation\n\n\nachieved: developed the new NetConfig test suite, raised PR, received and implemented feedback and merged.\n\n\nnwaku c-bindings (NodeJS + Python) {E:NodeJS Library}\n\n\nachieved:\n\n\nAdded a simple cpp example to the main code. https://github.com/waku-org/nwaku/pull/2079.\n\n\nSubmitted a PR where we start showing the doability of a Rust integration with the libwaku.\n\n\nThis PR is currently introducing the thread-safety enhancement of avoiding using global variables. Ideally, this should be in a separate PR. https://github.com/waku-org/nwaku/pull/2089.\nNotice that it was important to invest time in the Rust example so that we can carry on with the “callback” technique to exchange information between the host code (any) and the foreign code (Nim.)\n\n\nnext: Separate the PR mentioned above and submit another one which only avoids using global variables but doesn’t add the wip-Rust integration.\n\n\n\njs-waku §\nStatic Sharding {E:Static sharding}\n\n\nachieved: allowing for multiple pubsub topics to be configured &amp; refactoring protocols to support\n\n\nnext: enabling peer management to only dial relevant shards\n\n\n\ngo-waku §\nrefactor: add user_data to c-bindings {E:RLN non-native SDKs}\n\n\nachieved: updated all the functions to include an additional void* user_data parameter\n\n\nfeat: discovery &amp; peer management for static shards {E:1.4: Sharded peer management and discovery}\n\n\nachieved: basic relay peer mgmt for static/auto sharding\n\n\nfeat: Service peer selection on specific shards {E:1.4: Sharded peer management and discovery}\n\n\nachieved: Peer selection updated to be based on pubsubTopic or contentTopic\n\n\nnext: Update lightClient API to consider new peerSelection options\n\n\nfeat: Autosharding API for req-resp protocols {E:1.2: Autosharding for autoscaling}\n\n\nachieved: Updated lightpush API for autosharding\n\n\n\nEcoDev §\nOctober 2023\n\nETHSafari bound and was mostly travelling last week\n"},"waku/updates/2023-10-09":{"title":"2023-10-09 Waku Weekly","links":[],"tags":["waku-updates"],"content":"\nnwaku §\nfeat: Implement /admin Rest Api endpoint {E:REST API service node}\n\nachieved: /admin Rest API endpoint implemented\nnext: Restructure openapi descriptions and producing swagger ui like live document of all rest interfaces. Restructure Rest API schema types.\n\nchore: notify user if docker-compose fails {enhancement}, {E:3.2: Basic DoS protection in production}\n\nachieved: discussed the issue with colleagues, implemented the solution and closed the issue\n\nfeat: allowing users to choose port 0 for dynamically allocated ports {enhancement}\n\nachieved: analyzed code and found the different data structures affected by the dynamic port allocation. Considered the implications of different approaches to solve the issue, discussed and translated the different options into code.\nStarted the implementation of the chosen solution, with part of the solution already working.\nnext: complete the first working version of the solution, improve its design/architecture, and test.\n\nfeat: Service peer selection on specific shards {E:1.4: Sharded peer management and discovery}\n\nachieved: Filter, Store, Light push REST APIs discovery handler (a rework of the previous solution)\n\nsetting up static sharding fleet for Status {E:Static sharding}\n\nachieved: fleet has been deployed, PostgreSQL setup has been tested.\nnext: Do some basic dogfooding with Status Desktop.\n\nPostgreSQL {E:2.1: Production testing of existing protocols}, {E:PostgreSQL}\n\nachieved: Applied performance comparison between SQLite and Postgres but in this case, making direct requests from a  go-waku unittest that @richard-ramos had prepared.\nAfter directly comparing the Store protocol, noticed that the bottle neck is within the database itself. i.e. the SQLite database performs better than Postgres, given that we have a very simple schema and simple queries, without joins. Adding indexes to the Postgres database didn’t help very much. For example, given the same query, SQLite takes 1ms whereas Postgres takes 6ms.\nnext:\n\nWrap up the Store testing environment and install it into our sandbox machine, metal-01.he-eu-hel1.wakudev.misc.statusim.net, so that anyone can proceed from this point (two databases with the same dataset of ~2 million rows .) in case someone is keen on analyzing performance or debug in a more realistic testing scenery. This will include concurrent queries from multiple nodes, where PostgreSQL is expected to perform better.\nStart extracting the database creation and indexes creation to outside the code base.\n\n\n\nchore: add retention policy with GB or MB limitation {enhancement}, {E:PostgreSQL}\nIn review: the database bug to delete limited messages/rows\nUpcoming/working: updated retention policy + test + missing tes on timestamp based retention policy\nUndergoing: MUID concept on message level\nfeat: provide a way to define advertised addresses {enhancement}\n\nachieved: went over the code and found the root cause of the issue and a preliminary solution\nnext: finish discussing the approach to the solution and implement it\n\n\njs-waku §\nStatic Sharding {E:Static sharding}\n\nachieved: PR open for allowing peer management for multiple pubsub topics/shard\nnext: getting reviews &amp; releasing\n\nPeer Management: Connection and Disconnection {track:restricted-run}, {E:2.1: Production testing of existing protocols}\n\nachieved: investigated &amp; closed #1412\nnext: look into addressing deliberate vs accidental disconnections\n\n\ngo-waku §\n\nTeam attended EthRome\n"},"waku/updates/2023-10-16":{"title":"2023-10-16 Waku weekly","links":[],"tags":["waku-updates"],"content":"nwaku §\nchore: Reorganize RestApi specs for live documentation {E:REST API service node}\n\nachieved: Http RestAPI interface is in parity with json-rpc with even more features supported on it.\nnext: Openapi specification is reorganized and online doc generated out of it. Currently under PR review.\nFollow up spec reorganization with rest api type reorganization. RFC changes to enhance lighpust failure response.\n\nfeat: allowing users to choose port 0 for dynamically allocated ports {enhancement}\n\nachieved: had over code review sessions and got feedback. Implemented improvements, attempted new approaches, fixed bugs. Most of the solution is already implemented and working.\nnext: fix failed tests, add test cases and raise PR\n\nfeat: experimental incentivize store protocol {E:Basic service incentivization}\n\nachieved: wrote the first draft of incentivization outline\nnext: discuss open question, continue structuring the document\n\nsetting up static sharding fleet for Status {E:Static sharding}\n\nachieved: setup a separate shard for community points of contact, and another one for 1:1/group messages\nnext: investigate/fix discv5 not working when static sharding is being used.\n\nPostgreSQL {E:2.1: Production testing of existing protocols}, {E:PostgreSQL}\n\nachieved:\n\nTesting environment prepared in metal-01.he-eu-hel1.wakudev.misc.statusim.net. There are two databases (Postgres and SQLite) with 5 million of random messages.\nEnhanced Grafana dashboard so that we can compare timings performance throughout an histogram.\n\n\nnext: Carry on with the investigation to enhance the Postgres performance.\n\nfeat: provide a way to define advertised addresses {enhancement}\n\nachieved: implemented solution and raised PR\nnext: get feedback, implement suggested improvements and close\n\nnwaku c-bindings (NodeJS + Python) {E:NodeJS Library}\n\nachieved:\n\nSeparate PR to avoid global variables: https://github.com/waku-org/nwaku/pull/2118\nStarted to document the tasks tackled so far: https://www.notion.so/NWaku-cbindings-FFI-7a9ae6240cfc4caba7c7ff0bf3429a70\n\n\nnext: Start creating a separate NodeJs and Python repositories, where we will create nodejs-waku and py-waku, respectively.\n\n\njs-waku §\nPeer Management: Connection and Disconnection {E:2.1: Production testing of existing protocols}\n\nachieved: reached a conclusion tackling deliberate vs accidental disconnections, PRs opened to handle Filter subscriptions on disconnection/reconnections, iterative fixes on addressing multiple dial attempts for same peer, fixes around keep alive pings\nnext: getting reviews &amp; merging these PRs which should enable us to close this epic 🥳\n\n\ngo-waku §\nfeat: Service peer selection on specific shards {E:1.4: Sharded peer management and discovery}\n\nachieved:  refactor and migrate peer selection to peer manager and update lightclient API to use new options\nnext: on-demand discovery if peers are not available for the shard\n\nAdd postgresql to the unit tests {test}\n\nachieved: Completed. Fixed only sqlite being used for creating queries.\n"},"waku/updates/2023-10-23":{"title":"2023-10-23 Waku weekly","links":[],"tags":["waku-updates"],"content":"2023-10-23 Waku weekly §\nWaku Network Can Support 10K Users §\n\nachieved:\n\nVac/DST team has done further runs with up to 600 nodes in the network as part of wrapping up a blog post report.\nStaging fleet for Status with static sharding and PostgreSQL deployed and being tested by go-waku team using local changes in Status Desktop.\n\n\nnext:\n\nDogfooding of Status Desktop with Status staging fleet. Will aim to create a small internal Waku community.\nContinue integration of static sharding in status-go.\n\n\nrisks:\n\nDependency on Vac/DST to conclude ~1k nodes simulations.\nPostgreSQL implementation has not yet been proven more performant than SQLite. Further improvements and testing in progress.\nImplementation of static sharding in Status Communities and design decisions mostly driven by go-waku developer, with minimal input from Status dev (1, 2, 3). See status-go#4057 for remaining work. Mitigation by on-boarding Chat SDK lead on 6 Nov to drive effort.\n\n\n\nTargeted dogfooding for Status Communities §\n\nachieved: hardcoded bootnodes ENRs in addition to DNS Discovery URLs as a way to overcome nameserver issues. Use a static shard instead of the default pubsub topic. Update tool to crawl and discover nodes via discv5.\nnext:  fix if necessary strange behavior with discv5 when ENRs in DNS discovery URL do not contain shards. Document steps for dogfooding.\n\nWaku Network can Support 1 Million Users - 2023-11-30 §\n\nachieved: See 10k milestone update for PostgreSQL status.\nrisks:\n\nDependency on Vac/DST to run 10k nodes simulations.  Tracked under\nvac:dst:eng-10ktool.\nWakutorsis tool is being dropped, meaning new tooling needs to be developed for 10k nodes simulations. It is currently uncertain whether such tool can be developed.\nLarge scale simulations done by Vac/DST only covered nwaku relay. go-waku, status-go simulations are not planned short term (theoretical review of Status Communities messages is), nor are simulations including request-response protocols such as store and filter.\n\n\n\nWaku Network Gen 0 - 2023-12-01 §\n\nachieved:\n\nCritical path work for autosharding done in nwaku, in progress on go-waku\nParameters for the Waku Network Gen 0 have been captured in an RFC and use as a basis for simulations and theoretical analysis, removing uncertainty on this milestone around message rates, performance and expected bandwidth usage.\n\n\nrisks:\n\nUsage of RLN in js-waku and dependency on a (centralized?) Web3Provider remains unclear as one needs to know the merkle tree state (on chain) to generate proofs.\nWe are progressively moving a nwaku engineer to a solution engineer role we need to backfill the role.\njs-waku team is juggling between dev ex and gen 0 with only 2 engineers (3rd one joining at end of Oct) so delivery in this client is likely to lag behind other clients.\n\n\n\n3.2: Basic DoS protection in production §\n[js-waku] Task: Manage RLN membership(s) and keys\n\nachieved: completed flow up items and main stream of work;\n\n[js-waku-examples] feat: re-create rln-js\n\nachieved: experimented with different frameworks, almost complete rewriting the example;\n\n[research] Message propagation times with waku-rln\n\nachieved: Ran simulations with 1000 nwaku nodes with rln enabled, with the goal of measuring message propagation delays under different conditions.\nnext: Some issues with the current simulations, need to investigate shadow tool to simulate CPU “time passing”. Some results are not valid.\n\n2.1: Production testing of existing protocols §\n[js-waku] chore: improve logging when fails to connect to a node\n\nachieved: setup a Logger for more verbose and modular error readbility\n\n[js-waku] Peer Management: Connection and Disconnection\n\nachieved: The Connection and Disconnection Peer Management epic has been closed\n\n[waku-rust-bindings] feat: filterv2 support\n\nachieved: added support to waku_filter_subscribe\nnext: write unit tests for filterv2 and publish new version\n\nQuality Assurance processes are in place - 2024-03-31 §\nThis work is tracked with vac:dst:software-testingwaku\nSupport Many Platforms - 2024-04-30 §\nShip RLN as part of non-native SDKs §\n[go-waku] refactor: add user_data to c-bindings\n\nachieved: exposed filterv2 subscription details (useful for rust bindings)\n\nREST API service node §\n[nwaku] chore: reorganize rest-api types\n\nachieved: Enhancements on Rest request error handling.\nnext: Finalize api spec and doc after PR review. Work in progress: rest api type reorganization. RFC changes to enhance light-push failure response.\nblocking: Fixing found issues during release.\n\n[go-waku] feat: lightpush REST API\n\nachieved: Add lightpush rest api and test. Rest Filter v2 in progress.\n\nOther Work §\nEnhancements §\n[nwaku] feat: allowing users to choose port 0 for dynamically allocated ports\n\nachieved: fixed failed tests, added a test case to cover the changes, small refactor and raised PR\nnext: get PR reviewed and implement feedback\n\n[nwaku] feat: provide a way to define advertised addresses\n\nachieved: merged PR with initial fix. Implemented and raised PR for the --ext-multiaddr-only CLI flag\nnext: get PR reviewed, implement feedback and merge\n\nBugs §\n[nwaku] bug: WSS enabled node stops accepting websocket connections after some time\n\nachieved: discovered and debuged WSS issue, discovered and debugged REST API causing SIGSEGV, oversaw release v0.21.0\nnext: help with release v0.21.1, investigate existing bandwidth management work\n\nEcosystem Development - Docs §\n\nachieved:\n\ngot familiar with what The Graph is doing with Waku, @waku/sdk update in @waku/react\nPreparation to Polygon Enugu\nPeer management disconnection docs\n\n\nnext:\n\nWork on metrics dashboard\nRecord some explainer videos\nDocs redesign\nOutline for encryption docs\n\n\n"},"waku/updates/2023-10-30":{"title":"2023-10-30 Waku weekly","links":[],"tags":["waku-updates"],"content":"2023-10-30 Waku weekly §\nWaku Network Can Support 10K Users §\n\nIntegration of static sharding in go-waku is continuing (see updates below).\nTesting of PostgreSQL enabled some performance improvement in the implementation that are being implemented.\nInternal instructions have been distributed to dogfood static sharding with the Waku team (Waku Discord private channel).\nrisks:\n\nDependency on Vac/DST to conclude ~1k nodes simulations.\nImplementation of static sharding in Status Communities and design decisions mostly driven by go-waku developer, with minimal input from Status dev (1, 2, 3). See status-go#4057 for remaining work. Mitigation by on-boarding Chat SDK lead on 6 Nov to drive effort.\n\n\n\nTargeted dogfooding for Status Communities §\n\nachieved: unsuccesfully tried to avoid introducing a breaking change in status-go. We need to decide whether to go ahead and merge that PR\nblocker: discv5 filters out outdated ENR entries from DNS Discovery URL in shard fleet -  https://github.com/waku-org/nwaku/issues/2162\n\nWaku Network can Support 1 Million Users - 2023-11-30 §\n\nachieved:\n\nSee 10k milestone update for PostgreSQL status.\nFirst version of the 10k-tool by DST is ready and is being tested with simulation running a small nim-libp2p/gossipsub binary.\n\n\nrisks:\n\nDependency on Vac/DST to run 10k nodes simulations.  Tracked under\nvac:dst:eng-10ktool.\nWakutorsis tool is being dropped, meaning new tooling needs to be developed for 10k nodes simulations. It is currently uncertain whether such tool can be developed.\nLarge scale simulations done by Vac/DST only covered nwaku relay. go-waku, status-go simulations are not planned short term (theoretical review of Status Communities messages is), nor are simulations including request-response protocols such as store and filter.\n\n\n\nPostgreSQL in service node: Further optimisations §\n[nwaku] PostgreSQL\n\nachieved:\n\nTime processing enhancement when performing SELECT operations. There was an overhead caused by looping too many times over the returned rows, in order to convert the row types. By applying a “rowCallback” approach we can reduce by 30ms the time spent on the query under analysis.\n\n\nnext:\n\nThe queries used in the comparison analysis still perform much better in SQLite (&lt; ~5ms) than in Postgres (&lt; ~15ms.) Therefore we need to push the investigation further to enhance that.\n\n\n\nWaku Network Gen 0 - 2023-12-01 §\n\nachieved:\n\nFurther simulation done, with a continued focus on message propagation time and possible improvements.\nProgress across all client son sharded peer management discovery\nFirst PRs merged towards basic distributed store services\n\n\nrisks:\n\nUsage of RLN in js-waku and dependency on a (centralized?) Web3Provider remains unclear as one needs to know the merkle tree state (on chain) to generate proofs.\nWe are progressively moving a nwaku engineer to a solution engineer role we need to backfill the role.\njs-waku team is juggling between dev ex and gen 0 with only 2 engineers (3rd one just joined) so delivery in this client is likely to lag behind other clients.\n\n\n\n3.2: Basic DoS protection in production §\n[nwaku] feat: add rln to waku simulator instance\n\nachieved: learnt about waku-simulator’s inner workings and got the background required to integrate RLN to it. Added service that generates traffic to the nodes via their REST APIs. Investigated and tested different ways of approaching the RLN integration.\nnext: get RLN to work and add Grafana dashboards with RLN data\n\n[js-waku-examples] feat: re-create rln-js\n\nachieved: addressed flaws in integration, completed rewriting;\n\n[research] Tuning GossipSub’s D parameter in Waku\n\nachieved: nwaku simulations showing the impact in message propagation delay when reducing gossipsub’s D value. Main goal is to reduce bandwidth consumption in exchange of worsen propagation delay.\nnext: asses if we want to move forward changing D.\n\n[research] Message propagation times with waku-rln\n\nachieved: Final simulation results with 1000 nwaku nodes with rln enabled, with the goal of measuring message propagation delays under different conditions (amount of nodes and message size).\nnext: NA\n\n1.4: Sharded peer management and discovery §\n[nwaku] feat: Service peer selection on specific shards\n\nachieved: REST APIs discovery handlers PR merged\n\n[nwaku] feat: Peer management with shard as a dimension\n\nachieved: Waku Metadata shard subscriptions, Sharded relay peer management, draft sharded peer store pruning\nnext: finalize sharded peer store pruning &amp; run simulations\n\n[go-waku] feat: Deprecate Named Sharding and Update Lightpush Client API\n\nachieved: Create PR for review for removing of Named Pubsubtopic.\n\n[go-waku] feat: Service peer selection on specific shards\n\nachieved:  draft PR #834 opened for on-demand peer discovery\nnext: use on-demand peer discovery for service and relay peer selection\n\n2.3: Basic distributed Store services §\n[nwaku] feat: add new message_hash column to the archive protocol\n\nachieved: On SQLite’s schema transition (i.e. this PR) to messageHash feature complete PR posted (awaiting reviews), Gained insight into the connection and interplay between the store and archive components, and how they may be leveraged into making a sync protocol. Small stuff - bug fix on the jsWaku which was this PR dependent (that too was time-consuming since my first time interacting with JS code of waku), PR on vacuum on time-based retention policy, thought through the nitty gritty details of node based roles and incentives.\nnext:\n\nThe sync protocol formulation totally based on the messages sync without any external factors into POV\nReview PostgreSQL PRs by Ivan to gain more knowledge on the storage/archive feature.\n\n\n\n2.1: Production testing of existing protocols §\n[nwaku] PostgreSQL\n\nachieved:\n\nTime processing enhancement when performing SELECT operations. There was an overhead caused by looping too many times over the returned rows, in order to convert the row types. By applying a “rowCallback” approach we can reduce by 30ms the time spent on the query under analysis.\n\n\nnext:\n\nThe queries used in the comparison analysis still perform much better in SQLite (&lt; ~5ms) than in Postgres (&lt; ~15ms.) Therefore we need to push the investigation further to enhance that.\n\n\n\n[waku-rust-bindings] feat: filterv2 support\n\nachieved: fix issues found during testing\nnext: publish new version\n\nQuality Assurance processes are in place - 2024-03-31 §\nSupport Many Platforms - 2024-04-30 §\nPresentation Readiness  §\n[js-waku] feat: better support for development\n\nachieved: experimented with Next.js app;\nnext: looking for ways to mitigate errors in console or catch others;\n\nShip RLN as part of non-native SDKs §\n[go-waku] refactor: add user_data to c-bindings\n\nachieved: fixed issues found during tests with waku-rust-bindings\n\nREST API service node §\n[go-waku] feat: admin REST API\n\nachieved:  Implemented Admin REST API and updated the spec.\n\nEcosystem Development §\n\n\nachieved:\n\nnew tictactoe example with @waku/react\nProgress on Devconnect planning\nOrganising dev ex calls\nShipping resources for hackathon\nReviewed Graphcast proposal for using relay\n\n\n\nnext:\n\nipfs/waku example for file transfer\nWaku tutorial videos\n@waku/react hacker pain-point feedback report\nMetrics dashboard\nETHLisbon\n\n\n"},"waku/updates/2023-11-06":{"title":"2023-11-06 Waku weekly","links":[],"tags":["waku-updates"],"content":"2023-11-06 Waku weekly §\nWaku Network Can Support 10K Users §\n\nachieved:\n\nfurther PostgreSQL optimisations nearing conclusion\nimplemented bridge to allow Status Community to move to static sharding with backwards compatibility towards default pubsub topic\nsolution for shared bootstrap nodes being filtered out in discv5 as more static shards are activated\nensured no unknown blockers from Waku’s side to start dogfooding in conversation with Status Communities\n\n\nnext:\n\ncontinue integration of static sharding in status-go.\ndeploy bridge for backwards compatibility\ndogfooding of Status Desktop with Status staging fleet. Will aim to create a small internal Waku community\n\n\nrisks:\n\nDependency on Vac/DST to conclude ~1k nodes simulations.\nImplementation of static sharding in Status Communities and design decisions mostly driven by go-waku developer, with minimal input from Status dev (1, 2, 3). See status-go#4057 for remaining work. Mitigation by on-boarding Chat SDK lead on 6 Nov to drive effort.\nlack of confidence in simulation results: results so far exhibits various artifacts and anomalies seemingly related to tooling limitations. It is therefore difficult to draw certain conclusions re Waku scalability.\nlack of clarity in terms of Status fleet ownership, monitoring and maintenance, which is an integral part of the solution.\n\n\n\nTargeted dogfooding for Status Communities §\n\nachieved: fix in status-go to use correct unprotected pubsub topic for community point of contacts, added pubsub topic bridge feature to go-waku, stop filtering out bootnodes on discovery, minimize noise on logs when selecting peers and not having peers available.\nnext: deploy bridge between default pubsub topic and shard 32\n\nWaku Network can Support 1 Million Users - 2023-11-30 §\n\nachieved:\n\nSee 10k milestone update for PostgreSQL status.\nFirst version of the 10k-tool by DST is ready and is being tested with simulation running a small nim-libp2p/gossipsub binary.\n\n\nrisks:\n\nDependency on Vac/DST to run 10k nodes simulations.  Tracked under\nvac:dst:eng-10ktool.\nWakutorsis tool is being dropped, meaning new tooling needs to be developed for 10k nodes simulations. It is currently uncertain whether such tool can be developed.\nLarge scale simulations done by Vac/DST only covered nwaku relay. go-waku, status-go simulations are not planned short term (theoretical review of Status Communities messages is), nor are simulations including request-response protocols such as store and filter.\nlack of real world feedback/dogfooding: the complete static sharding solution involves significant changes to the Waku protocol and tech stack. Although each element is unit tested, dogfooding may hit corner cases in the integrated solution that cannot be foreseen/recreated in lab conditions.\n\n\n\nPostgreSQL in service node: Further optimisations §\n[nwaku] PostgreSQL\n\nachieved: Optimize select/Store queries by adding prepared statements. PR\nnext: Wrap up the Postgres optimizations. Summarize the performance comparison in a report.\n\nWaku Network Gen 0 - 2023-12-01 §\n\nachieved:\n\nStarting internal dogfooding of Waku Network: We have launched the proto-network and it is already possible to run a node in said network.\n\n\nrisks:\n\nUsage of RLN in js-waku and dependency on a (centralized?) Web3Provider remains unclear as one needs to know the merkle tree state (on chain) to generate proofs.\nWe are progressively moving a nwaku engineer to a solution engineer role we need to backfill the role.\njs-waku team is juggling between dev ex and gen 0 with only 2 engineers (3rd one just joined) so delivery in this client is likely to lag behind other clients.\nUncertainty as to how RLN membership mechanism would hinder application adoption, if memberships need to be distributed or obtained by registration, if staking is necessary to prevent abuse, etc.\n\n\n\n3.2: Basic DoS protection in production §\n[nwaku] feat: add rln to waku simulator instance\n\nachieved: integrated RLN, added Grafana dashboards, tested, merged and deployed\n\n1.4: Sharded peer management and discovery §\n[go-waku] feat: Service peer selection on specific shards\n\nachieved:  on-demand peer discovery for service peer selection and new relay shard subscriptions\n\n2.3: Basic distributed Store services §\n[nwaku] feat: add new message_hash column to the archive protocol\n\nachieved: PR to support SQLite code to support messageHash attribute without interrupting the existing cursor-related functionality, id field stays for now. Skelton for sync in progress.\nnext:\n\nfinalize the SQLite messageHash attribute and add a research page about it.\nstart a research page about the sync mechanism for nWaku, doing request/reply a PoC on the same.\n\n\n\nQuality Assurance processes are in place - 2024-03-31 §\nSupport Many Platforms - 2024-04-30 §\nPresentation Readiness  §\n[js-waku] feat: better support for development\n\nachieved: by going through basic flow identified errors that can or cannot be ignored;\nnext: working on improving log errors, aiming to complete in couple of days;\n\nOther Work §\nEnhancements §\n[js-waku-examples] feat: make light-js example a proper debugging tool\n\nachieved: added peer dropdown, list of connected peers, and button for querying past messages using store\nnext: will take on my first issue in js-waku\n\nBugs §\n[js-rln] bug: proof is not verified\n\nachieved: as per suggestion investigated if the roots are correct, seems found a fix;\n\nDocumentation §\n[docs.waku.org] Advanced docs for js-waku\n\nachieved: added createSubscription() docs in #128\nnext: tackle @waku/sdk deprecated namespace #131, create filter management docs\n\n[docs.waku.org] Node operator doc - cloud and advanced options\n\nachieved: updated nwaku config options in #128, added nwaku published MA option in #130\n\nChores §\n[nwaku] chore: bump vendor dependencies for 0.22.0\n\nachieved: updated dependencies, resolved conflicts, tested and raised PR\nnext: get PR reviewed, implement feedback and merge\n\nEcosystem Development §\n\n\nachieved:\n\nMultiple leads from ETHLisbon.\nSync call with The Graph.\njs-waku prioritizing.\nCreated Hackathon project with Waku at ETHLisbon.\nAwesome-waku updates.\n\n\n\nnext:\n\nReview RLN docs readiness for launch at DevConnect.\nWeb3privacy event preparation.\nWaku network soft-launch organisation.\nCreating tutorial videos.\nETHStaker gathering for gaining some awareness about node operator onboarding.\n\n\n"},"waku/updates/2023-11-13":{"title":"2023-11-13 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Waku Network Can Support 10K Users §\n\nachieved:\n\nfinal PostgreSQL optimisations completed. Benchmarks published: https://www.notion.so/Postgres-e33d8e64fa204c4b9dcb1514baf9c582\nadded “debug nodes” with trace-level message logging to each Status fleet to allow for easier e2e message traceability\nconfirmed no unknown blockers from Waku’s side to continue dogfooding in conversation with Status Communities\n\n\nnext:\n\ncontinue integration of static sharding in status-go.\ndogfooding of Status Desktop with Status staging fleet. Will aim to create a small internal Waku community\n\n\nrisks:\n\nDependency on Vac/DST to conclude ~1k nodes simulations.\nImplementation of static sharding in Status Communities and design decisions mostly driven by go-waku developer, with minimal input from Status dev (1, 2, 3). See status-go#4057 for remaining work. Mitigation by on-boarding Chat SDK lead on 6 Nov to drive effort.\nlack of confidence in simulation results: results so far exhibits various artifacts and anomalies seemingly related to tooling limitations. It is therefore difficult to draw certain conclusions re Waku scalability.\nlack of clarity in terms of Status fleet ownership, monitoring and maintenance, which is an integral part of the solution.\n\n\n\nTargeted dogfooding for Status Communities §\n\n\nachieved: deployed bridge between default pubsub topic and shard 32, added UseShardAsDefaultTopic node config option to indicate whether the client should use a shard or the default waku topic. Merged open status-go PRs related to sharding. Initial connection to peers + dns-discovery no longer blocks the login. Updated open status-desktop PR for dogfooding to take into account status-go latest sharding related changes.\n\n\nnext: get https://github.com/status-im/status-desktop/pull/12344 merged.\n\n\nWaku Network can Support 1 Million Users - 2023-11-30 §\n\nachieved:\n\nBasic Postgresql optimizations completed and benchmarks published. See 10k milestone.\nFirst version of the 10k-tool by DST is ready and is being tested with simulation running a small nim-libp2p/gossipsub binary.\n\n\nrisks:\n\nDependency on Vac/DST to run 10k nodes simulations. Tracked under vac:dst:eng-10ktool.\nWakutorsis tool is being dropped, meaning new tooling needs to be developed for 10k nodes simulations. It is currently uncertain whether such tool can be developed.\nLarge scale simulations done by Vac/DST only covered nwaku relay. go-waku, status-go simulations are not planned short term (theoretical review of Status Communities messages is), nor are simulations including request-response protocols such as store and filter.\nlack of real world feedback/dogfooding: the complete static sharding solution involves significant changes to the Waku protocol and tech stack. Although each element is unit tested, dogfooding may hit corner cases in the integrated solution that cannot be foreseen/recreated in lab conditions.\n\n\n\nWaku Network Gen 0 - 2023-12-01 §\n\nachieved:\n\nStarted internal dogfooding of proto-network and started to work on documentation.\nProgressed on capability and sharding discovery.\n\n\nrisks:\n\nUsage of RLN in js-waku and dependency on a (centralized?) Web3Provider remains unclear as one needs to know the merkle tree state (on chain) to generate proofs.\nWe are progressively moving a nwaku engineer to a solution engineer role we need to backfill the role.\njs-waku team is juggling between dev ex and gen 0 with only 2 engineers (3rd one just joined) so delivery in this client is likely to lag behind other clients.\nUncertainty as to how RLN membership mechanism would hinder application adoption, if memberships need to be distributed or obtained by registration, if staking is necessary to prevent abuse, etc.\n\n\n\n3.2: Basic DoS protection in production §\n[go-waku] bug: handle errors generated in gm.rootTracker.UpdateLatestRoot(pair.Key.(uint64))\n\nachieved: task complete\n\n1.5: Launch and dogfood integrated public Waku Network MVP §\n\nachieved:\n\nLaunched team-internal CC dogfooding with nwaku nodes and RLN Sepolia contract\nIntroduced landing page and tutorials to join the network and publish using nwaku-compose\n\n\nnext:\n\nSoft launch of the network at Devconnect Istanbul\nExtend dogfooding to other clients (js-waku, go-waku)\n\n\n\n1.4: Sharded peer management and discovery §\n[nwaku] feat: Peer management with shard as a dimension\n\nachieved: discv5 filter peer by capability, misc. improvement w.r.t sharding and tests, sharded peer management improvement\nnext: run more simulations\n\n[go-waku] feat(discv5): filter peer by capability\n\nachieved: added capacility in discv5 to filter out peers that do not have waku2 ENR field\n\n1.2: Autosharding for autoscaling §\n[go-waku] feat: Changes to Store protocol APIs for Autosharding\n\nachieved: API updates for autosharding\nachieved: added functions for validating content topic, determining shard index and pubsub topic for autosharding\nnext: configure js-waku node to use either static or auto sharding\nblocker: need my PRs approved/merged. Also best to merge in other open PRs, especially https://github.com/waku-org/js-waku/pull/1697\n\nOther Work §\nEnhancements §\n[nwaku] chore: allow text/plain contentType for rest request’s body types\n\nnext: Allow text/plain contentType on RestApi is on PR, libwaku Fedora build issue\n\n[nwaku] chore: decouple listen and announced addresses\n\nachieved: implemented, tested and raised PR\nnext: get PR reviewed, implement feedback and merge\n\n[waku-rust-bindings] Peer discovery &amp; management \n\nachieved: Worked mainly on rust-waku-bindings issues for go-waku.\nnext: Handle epic 2.2\n\n[go-waku] chore: # chore: remove --store-message-db-vacuum\n\nachieved: removed VACUUM functionality from go-waku, since it’s an operation that must be done by infra instead of being part of go-waku\n\nDocumentation §\n[docs.waku.org] Encryption documentation\n\nnext: begin work on encryption docs\n\n[docs.waku.org] Advanced docs for js-waku\n\nachieved: filter management docs\nnext: deprecated namespace docs #131\n\nChores §\n[nwaku] chore: bump vendor dependencies for 0.22.0\n\nachieved: finished and merged\n\nEcosystem Development §\n\nachieved: SpiffWorkflow x Waku sync\nnext: metrics, web3privacy meetup, DCxPrague talk\n"},"waku/updates/2023-11-20":{"title":"2023-11-20 Waku Weekly","links":[],"tags":["waku-updates"],"content":"2023-11-20 Waku weekly §\nWaku Network Can Support 10K Users §\n\nachieved:\n\nclosed last PostgreSQL issue for Store scalability\nconfirmed no unknown blockers from Waku’s side to continue dogfooding in conversation with Status Communities\nstarted team-internal dogfooding of a test community using static sharding\nstarted fleet ownership handover process: published guidelines/list of responsibilities - https://www.notion.so/Fleet-Ownership-7532aad8896d46599abac3c274189741\n\n\nnext:\n\ncontinue dogfooding of Status Desktop with Status staging fleet with test community\ntraining session to conclude fleet ownership handover: https://www.notion.so/Fleet-Ownership-7532aad8896d46599abac3c274189741\n\n\nrisks:\n\nDependency on Vac/DST to conclude ~1k nodes simulations.\nImplementation of static sharding in Status Communities and design decisions mostly driven by go-waku developer, with minimal input from Status dev (1, 2, 3). See status-go#4057 for remaining work. Mitigation by on-boarding Chat SDK lead on 6 Nov to drive effort.\nlack of confidence in simulation results: results so far exhibits various artifacts and anomalies seemingly related to tooling limitations. It is therefore difficult to draw certain conclusions re Waku scalability.\nlack of clarity in terms of Status fleet ownership, monitoring and maintenance, which is an integral part of the solution.\n\n\n\nTargeted dogfooding for Status Communities §\n\nachieved: logout / login freeze, fix request on correct pubsub topic, and add missing shard information on community  invite\nnext: dogfooding\n\nWaku Network can Support 1 Million Users - 2023-11-30 §\n\nachieved:\n\nClosed last Postgresql issue for basic Store scalability. See 10k milestone.\nAssisted DST in setting up initial tests with the ~1K tool. Currently still fine-tuning parameters, ensuring results are consistent, etc. for smaller configurations.\n\n\nrisks:\n\nDependency on Vac/DST to run 10k nodes simulations.  Tracked under\nvac:dst:eng-10ktool.\nWakutorsis tool is being dropped, meaning new tooling needs to be developed for 10k nodes simulations. It is currently uncertain whether such tool can be developed.\nLarge scale simulations done by Vac/DST only covered nwaku relay. go-waku, status-go simulations are not planned short term (theoretical review of Status Communities messages is), nor are simulations including request-response protocols such as store and filter.\nlack of real world feedback/dogfooding: the complete static sharding solution involves significant changes to the Waku protocol and tech stack. Although each element is unit tested, dogfooding may hit corner cases in the integrated solution that cannot be foreseen/recreated in lab conditions.\n\n\n\nWaku Network Gen 0 - 2023-12-01 §\n\nachieved:\n\nInternal dogfooding of proto-network continues.\nSignificant progress of autosharding in js-waku: autosharding function implemented, work to integrate in protocols started.\n\n\nrisks:\n\nUsage of RLN in js-waku and dependency on a (centralized?) Web3Provider remains unclear as one needs to know the merkle tree state (on chain) to generate proofs.\nWe are progressively moving a nwaku engineer to a solution engineer role we need to backfill the role.\njs-waku team is juggling between dev ex and gen 0 with only 2 engineers (3rd one just joined) so delivery in this client is likely to lag behind other clients.\nUncertainty as to how RLN membership mechanism would hinder application adoption, if memberships need to be distributed or obtained by registration, if staking is necessary to prevent abuse, etc.\n\n\n\n1.4: Sharded peer management and discovery §\n[nwaku] chore: improve cluster id, shards, topics flow\n\nachieved: Various tests updates and fixes.\nnext: Figure out why CI passes locally only.\n\n1.2: Autosharding for autoscaling §\n[nwaku] chore: allow fetching cached messages by content or pubsub topic\n\nachieved: failed refactor of message cache\nnext: a better and simpler message cache\n\n[js-waku] feat: Autosharding API for req-resp protocols\n\nachieved: derive pubsub topic from content topic in encoders/decoders when autosharding is specified\nnext: node config should specify static sharding or autosharding. implement autosharded topics in all req-resp protocols\n\nSupport Many Platforms - 2024-04-30 §\nPresentation Readiness  §\n[js-waku] feat: node connection state\n\nachieved: modified ConnectionManager to track connection state. exposed through read function and new event\nnext: resolve any remaining feedback\n\nOther Work §\nEnhancements §\n[nwaku] chore(REST): adding to /admin/v1/peers response lightpush and filter v2 peer info\n\nachieved: implemented, tested and raised PR\nnext: get PR reviewed, implement feedback and merge\n\n[nwaku] chore: allow text/plain contentType for rest request’s body types\n\nachieved: Better support for js-waku using RestApi: Allow text/plain contentType\nnext: Bandwidth management preparation\n\n[nwaku] chore: decouple listen and announced addresses\n\nachieved: got the PR reviewed, implemented feedback and merged\n\nEcosystem Development §\n\nachieved:\n\nPresented two talks last week. Logos + Waku at Web3Privacy meetup and RLN at DCxPrague.\nEthGlobal Istanbul - 20 projects submitted and contributed with production and mentorship\nsecured talks and presented at Libp2p day and EthGlobal\nrepresented Waku in pragma booth\nHelped organise Status-wide meetup during DevConnect\n\n\nnext:\n\npublish tic-tac-toe blog post\nmigrate examples from personal repository to examples repository and take responsibility of examples repo\nedit and send video tutorials for review for comms\nwrite event proposal for co-hosting LibP2P day in EthIndia along with Protocol Labs during the Waku hacker house\nEthIndia production works (finding venue, vendors for swag and booth)\nprocess and deliver devconnect feedback\nhelp draft devconnect winner promotions\nonboard the devconnect winners to Waku discord to Hackathon-winners channel\nprepare event report of Devconnect with help from Lou\nprepare KPI document for Eth India with help from Lou\n\n\n"},"waku/updates/2023-11-27":{"title":"2023-11-27 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Waku Network Can Support 10K Users §\n\n\nachieved:\n\nconfirmed no unknown blockers from Waku’s side to continue dogfooding in conversation with Status Communities\ncontinuing team-internal dogfooding of a test community using static sharding https://github.com/waku-org/pm/issues/97. See dogfooding report\nfleet ownership training: held session for stakeholders on responsibilities - https://www.notion.so/Fleet-Ownership-7532aad8896d46599abac3c274189741\n\n\n\nnext:\n\ncontinue dogfooding of Status Desktop with Status staging fleet with test community (https://github.com/waku-org/pm/issues/97)\nfix issue of store fleet not connecting to bootstrap fleet due to enr shards mismatch https://github.com/status-im/infra-shards/issues/23\n\n\n\nrisks:\n\nFleet Ownership doc defines fleet maintainer and owner. Status team yet to clarify who is the fleet owner for Status Communities.\nQA by Status team to be planned on staging static sharding fleet; Waku team has done internal dogfooding (report). Any change to the staging static sharding fleet should then be tested by QA before being deployed to prod (e.g. # of Postgres instances). Status has committed to this testing on 28Nov call.\nStatus team expressed will to deploy static sharding prod fleet and use it for all users: This is not recommended until proper QA is done on stagning static sharding fleet as it could impact other Status app activities.\nImplementation of static sharding in Status Communities and design decisions mostly driven by go-waku developer, with minimal input from Status dev (1, 2, 3). See status-go#4057 for remaining work. Mitigation by on-boarding Chat SDK team since November 2023 to drive effort.\nDependency on Vac/DST to conclude ~1k nodes simulations; lack of confidence in simulation results: results so far exhibits various artifacts and anomalies seemingly related to tooling limitations. It is therefore difficult to draw certain conclusions re Waku scalability.\n\n\n\nTargeted dogfooding for Status Communities §\n\nachieved: fix issue of using default clusterID as 16 for shards fleet, dogfooding of status-desktop with shards fleet, debug issues in connection to fleet. See dogfooding report\nnext: continue dogfooding\nachieved: fix pubsub topic used for store queries, logic for finding free port when initializing torrent service, add back changes related to default shard that were reverted before, store clusterID in app database, refactor mailserver cycle to not require having an active connection to a store node\nnext: dogfooding\n\nWaku Network can Support 1 Million Users - 2023-11-30 §\n\nnext: Pending DST simulations of 10k nodes gossipsub network.\nrisks:\n\n\nDependency on Vac/DST to run 10k nodes simulations. Tracked under vac:dst:eng-10ktool.\n\n\nWakutorsis tool is being dropped, meaning new tooling needs to be developed for 10k nodes simulations. It is currently uncertain whether such tool can be developed.\n\n\nLarge scale simulations done by Vac/DST only covered nwaku relay. go-waku, status-go simulations are not planned short term (theoretical review of Status Communities messages is), nor are simulations including request-response protocols such as store and filter.\n\n\nlack of real world feedback/dogfooding: the complete static sharding solution involves significant changes to the Waku protocol and tech stack. Although each element is unit tested, dogfooding may hit corner cases in the integrated solution that cannot be foreseen/recreated in lab conditions.\n\n\n\n\nWaku Network Gen 0 - 2023-12-01 §\n\nachieved:\n\nInternal dogfooding of proto-network continues.\njs-waku work continues.\nnwaku optimization around peer management are underway.\n\n\nrisks:\n\nUsage of RLN in js-waku and dependency on a (centralized?) Web3Provider remains unclear as one needs to know the merkle tree state (on chain) to generate proofs.\nWe are progressively moving a nwaku engineer to a solution engineer role we need to backfill the role.\njs-waku team is juggling between dev ex and gen 0 with only 2 engineers (3rd one just joined) so delivery in this client is likely to lag behind other clients.\nUncertainty as to how RLN membership mechanism would hinder application adoption, if memberships need to be distributed or obtained by registration, if staking is necessary to prevent abuse, etc. Tracked with #102\n\n\n\n4.1: Basic front end for node operator §\n\nachieved: follow ups and reduction of FE image;\nnext: double check with cors solved, minor improvements and fixes\n\n1.5: Launch and dogfood integrated public Waku Network MVP §\n\nachieved: come up with go-waku-compose to run a go-waku node in order to dogfood the public waku network\nnext: fix issues in go-waku-compose to support secure websockets and auto-fetch public IP\n\n1.4: Sharded peer management and discovery §\n[nwaku] chore: add sharding information to peer storage\n\nachieved: merged and closed\n\n[nwaku] chore: add sharding information to peer storage\n\nachieved: updated peer storage to include ENR\nnext: review feedback cycle\n\n[js-waku] feat: Deprecate Named Sharding and Update Lightpush Client API\n\nachieved: PR ready and currently in review-iteration phase ( #1697 )\nnext: to be merged\n\n[js-waku] feat: add new metadata protocol\n\nnext: unblock this issue by merging #1697\n\n1.2: Autosharding for autoscaling §\n[nwaku] chore: allow fetching cached messages by content or pubsub topic\n\nachieved: PR merged DONE!\n\n2.1: Production testing of existing protocols §\n[nwaku] feat: Migrate deployments to PostgreSQL\n\nachieved: Preparing environment to stress one single database with multiple Postgres clients writing and reading simultaneously.\nnext: Extend Postgres benchmarking report from previous results and start analyzing the performance of status.test fleet where three nodes will use one single database.\n\nPresentation Readiness  §\n[js-waku] feat: filter subscription API\n\nachieved: PR opened and currently under review-iteration phase ( #1725 )\nnext: merge PR\n\nOther Work §\nEnhancements §\n[nwaku] chore(REST): adding to /admin/v1/peers response lightpush and filter v2 peer info\n\nachieved: merged PR and closed issue\n\n[js-noise] feat: allow parameterization of handshakes\n\nachieved: implemented parameterization of DH, Cypher and Hash\n\nBugs §\n[nwaku] bug: incomplete data sent or received log appearing when WSS is enabled\n\nachieved: attempted reproducing, haven’t gotten it to happen yet\nnext: succeed reproducing and fix\n\n[nwaku] bug: relay publish fails with 400 Bad Request when message contains meta field\n\nachieved: analyzed issue and started implementing fixes\nnext: continue implementing the solution\n\n[nwaku] bug: relay push with malformed timestamp crashes nwaku\n\nachieved: analyzed issue, found and implemented fix, raised PR in nim-json-serialization repo and implemented feedback. Merged fix and opened a PR in nwaku updating the dependency.\nnext: get nwaku PR reviewed y merge\n\n[go-waku] bug: duplicate validator for topic error when trying to re-subscribe to previously unsubscribed topic\n\nachieved: fix relay subscribe API issue causing failure in resubscription to a pubsubtopic, return appropriate errors in relay REST API\n\nDocumentation §\n[docs.waku.org] Advanced docs for js-waku\n\nachieved: published manage filter guide, finished react docs\nnext: ECIES and symmetric encryption/decryption\n\n[docs.waku.org] Docs general improvement/incorporating feedback (2023)\n\nachieved: added light mode toggle, updated the logos preset, added TWN guide, updated docs design and structure\n\nEcosystem Development §\n\n\nachieved:\n\nDocumentation refactor based on feedback\nPreparing react hooks for release\nEthIndia organizing\nWaku hackerhouse organizing\nETHIstanbul winner tweets\n\n\n\nnext:\n\nAnnounce react hooks\nWaku hackerhouse\n\n\n"},"waku/updates/2023-12-04":{"title":"2023-12-04 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Waku Network Can Support 10K Users §\n\nachieved:\n\nconfirmed no unknown blockers from Waku’s side to continue dogfooding in conversation with Status Communities\ncontinuing team-internal dogfooding of a test community using static sharding https://github.com/waku-org/pm/issues/97. See dogfooding report\nfleet ownership training: held session for stakeholders on responsibilities - https://www.notion.so/Fleet-Ownership-7532aad8896d46599abac3c274189741\n\n\nnext:\n\ncontinue dogfooding of Status Desktop with Status staging fleet with test community (https://github.com/waku-org/pm/issues/97)\nfix issue of store fleet not connecting to bootstrap fleet due to enr shards mismatch https://github.com/status-im/infra-shards/issues/23\n\n\nrisks:\n\nFleet Ownership doc defines fleet maintainer and owner. Status team yet to clarify who is the fleet owner for Status Communities.\nQA by Status team to be planned on staging static sharding fleet; Waku team has done internal dogfooding (report). Any change to the staging static sharding fleet should then be tested by QA before being deployed to prod (e.g. # of Postgres instances). Status has committed to this testing on 28Nov call.\nStatus team expressed will to deploy static sharding prod fleet and use it for all users: This is not recommended until proper QA is done on stagning static sharding fleet as it could impact other Status app activities.\nImplementation of static sharding in Status Communities and design decisions mostly driven by go-waku developer, with minimal input from Status dev (1, 2, 3). See status-go#4057 for remaining work. Mitigation by on-boarding Chat SDK team since November 2023 to drive effort.\nDependency on Vac/DST to conclude ~1k nodes simulations; lack of confidence in simulation results: results so far exhibits various artifacts and anomalies seemingly related to tooling limitations. It is therefore difficult to draw certain conclusions re Waku scalability.\n\n\n\nTargeted dogfooding for Status Communities §\n\nachieved: fix issue of using default clusterID as 16 for shards fleet, dogfooding of status-desktop with shards fleet, debug issues in connection to fleet. See dogfooding report\nnext: continue dogfooding\n\nWaku Network can Support 1 Million Users - 2023-11-30 §\n\nnext:\n\nPending DST simulations of 10k nodes gossipsub network.\n\n\nrisks:\n\nDependency on Vac/DST to run 10k nodes simulations. Tracked undervac:dst:eng-10ktool.\nWakutorsis tool is being dropped, meaning new tooling needs to be developed for 10k nodes simulations. It is currently uncertain whether such tool can be developed.\nLarge scale simulations done by Vac/DST only covered nwaku relay. go-waku, status-go simulations are not planned short term (theoretical review of Status Communities messages is), nor are simulations including request-response protocols such as store and filter.\nlack of real world feedback/dogfooding: the complete static sharding solution involves significant changes to the Waku protocol and tech stack. Although each element is unit tested, dogfooding may hit corner cases in the integrated solution that cannot be foreseen/recreated in lab conditions.\n\n\n\nWaku Network Gen 0 - 2023-12-01 §\n\nachieved:\n\nInternal dogfooding of proto-network continues.\njs-waku work continues.\nnwaku optimization around peer management are underway.\n\n\nrisks:\n\nUsage of RLN in js-waku and dependency on a (centralized?) Web3Provider remains unclear as one needs to know the merkle tree state (on chain) to generate proofs.\nWe are progressively moving a nwaku engineer to a solution engineer role we need to backfill the role.\njs-waku team is juggling between dev ex and gen 0 with only 2 engineers (3rd one just joined) so delivery in this client is likely to lag behind other clients.\nUncertainty as to how RLN membership mechanism would hinder application adoption, if memberships need to be distributed or obtained by registration, if staking is necessary to prevent abuse, etc. Tracked with #102\n\n\n\n4.1: Basic front end for node operator §\n[nwaku] bug: access-control-allow-origin should be set to localhost\n\nachieved: understood and applied initial fixes, tested, found bug and got it to work\nnext: add tests for changes in presto, raise PRs in both presto and nwaku\n\n1.4: Sharded peer management and discovery §\n[nwaku] feat: Peer management with shard as a dimension\n\nachieved: sharded peer management final version in review\nnext: review feedback\n\n1.2: Autosharding for autoscaling §\n[nwaku] chore: allow fetching cached messages by content or pubsub topic\n\nachieved: PR merged DONE!\n\n[js-waku] feat: Autosharding API for req-resp protocols\n\nachieved: config node for static/autosharding, test all protocols against autosharding RPC endpoints on nwaku\nnext: config application and version on node creation, only discover nodes of same shard\n\n[js-waku] (https://github.com/waku-org/js-waku/issues/1500)\n\nachieved: all protocols can be configured to use autosharding for determining pubsub topics\nnext: make autosharding the default behavior when running js-waku\n\nOther Work §\nEnhancements §\n[go-waku] feat: use current timestamp when not provided in relay rest api\n\nachieved: return error in relay API when message gossipsub threshold is crossed, fill messageTimestamp if RLN is enalbed and not set in WakuMessage, improve errors returned for filter unsubscribe APIs\n\nBugs §\n[nwaku] bug: incomplete data sent or received log appearing when WSS is enabled\n\nachieved: reproduced it, did superficial checks but couldn’t get deep enough to find the root cause\nnext: continue investigating\n\n[go-waku-compose] fix: automatic fetching of public ip not working\n\nachieved: made go-waku-compose ready to run go-waku node to support the public waku network\n\nDocumentation §\n[go-waku] doc: best practice to handle disconnection when sending messages over relay\n\nachieved: provided a short-term approach to address message send/receive issues during disconnections, intiated discussions in nimbus and vac channels to find out possible approaches being used in other protocols using gossipsub\n\nEcosystem Development §\n\nachieved:\n\nReviewed upcoming Waku press release\nCreated new bounties: 1, 2\nReviewed expectations for EthIndia and the Waku Network\n\n\n\nChat SDK §\nchat-sdk-tracking\n\nachieved: Running custom built desktop with status-go, working on community store node\nnext: continue working on community store node\nblocker: no so far\n\nProject Management §\n\nachieved:\n\nOpen discussion around project management, milestones and expectations from Logos Program.\nEnsure critical work for Status app is tracked and planned: 1, 2\nVarious hiring activies: BD, Growth lead and how to handle js-libp2p maintenance\nReview Status plans around testing static sharding and ensure potential risks are understood.\nFind a spot to host studies and simulation output as part of our commitment to build in the open and awarness of potential deplatforming: [1, Waku Discord]\nDrafting updated PM tracking proposal\n\n\nnext:\n\nResume discussion around Nim usage and multiple clients in Waku: 1\nReview 2023 achievements and start planning 2024 milestones.\nShare proposal doc to Waku cc’s for review\n2024 Research milestone tracking\n\n\n\nBasic Dev Rel Assets\n\nachieved: Lead conversion process and community engagement process docs completed\n"},"waku/updates/2023-12-11":{"title":"2023-12-11 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Waku Network Can Support 10K Users §\n\nachieved:\n\nfixed issue of store fleet not connecting to bootstrap fleet due to enr shards mismatch https://github.com/status-im/infra-shards/issues/23\ncontinuing team-internal dogfooding of a test community using static sharding https://github.com/waku-org/pm/issues/97. See dogfooding report\nbenchmarked various ways for large postgresql deployments: https://github.com/status-im/infra-status/issues/37\n\n\nnext:\n\ncontinue dogfooding of Status Desktop with Status staging fleet with test community (https://github.com/waku-org/pm/issues/97)\n\n\nrisks:\n\nFleet Ownership doc defines fleet maintainer and owner. Status team yet to clarify who is the fleet owner for Status Communities.\nQA by Status team to be planned on staging static sharding fleet; Waku team has done internal dogfooding (report). Any change to the staging static sharding fleet should then be tested by QA before being deployed to prod (e.g. # of Postgres instances). Status has committed to this testing on 28Nov call.\nStatus team expressed will to deploy static sharding prod fleet and use it for all users: This is not recommended until proper QA is done on stagning static sharding fleet as it could impact other Status app activities.\nImplementation of static sharding in Status Communities and design decisions mostly driven by go-waku developer, with minimal input from Status dev (1, 2, 3). See status-go#4057 for remaining work. Mitigation by on-boarding Chat SDK team since November 2023 to drive effort.\nDependency on Vac/DST to conclude ~1k nodes simulations; lack of confidence in simulation results: results so far exhibits various artifacts and anomalies seemingly related to tooling limitations. It is therefore difficult to draw certain conclusions re Waku scalability.\n\n\n\nTargeted dogfooding for Status Communities §\n\nachieved: fix peer manager to take into account the ENR seq to determine if a peer is new or not and fix incorrect number of connected peers per topic. Register lightpush protocol correctly in go-waku. Drop pubsub topic bridging. Use shards.test fleet as default (in status-go and desktop)\nnext: continue dogfooding / fixing issues\n\nWaku Network can Support 1 Million Users - 2023-11-30 §\n\nachieved:\n\nResearched various ways of deploying shared postgresql instances for large deployments: https://github.com/status-im/infra-status/issues/37\n\n\nnext:\n\nPending DST simulations of 10k nodes gossipsub network.\n\n\nrisks:\n\nDependency on Vac/DST to run 10k nodes simulations. Tracked under vac:dst:eng-10ktool.\nWakutorsis tool is being dropped, meaning new tooling needs to be developed for 10k nodes simulations. It is currently uncertain whether such tool can be developed.\nLarge scale simulations done by Vac/DST only covered nwaku relay. go-waku, status-go simulations are not planned short term (theoretical review of Status Communities messages is), nor are simulations including request-response protocols such as store and filter.\nlack of real world feedback/dogfooding: the complete static sharding solution involves significant changes to the Waku protocol and tech stack. Although each element is unit tested, dogfooding may hit corner cases in the integrated solution that cannot be foreseen/recreated in lab conditions.\n\n\n\nWaku Network Gen 0 - 2023-12-01 §\n1.4: Sharded peer management and discovery §\n[nwaku] feat: Peer management with shard as a dimension\n\nachieved: sharded peer management and store pruning PR merged\n\n1.2: Autosharding for autoscaling §\n[js-waku] feat: make autosharding default node behavior\n\nachieved: open PR to reintroduce (but deprecate) name sharding alongside auto/static sharding without breaking APIs\nnext: update all examples to use autosharding\nblocker: need review on https://github.com/waku-org/js-waku/pull/1723\n\nSupport Many Platforms - 2024-04-30 §\nREST API service node §\n[docs.waku.org] REST API/ NodeJS\n\nachieved: added references for the REST API\n\nOther Work §\nResearch §\n[research] Onchain RLN tree+root: Proof Of Concept\n\nachieved: We present a proof of concept change in the RLN contract to store the whole membership tree on-chain + its Merkle root. This lowers sync time from several minutes to a few seconds, but at a cost of x10 the membership insertion cost. It also makes light clients lighter since proof verification becomes stateless (Merkle root can be accessed onchain, without having to sync the tree). We also present go-waku-light, to showcase the newly introduced features and how they are meant to be used.\n\nEnhancements §\n[nwaku] chore: avoid blocking the whole waku node when retention policy is being applied\n\nachieved: avoid blocking the whole waku node when the retention policy is being applied\n\nDocumentation §\n[docs.waku.org] Encryption documentation\n\nachieved: push initial draft for symmetric, ECIES, message signing\nnext: merge and deploy encryption docs #145\n\n[docs.waku.org] Docs general improvement/incorporating feedback (2023)\n\nachieved: add RN warning, add certbot instructions, improve nwaku-compose guide\n\nChores §\n[nwaku] Bump vendor dependencies for release 0.23.0\n\nachieved: bumped nim-dnsdisc dependencies\nnext: bump nim-waku dependencies\n\nEco Dev §\n\nachieved: 51 projects submitted at EthIndia hackathon\n"},"waku/updates/2023-12-18":{"title":"2023-12-18 Waku weekly","links":[],"tags":["waku-updates"],"content":"2023-12-18 Waku weekly §\nTargeted dogfooding for Status Communities §\n\nachieved: fix panic on logout, publish messages async, fix loading message history for communities, fix invalid bootnodes being used on status desktop, status dogfooding, raise issues and optimizations needed wrt light protocols usage in status-go and improvements to be done in nwaku,\nnext: continue dogfooding / fixing issues\n\nSupport Many Platforms - 2024-04-30 §\nPresentation Readiness  §\n[js-waku] feat: filter subscription API\n\nachieved: rebasing\nnext: error handling via event emitter as well. plan if restructuring is required.\n\nOther Work §\nEnhancements §\n[nwaku] feat: Have additional Admin REST API endpoints that helps node operator in monitoring\n\nachieved: improved logging and merged. Created locally a new REST endpoint that returns the information of all the filter subscriptions on a service node\nnext: add unit tests, update documentation and open PR\n\n[research] Sync store baseline understanding\n\nachieved: PoC of Prolly Tree (fixing a Bug), insertion and deletion of data into it.\nnext: a writeup about Prolly trees PoC in issue, further testing, generating some operational data details such as memory consumption using RLN specs.\n\nBugs §\n[nwaku] bug/regression: Relay connection works no more\n\nachieved: reproduced the issue both in testing framework and with local nodes, analyzed logs and narrowed down to the commit where things got broken\nnext: continue investigating, find root cause and fix\n\n[nwaku] bug: no messages returned from store node when multiple content topics and start/end time are used\n\nachieved: bug fix store service in nim-waku when the query used more than one content topic\n\nDocumentation §\n[docs.waku.org] Document how to use k-anonymity with content topic\n\nachieved: add content topic buckets consideration #153\n\nChores §\n[nwaku] Bump vendor dependencies for release 0.23.0\n\nachieved: bump all nim-waku vendor dependencies\n"},"waku/updates/2023-12-25":{"title":"2023-12-25 Waku weekly","links":[],"tags":["waku-updates"],"content":"Happy Holidays!\n1.3: Node bandwidth management mechanism §\n\nachieved: make configurable the max message size in nim-waku https://github.com/waku-org/nwaku/pull/2298\n\n1.2: Autosharding for autoscaling §\n[js-waku] feat: make autosharding default node behavior\n\nachieved: merged PR that implements autosharding after feedback. PR to reintroduce named sharding ready for review\nnext: update all examples to use autosharding\n\nOther Work §\nChat SDK §\n[chat-sdk] chat-sdk tracking\n\nachieved: close connections for filter light client, draft a doc about messages on the relay\nnext: work on user cannot join the community bug\n\nResearch §\n[nwaku] feat: experimental incentivize store protocol\n\nachieved: continued discussion on incentivization RFC\nnext: move towards implementation\n\nEnhancements §\n[nwaku] feat: Have additional Admin REST API endpoints that helps node operator in monitoring\n\nachieved: improved initial implementation. Added unit tests, updated documentation, opened and got approved PR.\nnext: verify if there’s other places where the new endpoint should be document before merging\n\n[research] Sync store baseline understanding\n\nachieved: PoC of Prolly Tree feature complete, Postgres retention policy PR, diff protocol ground work started.\nnext: pending technical writeup about Prolly trees PoC in issue, Diff protocol, generating some operational data details such as memory consumption using RLN specs.\n\nBugs §\n[nwaku] bug/regression: Relay connection works no more\n\nachieved: reproduced, investigated, found root causes and fixed\n\n[nwaku] bug: lack of error checking in publish\n\nachieved: reproduced, investigated and started improving error handling\nnext: continue with the implementation\n\nPM §\n\nachieved: proposed Waku strategy draft to team and started discussions\nnext: continue Waku strategy discussion, publish strategy/discuss with Logos leadership, continue drafting Waku roadmap for 2024\n"},"waku/updates/2024-01-08":{"title":"2024-01-08 Waku weekly","links":[],"tags":["waku-updates"],"content":"2024-01-08 Waku weekly §\nWaku Network Can Support 10K Users §\nTargeted dogfooding for Status Communities §\n\nachieved: status-mobile dogfooding, debug and attempt to identify root cause of filter delay issue\nachieved: attempt to identify root cause of filter delay issue, work on upgrading status-go to use Go 1.21 (to use latest go-libp2p), use latest go-waku version and identify missing commits between release and develop branch\nnext: continue dogfooding / fixing issues\n\nWaku Network Gen 0 - 2023-12-01 §\n1.5: Launch and dogfood integrated public Waku Network MVP §\n\nachieved: add new metrics and make go-waku-compose dashboard functional, dogfooding the network with go-waku node\nnext: fix few pending items in dashboard\n\nOther Work §\nEnhancements §\n[nwaku] feat: Have additional Admin REST API endpoints that helps node operator in monitoring\n\nachieved: got feedback about improved error handling. Added it to the code, got a segfault from the testing framework, investigated and found the root cause.\nnext: define how to proceed based on the testing issue and merge the PR\n\n[nwaku] feat: Have additional Admin REST API endpoints that helps node operator in monitoring\n\nachieved: improved initial implementation. Added unit tests, updated documentation, opened and got approved PR.\nnext: verify if there’s other places where the new endpoint should be documented before merging\n\n[waku-rust-bindings] Peer discovery &amp; management \n\nachieved: Added dns discovery parameters to the node config\n\n[research] Sync store baseline understanding\n\nachieved: 1-day work this week due to time off, nim implementation of Prolly trees\nnext: Diff protocol discussion, Sync mechanism on wire query protocol discussion, generating some operational data details such as memory consumption using RLN specs.\n\n[go-waku] feat: parameterizable number of connections per IP\n\nachieved: Maintain parity between nwaku and go-waku clients\n\nBugs §\n[nwaku] bug: sort order ignored in store nodes\n\nachieved: created v0.23.1-rc.0 and deployed in status.test fleet.\nnext: Deploy v0.23.1 to both status.test and status.prod after having the approval from @richard-ramos and @mprakhov\n\n[nwaku] bug: lack of error checking in publish\n\nachieved: fixed compilation errors, got it to work and tested it\nnext: add test cases to the codebase and open PR\n\n[go-waku] bug: filter/v2/subscriptions take a lot of time and even timeout sometimes\n\nachieved:fix panic when static peer is also discovered dynamically, fix ENR Waku field population for Fitler, analyze data races identified\n\n[go-waku] bug: update examples to use autosharding\n\nachieved: update basic_relay example to use static and autosharding\n\nDocumentation §\n[go-waku] bug: update examples to use autosharding\n\nachieved: update basic_relay example to use static and autosharding\n\n[go-waku] chore: create docs for setting up a systemd service and exit codes\n\nachieved: Added systemd template and docs\nnext: Add env variables suggested by infra\n\nPM §\n[pm] Waku Research - Post Gen 0 Milestones and Epics\n\nachieved: Significantly refined milestones and epics and started getting feedback from stakeholders\nnext: Further stakeholder engagement. Define work needed to improve RFC process.\n\nChores §\n[nwaku] Bump vendor dependencies for release 0.24.0\n\nachieved: bump dependencies to prepare the v0.24.0.\n"},"waku/updates/2024-01-22":{"title":"2024-01-22 Waku weekly","links":[],"tags":["waku-updates"],"content":"Waku Update §\n\nCurrently the Waku team is focused on completing the remaining critical TWN Generation 0 Milestone Epics, the Status Integration, and various bug fixes and enhancements.\nWaku’s development is divided among 5 teams: nwaku, go-waku, js-waku, chat-sdk, and ecosystem-development.\n2024 Milestones and Epics are currently being structured, kickoffs slated begin first week of February.\nThe go-waku  and chat-sdk teams were at the Status integration Doha offsite January 13 - 21.\n\nWaku Network Gen 0 §\nOpen Epics\n\nAutosharding for autoscaling | js-waku | critical | 66%\nNode bandwidth management mechanism | nwaku | not critical | 0%\nSharded peer management and discovery | js-waku | critical | 87%\nLaunch and dogfood integrated public Waku Network MVP | nwaku | critical | 0%\nProduction testing of existing protocols | js-waku &amp; nwaku | critical | 40%\nSharded capability discovery for light protocols | js-waku &amp; go-waku | critical | 0%\nBasic DoS protection in production | go-waku &amp; research | critical | 28%\nBasic front end for node operator | js-waku &amp; nwaku | critical | 83%\n\nJanuary 22 Update §\nnwaku §\nTWN Connectivity\nPrepare release 0.24.0\n\nachieved: big picture solutions for TWN connectivity problem , coordinate nwaku v0.24 release candidate\nnext: Nwaku v0.24.0 test and release, autosharding/cluster-id error handling, moar connectivity research\n\nbug: restart loop of current master\n\nachieved: investigated, found the root cause and solution. Afterwards, got requested a change in logging, implemented it and raised PR.\nnext: get confirmation that the change in logging meets Infra’s needs and get the PR reviewed and merged\n\nfeat: REST API - large messages does not seem to be rejected by relay auto api\n\nachieved: developed and tested an initial working implementation\nnext: after talking to Franck, will implement it differently with a more generalized message verification logic\n\nchore: improve POST /relay/v1/auto/messages/{topic} error handling\n\nachieved: fix compilation errors, open PR, implement feedback and merge\n\nbug: incomplete data sent or received log appearing when WSS is enabled\n\nachieved: investigated code, ran private images with logs on nim-libp2p and analyzed results. Talked to nim-libp2p team to further understand where the failure happens\nnext: investigate further with the new understanding after talking with nim-libp2p team\n\nchore: review waku-simulator deployment and improve tracking processes\n\nachieved: found that simulator’s nwaku image wasn’t getting updated with latest master. Requested Infra for the fix and verified afterwards that it’s working properly\nnext: talk with stakeholders to see what metrics/logs we should keep track of and how\n\nbug: Filter doesn’t receive messages after subscribing and restarting\n\n_achieved:_ investigated and fixed cause of failing test\n\nchore: Refactor of FilterV2 subscription management with Time-to-live maintenance\n\nachieved: Filter V2 subscription management reworked: new Time-to-live tracking, configurable limits of peers served and suvbscriptions per peer. Subscription per request is raised from 30 to 100 (hardcoded)\n\nbug: access-control-allow-origin should be set to localhost\n\nachieved: Alignment with Eugen (presto and chronos maintainer) is made upon the solution to be applied on presto rest server class.\nnext: Once new desing is ready and pushed to presto library, we can add the already prepared “allowed origin” matching mechanism that will enable proper CORS header in response to rest request.\n\nfeat: Enforce service specific rate limits\n\nnext: measurement of usage rates of store protocol to be added (also add to grafana dashboard), add configurable limits (query per sec/min)\n\njs-waku §\nchore: upgrade lip2p\nfeat: set cluster ID as optional when specifying shard info\nfeat: Peer management with shard as a dimension\n\nachieved:\n\nupgrade libp2p to 1.X\nimproved how params are handled between consumer-facing and internal functions\nfix failing tests for autosharding peer mgmt\n\n\n\nallow user to pass content topic to createSubscription\nfeat: sdk function to setup autosharding node with application and version\nfeat: determine bootstrap behavior based on sharding type\n\nnext:\n\nallow creating subscriptions with just content topics\nsetup node with just application and version\ndetermine boostrap behavior based on sharding type\n\n\n\nDecouple sharding logic from internal classes to SDK\n\nblockers:\n\nneed review of issue for decoupling sharding logic\n\n\n\nfeat: simplify rln-js\nfeat: simplify API of bootstrapping, connection to MetaMask\nchore: investigate interop test failures\nchore: fix go-waku interop tests\n\nachieved:\n\nSimplified rln-js\nStep 1 to improve API\ninterop tests with nwaku\nidentified problems with go-waku\n\n\n\nUser Pays Own RLN Membership\n\nnext:\n\nnew cred registration example (based on prev examples)\ncontinue with improvements\naction if needed to improve testability with go-waku\nsome bugs found in rln\n\n\n\nfeat!: protocols filter peers per shard\nfeat: SDK for redundant usage of filter/lightpush\n\nachieved:\n\nmerged: sharded peer management\nmerged: redundant peers for lightpush &amp; filter\n\n\n\nfeat: local storage as a discovery layer\nfeat: SDK for redundant usage of filter/lightpush\n\nnext:\n\nIntroducing Local Storage as a discovery layer, handle renewing of faulty redundant peers (TODO 3) on feat: SDK for redundant usage of filter/lightpush\n\n\n\ngo-waku §\nbug: filter delay errors\n\n\nachieved:\n\ninvestigated and identified the root-cause of bug: filter delay errors and provided a solution\nstarted documenting tips/approach to help message loss debug issues for status QA both from status-go and waku perspective Debugging\n\n\n\nnext:\n\ninvestigate and identify root-cause of message loss while using relay ⁠Unable to Receive msgs while us…\nfinish documenting message loss debugging\n\n\n\nbug: filter delay errors\nContact requests are not received without restart\n\n\nachieved:\n\ninvestigation with Jakub and Igor to find out the reason why store request were taking a long time to be retrievedsage reliability issues were present on CI for filter.\ninvestigate and fix Contact requests are not received without restart (some commits were missing in desktop master branch.\nStatus x Waku war room at Doha\n\n\n\nnext:\n\nfix issues reported in ⁠status\n\n\n\neco-dev §\n[BOUNTY] Build dApp of Your Choice Using Waku (Decentralized Communication) and Vue.js\n\nachieved:\n\nthorough review and feedback\n\n\nnext:\n\nfinal review and approval\n\n\n\nadd content topic buckets consideration\n\nachieved:\n\nmerged add content topic buckets consideration on content topic consideration, playing around with Noise encryption\n\n\n\n[Epic] Encryption documentation\n\n\nnext:\n\ncreating an initial draft for Noise docs, go-waku docs migration\n\n\n\nachieved :\n\ncompleted and recorded videos with 2 teams for builder spotlight, positioning call is completed, revised the cheatsheet based on ethindia feedback\n\n\n\nnext :\n\nget the videos reviewed\n\n\n"},"waku/updates/2024-01-29":{"title":"2024-01-29 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Waku Update §\n\n2024 Milestones have been defined, to be structured and prioritized this week, subject to change pending approval from stakeholders.\nRemaining open TWN Gen 0 Milestone items to be priorirized in 2024 Milestones and Epics.\n\nWaku Network Gen 0 §\nOpen Epics\n\nAutosharding for autoscaling | js-waku | critical | 75%\nNode bandwidth management mechanism | nwaku | not critical | 0%\nSharded peer management and discovery | js-waku | critical | 87%\nLaunch and dogfood integrated public Waku Network MVP | nwaku | critical | 0%\nProduction testing of existing protocols | js-waku &amp; nwaku | critical | 40%\nSharded capability discovery for light protocols | js-waku &amp; go-waku | critical | 0%\nBasic DoS protection in production | go-waku &amp; research | critical | 28%\nBasic front end for node operator | js-waku &amp; nwaku | critical | 83%\n\nBlocked : Add implementation of PRESTO middleware.\n\n\n\nJanuary 29 Update §\nWaku’s development is divided among 6 teams: research, nwaku, go-waku, js-waku, chat-sdk, and ecosystem-development.\nResearch §\nrln-proof-witness\nCreate RLN proof without having the whole tree\n\nachieved:\n\nCreate proof of concept where light clients can generate their own rln proofs without having to sync the whole tree.\nDog food above PoC and get feedback\nStart with rln in gossipsub paper\n\n\n\nWaku Research - Post Gen 0 Milestones and Epics\n\nachieved: created outline doc for new Specs/RFC process: https://www.notion.so/Waku-Specs-Process-Improvements-3bca80fe10804aeaa7a184143bdca07d, first designs for new Store protocol, refined effort estimates\nnext: implement new Specs process, create milestone/epic related issues, work on draft Store protocol improvement\n\nTWN Connectivity\n\nachieved: read Meridian paper and wrote how it could be used in TWN, reading on Discv5 topic advert design problems\nnext: discuss with VAC topic experts?\n\nnwaku §\nfeat: Enforce service specific rate limits\n\nachieved: implemented a simple lightpush and store request rate limit with configurable defaults\nnext: prior PR need to finish some more tests\n\nbug: access-control-allow-origin should be set to localhost\n\nblocked: Eugen done a presto PR utilizing new chronos middleware design, added comments due we need some change on it prior able to use it.\n\nfeat: sharded peer management Round 2\n\nachieved: added sharded peer management config flag, feedback\nnext: review &amp; merge\n\nchore: improved error handling when config uses cluster-id and pubsub topics\n\nachieved: improved error handling for cluster and shard config\nnext: review &amp; merge\n\nbug: restart loop of current master\n\nachieved: got feedback for the PR, implemented fix and merged\n\nbug: RLN validator is only added for statically configured pubsub topics\n\nachieved: analyzed issue, implemented a solution, tested and raised PR\nnext: get feedback on the PR, implement it and merge\n\nfeat: REST API - large messages does not seem to be rejected by relay auto api\n\nachieved: investigated how to approach the issue using generalized validators, implemented a solution, tested and raised PR\nnext: get feedback on the PR, implement it and merge\n\ngo-waku §\n\n\nachieved:\n\ndocument tips and how to debug message loss for status team Debugging\nfix updating lastProcessedBlock even if no RLN membership event is present fix: update lastProcessedBlock even if no RLN membership event is present\nfix issue in connectionStatus reporting fix: minor issues in connectionstatus report\ninclude a basic lightClient example chore: example update\nimprove logging chore: set log level for all loggers based on logger passed , https://github.com/waku-org/nwaku/pull/2366\nsupport for multiple peer selection for filter feat: support multiple peer selection for filter client\n\n\n\nnext:\n\ninvestigate message loss in status-mobile ci\ninvestigate if gossipsub scoring can be monitored and reported to app as unhealthy https://github.com/waku-org/go-waku/issues/1017\ndogfooding status desktop and mobile and investigate and support status team for any other message reliability issues\n\n\n\nachieved:\n\nfix: add support to aarch64-linux-android in go-zerokit-rln-arm: fix: add support to aarch64-linux-android\nfix: handle community shard unassignment: fix: handle community shard unassignment and update\n\n\n\nnext:\n\nwork on status/waku integration items\n\n\n\njs-waku §\n\n\nachieved:\n\nsimplified rln-js example;\nreleased part of improvements for User Pays Own RLN Membership\ndone with investigating test\n\n\n\nnext:\n\nnew cred registration example (based on prev examples)\nfinish improvements for rln\nbugs found in rln\nimprove tests (issue tbd)\n\n\n\nachieved:\n\ndecouple sharding params out of core classes Decouple sharding logic from internal classes to SDK\n\n\n\nnext:\n\nallow creating subscriptions with just content topics allow user to pass content topic to createSubscription\n\n\n\nachieved:\n\nlightpush &amp; filter use multiple peers instead of one feat: lightpush &amp; filter send requests to multiple peers\nlocal storage as a discovery layer (in progress)\nfixing interop tests (in progress) fix(tests): append p2p with the multiaddrs from ENR, chore(tests): update max content topics on lightpush from 30 to 100\n\n\n\nnext:\n\nmerge local storage discovery (https://github.com/waku-org/js-waku/pull/1811),\nmoving message-hash into core (https://github.com/waku-org/js-waku/pull/1810),\n\n\n\nEcosystem-development §\nCommunity/Partners §\n\nachieved: Waku Community Space https://twitter.com/Waku_org/status/1750927368644919722\nnext: Logos x HOPR space, 30 days of web3 presentation\n[BOUNTY] Build dApp of Your Choice Using Waku (Decentralized Communication) and Vue.js\nachieved: final reviews, approved\n\nPost by community member bounty hunter: https://x.com/wolz_codelife/status/1751955673603002459?s=20\nwaku-org/bounties\n\n\nachieved: collected and reviewed a few options for Bounty platforms\nnext: create dummy bounties to see how things work\n\nDocs §\nIntegrate benchmark and research into website\n\nachieved: review of linked PR https://github.com/waku-org/docs.waku.org/pull/157\nnext: follow up on integrating spell check into the research and nwaku repos\n[Epic] Encryption documentation\nnext: (still ongoing) initial noise encryption docs\nCreate a FAQ and troubleshooting guide\nnext: starting the technical FAQ drafting\n\nDevRel §\n\nachieved:\n\nbuilder spotlight video with MrFox team\n2 tutorial videos reviewed by comms\nmonthly community twitter space: https://twitter.com/Waku_org/status/1750927368644919722\n\n\nnext:\n\ncomplete all the tutorial videos\nworkshop presentations for ethlatam\nmore builder spotlight videos\ncalls with node operators\n\n\n\nStatus Integration §\nchat-sdk §\n\nachieved: started the conversation with Hanno on permission-less communities\nnext: agree on an approach on permission-less communities.\nachieved: research and draft hash based message query to store node spec\nnext: discuss on the iteration of hash based message query\n"},"waku/updates/2024-02-05":{"title":"2024-02-05 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Waku Update §\n\n2024 Milestone work breakdowns underway. Target date estimates, Epics and sub-tasks to be created following scope sign off.\n\nResearch §\n\nachieved:\n\nscript to benchmark rln\nstarted rln+gossipsub paper, some plots\ntidying TWN Connectivity Research issue\nWaku Sync overview first draft\nstarted implementation of incentivization RFC\nstarting on protobuf codec for eligibility proofs\nfirst draft for new Store protocol that is simpler, more feature-rich and store-sync ready\n\n\nnext:\n\nContinue onchain merkle proofs PoC + paper\nWaku Sync overview finalization and Sync protocol first draft\naddress review comments, refine design of new Store protocol\n\n\nblocked:\n\nMerkle proofs from onchain blocked by this suspected bug in zk-kit\n\n\n\nnwaku §\n\nachieved:\n\nREST endpoint can serve its own messages as well as act as store-client\nadd simple dictionary with known words so that cSpell doesn’t complain\nworked on how to make the tests not to core dump\nstart creating basic py-waku structure that allows to create a py-waku module that can be imported in Python projects.\nstart using nph formatter extension\nPR is under review - covers LightPush and Store request rate limiting\n“bug fix” in README.md\nAdd new panel to show num msgs per shard\napplied all the feedback from the reviews. Changed the validation logic in our codebase so that the same validator runs for all pubsub topics. Applied fixes for autosharding endpoint. Merged PRs, closed issue.\nfixed decoding error when trying to send a message with the new meta field\nadded debug logs in nim-websock dependency and reproduced the issue with them for further investigation\nhelped debug and find root cause of a long-standing failed test for dynamically added pubsub topics\nmerged better error handling when cluster id and shards are used\nmerged sharded peer manager experiment\nmerged vendor bump for version 0.25.0\n\n\nnext:\n\nfinalize demo implementation (demo in terms uses Presto un-released feature) on refactor Waku RestService to utilize middleware approach and solve CORS headers issue.\nprepare Release 0.25.0 release and test it.\nwrap up the py-waku repository and make it clear that it is a PoC and is not going to be continued in short-term.\nwait until the 0.4 version of the nph extension is released and then we perform the actual migration.\nadd metrics and dashboard, update configuration doc\ndebug failed tests\n\n\n\njs-waku §\n\nDecouple sharding logic from internal classes to SDK\nachieved:\n\nSDK functions for creating a subscription to a content topic using a callback or returning a stream\n\n\nnext:\n\nfunction like above but starts a node with default settings as well\n\n\nblocker:\n\nremove requirement to pass a peer ID to above function\n\n\n\ngo-waku §\n\nachieved :\n\nSupport getting peers by shard via PeerExchange\nIdentified some improvements/changes to be done in go-waku based on status use-case to status-go feat: notify app when peer scores for all connected relay peers goes below thresholds &amp; feat: Report shard/pubsubTopic specific connection health/status\nAdded rate limiter option to lightpush\nAdded support for multiple public keys per topic (likely to not get merged due to issues found)\n\n\nnext:\n\nImplement\n\n\n\nChatSDK §\n\nachieved:\n\nClarify the data flow for a community creation when external operator is paid to provide resources\n\n\nnext:\n\ncontinue store rfc reviews, continue analysis of filter unsubscribe issue\ncontinue permissionless communities setup\n\n\n\nEcoDev §\nDocs §\n\nachieved:\n\nspell check has been integrated into the research and nwaku repos\n\n\nnext:\n\nre-review the linked PR and close it\n\n\nblocker:\n\nI’ve been unable to get the noise-js example to pair with another peer\n\n\n\nEcosystem Development §\n\nachieved:\n\nRecorded 2  builder spotlight videos\nAdded faqs\nStarted drafting the optimism grant proposal\nLogos x HOPR space, Web3Privacy, 30 days of web3\n\n\nnext:\n\nTidied up metrics dashboard and host it with help from vaclav/infra\nCreate rln/node setup cheatsheet\nPrepare for ethdenver\nKick off out-of-band node incentivization discussion\n\n\n\nSolutions §\nPrometheus metrics view\n\nachieved:\n\nbasic metrics (num of connectable nodes and avg ping) added to the dashboard\n\n\nnext:\n\nmodify NetworkMonitor to work with The Waku Network\n\n\n\nStatus Integration §\n\nachieved:\n\nInvestigated and found out root-cause for message loss issue identified in status-desktop\nInvestigated and found out root-cause for message loss issue identified in status-mobile CI\nReview status-go usage of Waku to identify improvements/changes\nfixed missing cluster ID in node config\nadded peer count to logs when sending msg via relay\nfixed history sync regardless of using a data plan or wifi\nfix: full nodes will run filter and lightpush\n\n\nnext:\n\nSupport status integration in case of message loss or Waku related issues\nContinue reviewing status-go code from Waku usage perspective of sharding\nContinue working on bug fixes or issues related to status-go x waku integration\n\n\n"},"waku/updates/2024-02-19":{"title":"2024-02-19 Waku Weekly","links":[],"tags":["waku-updates"],"content":"This update covers the two week span between February 5th -19th.\nresearch §\n\nachieved:\n\nCreated a C wrapper API for negentropy and moved it as a submodule into nwaku https://github.com/waku-org/negentropy/pull/2, https://github.com/waku-org/nwaku/pull/2448\nRerun nwaku latency measurements with latest nwaku release + new plots: https://github.com/waku-org/research/pull/86\nDraft for “practical use of rln in gossipsub” paper ready, peer review ongoing.\nfurther work in PoC incentivization https://github.com/waku-org/nwaku/pull/2419\nonboarding and local ethereum chain tools research\nOpened up the discussions of waku as a sovereign chain: https://github.com/waku-org/research/issues/84\nWaku latency simulations in a real environment: https://github.com/waku-org/research/pull/85\nWork on practical usage of rln in gossipsub paper: https://github.com/waku-org/research/pull/82\nBenchmarked rln in different platforms: https://github.com/waku-org/nwaku/pull/2410\nimplemented the first version of a codec for incentivization PoC: https://github.com/waku-org/nwaku/issues/1961\nresearch post tidying, negentropy C++ bindings first draft, https://github.com/waku-org/research/issues/80 https://github.com/waku-org/nwaku/pull/2403\nrefined new Store protocol design based on community input  https://github.com/waku-org/research/issues/81\n\n\nnext:\n\nimprove the C API and integrate into nwaku and test the integration\ncontinue modifications in zk-kit library to allow onchain merkle proofs: https://github.com/privacy-scaling-explorations/zk-kit/pull/162\nPoC implementation and research papers - continued\ndeploy local ethereum chain for waku-simulator https://github.com/waku-org/waku-simulator/issues/17\nResume work on onchain proofs, upstream bug fixed\nAnalyze data + report on latency simulations\ngather feedback, continue PoC implementation; plan working on the academic conference submission (Waku poster)\nnegentropy C++ bindings continues\nmore reviewers and comments, gain consensus, start plan for PoC implementation https://github.com/waku-org/research/issues/81\n\n\n\nnwaku §\n\nachieved:\n\nNwaku Sync protocol bindings improvements https://github.com/waku-org/nwaku/issues/2426\nNwaku Store v3 first draft\nfound fixes for keystore generation error and for running nwaku-compose without keystore. Validated fixes, and merged both PRs. Closed issue https://github.com/waku-org/nwaku-compose/issues/32\ndesigned and started refactor  https://github.com/waku-org/nwaku/issues/2441\nimplemented fix, opened PR, improved the solution after feedback and merged https://github.com/waku-org/nwaku/issues/2406\nimplemented feedback and merged https://github.com/waku-org/nwaku/issues/2214\napply PoC to handle disk through partitions management https://github.com/waku-org/nwaku/issues/1885\nshare knowledge on waku-nodejs-bindings https://github.com/waku-org/nwaku/issues/2420\naccept base64 payloads; make private key optional by generating a random one if not defined; simplified error handling. https://github.com/waku-org/nwaku/issues/2420\npublish and subscribe to waku messages using nwaku, fixed event callback setup. https://github.com/waku-org/waku-rust-bindings/pull/87\nHelped to define the C-bindings milestone https://github.com/waku-org/pm/issues/121\nsimpler ctx mgmt. Param now receiving void* instead of void** https://github.com/waku-org/nwaku/pull/2398\noverview the partition approach  https://github.com/waku-org/nwaku/issues/1885\ndefined part of bindings milestone with emphases in go (for status-go) and rust https://github.com/waku-org/pm/issues/121\nstarted the integration of nwaku with waku-rust-bindings, compiling and doing FFI nwaku succesfully. https://github.com/waku-org/pm/issues/121\nadded support to yamux https://github.com/waku-org/nwaku/issues/2331\nfinished implementation, debugged and fixed failed tests, opened PR https://github.com/waku-org/nwaku/issues/2214\nimplemented solution, opened PR, implemented feedback and merged https://github.com/waku-org/nwaku/issues/2349\ninvestigated, tried to reproduce. Found out that it got unintentionally fixed by a recent PR, closed issue https://github.com/waku-org/nwaku/issues/2371\ngetting introduced to our C-bindings codebase https://github.com/waku-org/pm/issues/121\nPR is under review - covers LightPush and Store request rate limiting next: fix nim-chronos’ TokenBucket wrong replenis. https://github.com/waku-org/nwaku/issues/2032\nRC release done, test has ran, changelog done https://github.com/waku-org/nwaku/issues/2402\n\n\nnext:\n\ncontinue with the refactor https://github.com/waku-org/nwaku/issues/2441\narchive update to fullfill Store v3 requirements https://github.com/waku-org/nwaku/issues/2425\nmanual tests to ensure it works properly  https://github.com/waku-org/nwaku/issues/1885\nexpose additional bindings functions and add function to free alloc memory https://github.com/waku-org/waku-rust-bindings/pull/87\nContinue defining C-binding epics https://github.com/waku-org/pm/issues/121\ntry the “partition table” implementation approach plus “partition truncate”. https://github.com/waku-org/nwaku/issues/1885\nexpose existing nwaku’s bindings functions and test rust-bindings. Investigate packaging nwaku for mobile. https://github.com/waku-org/waku-rust-bindings/pull/87\nlast mile of implementation (demo in terms uses Presto un-released feature) on refactor Waku RestService to utilize middleware approach and solve CORS headers issue. https://github.com/waku-org/nwaku/issues/2223\n\n\nblocker:\n\nPostgres doesn’t provide a native mechanism to limit the maximum stored size. If the partition+truncate approach doesn’t work properly, we will dismiss the “size” retention policy and just keep the “capacity” and “time” for Postgres. https://github.com/waku-org/nwaku/issues/1885\n\n\n\njs-waku §\n\nachieved:\n\nimplemented and merged @waku/local-discovery to store healthy connected peers in the local state, and use these peers to connect with when an application restarts https://github.com/waku-org/js-waku/issues/1463\nreplaced all use of nwaku’s deprecated JSON RPC API with REST API https://github.com/waku-org/js-waku/issues/1826\nadded SDK functions for creating a node and subscription given a peer id and content topic https://github.com/waku-org/js-waku/issues/1764\nmade improvements based on feedback and merged decoupling of sharding logic out of core protocol logic https://github.com/waku-org/js-waku/issues/1808\nfinished SDK function for creating a subscription (with or without a node) using a content topic and peer id next: implement fixes/improvements from review https://github.com/waku-org/js-waku/issues/1764\n\n\nnext:\n\ncycling stored peers with new peers (discover new peers with peer-exchange) to increase decentralisation\norient protocol implementations to be strictly based on the RFCs https://github.com/waku-org/pm/issues/114#issuecomment-1934535353\nmove WakuNode class to SDK with above functions as private class functions\n\n\n\ngo-waku §\n\nachieved:\n\nexecuted a version of bindings with updated dependencies in go-waku for a couple of days to confirm memory leak is gone. https://github.com/waku-org/waku-rust-bindings/issues/86\narrive at approach and implement topic connection health reporting based on sharding https://github.com/waku-org/go-waku/issues/1021\ninitial version of client side for storev3 https://github.com/waku-org/go-waku/pull/1028\n\n\nnext:\n\nrelease a new version of rust bindings\n\n\n\nchat-sdk §\n\nachieved:\n\ndraft the comparison doc about build client with REST API\nattempting to merge: https://github.com/status-im/status-go/pull/4532\ncreating test code for the selection of store nodes in communities: https://github.com/status-im/status-go/issues/4357\n\n\n*next:\n\ncontinue work on the sending messages with cli\nplan next permission-less community tasks\n\n\n\neco-dev §\n\nachieved:\n\nevents page\npresentation for ETHLATAM\nworking on metrics dashboard https://github.com/waku-org/metrics.waku.org/issues/14\ndeployed the research section of the docs https://github.com/waku-org/docs.waku.org/issues/155\nadded the new filter configurations per nwaku 0.25.0 release https://github.com/waku-org/docs.waku.org/pull/158\nSecret Network space\nminor tweak to nwaku metrics https://github.com/waku-org/nwaku/pull/2430\nupdated instructions, added ENV file configuration, recommended docker as the default way to run nodes https://github.com/waku-org/docs.waku.org/issues/154\nsome repo org for waku metrics and restarted supabase https://github.com/waku-org/metrics.waku.org/issues/6\nworkshop and prize descriptions handed over to ethlatam\ncomposing cheatsheets for RLN membership and how to run a node\nnetworkmonitor now supports RLN and thus can be deployed for The Waku Network https://github.com/waku-org/nwaku/pull/2401\ntested and provided a minor fix for py-waku, create new issues for cbindings based on this https://github.com/waku-org/py-waku/pull/1\n\n\nnext:\n\ncomplete metrics dashboard improvements, start drafting protocols comparison blog and send presentations to comms for review\nfinish up the FAQ section for the docs platform  https://github.com/waku-org/docs.waku.org/issues/152\ndeploy the new pages on the docs https://github.com/waku-org/docs.waku.org/pull/166\nreview PR https://github.com/waku-org/research/pull/83 to add cspell to the research repo\nsome ui improvements in the metrics dashboard\ncommunity call agenda for february\nethlatam presentation\nblog post : unbiased comparison of web3 communication protocols\ndeploy new version of NM, add new metrics to internal and public dashboards\n\n\n\nwaku-status-integ §\n\nachieved:\n\ninvestigate contact ack loss issue identified in mobile-CI after filter-manager PR https://github.com/status-im/status-mobile/pull/18769\n\n\nnext:\n\nsupport status integration in case message loss or Waku related issues\n\n\n"},"waku/updates/2024-04-26":{"title":"2024-04-26 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Research Milestones §\nStore Incentivisation\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/17\n\nachieved: discuss incentivization with Akhil\nnext: plan out incentivization PoC (Lightpush instead of Store?)\nblockers: (no longer a blocker) the deadline for the academic paper final version\n\n\n\nRLN in resource-restricted clients\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/18/views/1\n\nachieved: New Merkle tree integration (LazyIMT) integrated https://github.com/alrevuelta/go-waku-light/pull/2 and new version of contract using said tree https://github.com/vacp2p/rln-contract/pull/31 (with Ar. help). PoC ready to get Merkle proofs from the contract using the finally merged https://github.com/privacy-scaling-explorations/zk-kit/pull/162. With this tree, we can assume the increase in gas cost and in exchange we get roots and merkle proofs onchain.\nnext: Continue work in go-waku-light and prepare an end to end PoC to showcase this new feature. Write a report with findings and tradeoffs for future reference.\nblocker: “VacRlnContract” is not compatible with “WakuRlnContract”. This https://github.com/vacp2p/rln-contract/pull/31 should be adapted to work with waku nodes (required for the PoC). Awaiting Vac’s support.\n\n\n\nRLNv2\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/21/views/1\n\nachieved: merged PR to remove go-waku from waku-simulator\nnext: update to RLNv2\nblockers: deployment still not working on wakusim host, but there is an issue for infra to debug and I can continue by using the wakudev host\n\n\n\nStore v3 - Waku Sync\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/20/views/1\n\nStore v3 - message hashes\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/16/views/1\n\nStatus Integration §\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/5/views/2\n\nin-progress:\n\n[nwaku] Add logging of hashes to all nodes\n\n\n\n\n\nEngineering Milestones §\nJSON RPC Deprecation\n\nStatus: Completed\nProject: https://github.com/orgs/waku-org/projects/8/views/1\n\nComposing Waku Protocols to Improve Reliability\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/9/views/1\n\ncompleted:\n\n[js-waku] chore: protocol implementations in @waku/core should be as unopinionated as possible\n\n\nin-progress:\n\n[js-waku] feat: Store reliability\n\n\n\n\n\nOperator Feature Requests\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/13/views/1\n\ncompleted:\n\n[nwaku] chore: detailed json report on /health endpoint\n[nwaku] chore: Extend node isReady with more mature checks and result returned\n\n\n\n\n\nBindings (Rust, NodeJS, Golang)\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/6/views/6\n\nin-progress:\n\n[nwaku] chore: migrate DiscV5 and DNS Discovery from app.nim to waku_node.nim\n\n\nnext:\n\n[nwaku] chore: support setting DiscV5 and DNS-discovery in libwaku\n\n\n\n\n\nNode Bandwidth Management Mechanism\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/11\n\nin-progress:\n\n[js-waku] feat: prefer error code for req-res protocol over exception\n\n\n\n\n\nOther Work §\nBugs §\nIn Progress §\n\n[js-waku] bug: lightPush is not able to keep node connections\n[js-waku] bug: remote peer fault\n[js-waku] bug: filter subscription stops without occasional pings\n[nwaku] bug: wakunode2 systemd unit restarts about 10-15x per day\n[nwaku] bug: SIGSEGV with RLN\n[nwaku] bug: build error on new AMD cpu’s (ubuntu 22.04 LTS)\n[nwaku] bug: Peer Reconnection not working?\n[nwaku] bug: nwaku &lt;&gt; js-waku interop tests failing\n\nNext §\n\n[nwaku] bug/regression: node ca be started on multiple clusters\n[nwaku] bug: autosharding resolves content topics to wrong shard\n[nwaku] bug: Store REST API returns invalid digest\n\nEnhancements §\nIn Progress §\n\n[nwaku] chore: review waku-simulator deployment and improve tracking processes\n[nwaku] feat: add WakuMessage’s meta field to db schema\n[nwaku] chore: Address more attack vectors in rate limiting non-relay protocols\n[js-waku] feat: filter.createSubscription accept ShardParams\n\nNext §\n\n[js-waku] chore: move to js-waku repo\n[js-waku] feat: better developer experience\n\nEcosystem Development §\nBD §\n\nCalls with prospects\nAdvancing ongoing going leads\nQualified prospects\nCreated a validation tracking database\nEvent planning done for the upcopming quarters\n\nSolution Engineering §\n\nWorking on slides for talks in May/June\nTrying to get js-waku working in projects again - so far resulted in filed issues\nupdated nwaku to 0.27.0 in awesome-akash\ncalls with BD\nassisting Portrait with some architectural decisions\nassisting Dria with nwaku REST API\n\nDev Rel §\n\ntoken2049 (20+ leads)\nlibp2p rpgf nomination completed\nsorting out ethdenver leads, sorting out crm\ndrafting Railgun blog article\nforwarding portrait.so interview to comms\ninterview preparation for Railgun &lt;&gt; waku\nEthdam feedback/summary\n\nComms and Events §\n\nX: 1441 new followers ( +11%), 47.8% engagement rate ( +58%), 15889 likes (+47%) - we hit 10k on Twitter - yay!\nLinkedin: 11 new followers\nDiscord: +44 (2.6%)\n1 PR went live, about W3PN and Logos, mentioning Waku - https://cointelegraph.com/press-releases/logos-partners-with-web3privacy-now-to-advance-digital-privacy\nWe’v interviewed Portrait founder at ETHDam - video sent for editing\n\nEvents §\n\nIvan gave a presentation and spoke at the panel at https://web3fc.xyz/\nGuru attended token2049\nETHDam summary doc - https://docs.google.com/document/d/1kgR8q-WMWJ56kGav6MiFYqkA2eDudc_lFUpdYM3sQ8s/edit and photos\n\nDocs §\n\nmerged the general FAQ\ndeprecated the JSON-RPC RFC spec\nWaku RFC website followup\n"},"waku/updates/2024-05-15":{"title":"2024-05-15 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Research Milestones §\nStore Incentivisation\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/17\n\nin-progress:\n\n[nwaku] feat: experimental incentivize store protocol\n\n\n\n\n\nRLN in resource-restricted clients\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/18/views/1\n\nachieved: PR for message validation in lightpush before relaying.\nnext: continue lightpush attaching RLN proofs to messages received from clients.\n\n\n\nRLNv2\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/21/views/1\n\nachieved: Test implementation WIP.\nnext:\n\nContinue planning for next waku fork (RLNv2 + onchain root/proofs) See: https://github.com/waku-org/research/issues/96 (future section). RLN v2 testing. New smart contract with both features. Prepare presentation for DLT conference.\nTest implementation continued and testing.\n\n\n\n\n\nStore v3 - Waku Sync\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/20/views/1\n\nachieved:\n\nExplored if there is a way to prune the negentropy storage based on timestamp.\nTtype state machine implementation and pruning mechanism.\n\n\nnext:\n\nwrite subrange wrappers for negentropy and use subranges to sync.\nusing hashes to fill the archive with the missing messages.\n\n\n\n\n\nStore v3 - message hashes\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/16/views/1\n\nachieved:\n\nbug fixes\n\n\nnext:\n\nfix compatability with Waku sync\n\n\n\n\n\nEngineering Milestones §\nComposing Waku Protocols to Improve Reliability\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/9/views/1\n\ncompleted:\n\n[js-waku] refine Filter\n[js-waku] chore: protocol implementations in @waku/core should be as unopinionated as possible\n[js-waku] feat: SDK for redundant usage of filter/lightpush\n[js-waku] bug: lightPush is not able to keep node connections\n[js-waku] https://github.com/waku-org/js-waku/issues/2002\n\n\nin-progress:\n\n[js-waku] feat: peer management for protocols (with disconnection management)\n\n\nnext:\n\n[js-waku] investigate suspended js-waku in suspended mode\n\n\n\n\n\nDOS protection for req-res protocols and metrics\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/11/views/1\n\ncompleted:\n\n[nwaku] chore: Address more attack vectors in rate limiting non-relay protocols\n\n\nin-progress:\n\n[nwaku] feat: Rate limit phase#3 - peer request rate registration and prioritization\n[nwaku] feat: Proper bandwidth metrics per shard\n[nwaku] feat: Enforce service specific rate limits\n\n\nnext:\n\n[nwaku] feat: Failsafe mechanism (guide) for BW limiting\n\n\n\n\n\nBindings\n\nStatus: In Progress\nProject: https://github.com/orgs/waku-org/projects/6/views/6\n\n[nwaku] chore: support setting DiscV5 and DNS-discovery in libwaku\n\n\n\nOther Work §\nBugs §\nIn Progress §\n\n[js-waku] feat: map/use correct bootstrap nodes fleet according to the configured pubsub topic\n[js-waku] test: create scripts for running light-push/filter and measuring ratio of messages sent and received\n[nwaku] bug: flaky test fails on MacOS\n[nwaku] bug: nwaku &lt;&gt; js-waku interop tests failing\n[nwaku] bug: Peer Reconnection not working?\n[nwaku] bug: build error on new AMD cpu’s (ubuntu 22.04 LTS)\n[nwaku] bug/regression: node ca be started on multiple clusters\n\nNext §\n\n[js-waku] bug: ApplicationInfo to PubsubTopic doesn’t take clusterId into consideration\n[nwaku] bug: Deserialization error on POST /relay/v1/auto/messages with ephemeral field in body\n[nwaku] bug: running testwaku can hang in some cases of UPnP or nat-pmp networking\n[nwaku] bug: Store REST API returns invalid digest\n[nwaku] bug: autosharding resolves content topics to wrong shard\n\nEnhancements §\nIn Progress §\n\n[js-waku] feat: map/use correct bootstrap nodes fleet according to the configured pubsub topic\n[nwaku] feat: light protocol tester application\n\nNext §\n\n[js-waku] feat: improve reuse of pubsub/content topic configuration\n[js-waku] feat: better developer experience\n[nwaku] feat: RLN-proofs as a lightpush service\n[nwaku] Add a flag to require minimum number of peers to publish a message on relay\n\nEcosystem Development §\nBD §\n\nQualified two leads\nAdvanced one lead toward deal\nSet up two meetings with potential partners\n\nDev Rel §\n\nThe Waku Network hit 500 nodes - yay!\nEvents page update\nThe Graph blog article draft\nThe Graph interview\n\nComms and Events §\n\nX: +489\nLinkedin: +7\nDiscord: +44\nWaku intro finalized - https://www.youtube.com/watch?v=nIWx5Vp_Qxk\n2 “how to run nodes” tutorials went live\nPublished Montly newsletter\nRailgun interview went live\nBuilder Spotlight went live\n\nDocs §\n\nImplemented a script on waku.org for automatic creation and updating of the specs section\nSubmitted a pull request to the specs repository to fix broken links and adjust the front matter\nGot the specs repo PR approved and merged Follow up with Hanno on RFC website plans Added high level overview of waku simulation results\n"},"waku/updates/2024-06-24":{"title":"2024-06-24 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\n\n[nwaku] PR bug fixes\n[chat] hash based query for outgoing messages https://github.com/status-im/status-go/pull/5217\n\n\nblockers:\n\n[chat] awaiting reviews\n[chat] unable to reproduce CI failures\n\n\n\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[nwaku] waku-simulator testing\n[chat] Dogfooding and fixes for routine that checks for missing messages https://github.com/status-im/status-go/pull/5281\n\n\nblockers:\n\n[chat] awaiting reviews\n[chat] unable to reproduce CI failures\n\n\n\n\n\nDOS protection for req-res protocols and metrics\n\nachieved:\n\n[nwaku] Rate limit phase3: implemented per peer request rate checks\n[nwaku] BW metrics per shard: implemented per shard metric collection\n\n\nnext:\n\n[nwaku] Rate limit phase3: Some polishing and test cases needed to finish\n[nwaku] Rate limit phase3: add rate limit metrics to dashboard\n[nwaku] BW metrics per shard: needs some tests and add section onto dashboard\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[nwaku] enhance partition creation: https://github.com/waku-org/nwaku/issues/2783\n[nwaku] validate that time retention policy works well: https://github.com/waku-org/nwaku/issues/2807\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nEnable testing of direct messages\n\nachieved:\n\n[chat] set up nightly tests &amp; 1:1 messages tests https://github.com/status-im/status-cli-tests/pull/1\n[chat] set up nightly tests for contact requests https://github.com/status-im/status-cli-tests/pull/3\n[chat] CLI bugs and improvements for usage in nightly tests https://github.com/status-im/status-go/issues/5266\n\n\nnext:\n\n[chat] set up nightly tests for group chats and community join requests\n[chat] investigate remaining tests failing\n\n\n\n\n\nReview connection management strategy and back-off and fix long disconnection issues\n\nachieved:\n\n[chat] Pause peer connector if node is offline https://github.com/status-im/status-go/pull/5340, https://github.com/waku-org/go-waku/pull/1125\n[chat] Fix usage of context for DiscV5 https://github.com/status-im/status-go/pull/5347\n[chat] Fix in status-go to filter peers by shard\n[chat] Dogfood light client with peer exchange enabled\n\n\nnext:\n\n[chat] Investigate / fix DiscV5 not finding valid peers in shards.test fleet\n[chat] make filter working along with peer exchange and debug connectivity issues with peers returned via peerExchange\n\n\n\n\n\nTooling: filter and light push protocols\n\nachieved:\n\n[nwaku] lite-protocol-tester works on waku-simulator\n[nwaku] configurable stress conditions\n[nwaku] intensive stress test had been ran (45 nodes (relay + service nodes) + multiple publisher light client and a filter client receiver)\n[nwaku] ran with different conditions\n[nwaku] in co-op with Alberto analyzing topology and message flows\n\n\nnext:\n\n[nwaku] exclude docker limitations from the seen failed message deliveries\n\n\n\n\n\nTelemetry: direct message reliability\n\nachieved:\n\n[nwaku] implemented two different ways to log received message information. One based on libp2p observers https://github.com/waku-org/nwaku/pull/2800 which we won’t use in practice. And one by adding the logs in a new nim-libp2p branch https://github.com/vacp2p/nim-libp2p/pull/1128\n\n\n\n\n\nReliability Protocol for Relay\n\nachieved:\n\n[nwaku] started to look at the current status-go implementation\n\n\nnext:\n\n[nwaku] carry on with the implementation in nwaku - https://github.com/waku-org/nwaku/issues/2819\n\n\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[chat] Improve filter subscription management in LightClient: various fixes wrt filter subscriptions and making lightNode work with peerExchange enabled https://github.com/status-im/status-go/pull/4665\n[chat] dogfooding light client in desktop\n[chat] fixed issue found while dogfooing, remove stale subs and update ping interval https://github.com/waku-org/go-waku/pull/1119\n[js-waku] improved peer management for light push protocol https://github.com/waku-org/js-waku/issues/2002\n[js-waku] worked on updating js-waku to store v3 https://github.com/waku-org/js-waku/issues/2029\n[js-waku] improving offline recoverability for Filter https://github.com/waku-org/js-waku/issues/2024\n\n\nnext:\n\n[js-waku] continue with moving to store v3 https://github.com/waku-org/js-waku/issues/2029\n[js-waku] continue with offline recoverability for Filter https://github.com/waku-org/js-waku/issues/2024\n\n\n\n\n\nUser apps for large scale dogfooding\n\nachieved:\n\n[js-waku] settled on the base implementation of dogfooding app https://github.com/waku-org/lab.waku.org/pull/68\n\n\nnext:\n\n[js-waku] provide front end for dogfooding app\n[js-waku] provide basic telemetry framework\n\n\n\n\n\nReview MVDS usage and fail path\n\nachieved:\n\n[chat] draft changes for reset MVDS epoch for online peers https://github.com/status-im/status-go/pull/5349\n\n\nnext:\n\n[chat] continue MVDS review https://github.com/orgs/waku-org/projects/33\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\nEnd-to-end reliability protocol - PoC\n\nachieved:\n\n[nwaku] continued gathering wide input on e2e reliability proposal: https://forum.vac.dev/t/end-to-end-reliability-for-scalable-distributed-logs/293/\n[nwaku] performed basic calculations to understand mathematical properties of proposed protocol, probabilistic model\n\n\nnext:\n\n[nwaku] stakeholders sync on next steps\n[nwaku] set scope for POC implementation\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[nwaku] start testing and investigating discv5 performance and possible issues https://github.com/waku-org/nwaku/issues/2810\n[nwaku] started deep review of peer manager logic opened PR with small fix to be able to update peers’ ENRs https://github.com/waku-org/nwaku/pull/2818\n[nwaku] reproduced with DST team issues forming stable mesh https://github.com/waku-org/nwaku/issues/2780 and analyzed logs. Found that connections aren’t being answered and started investigating a prospective problematic place in the code.\n\n\nnext:\n\n[nwaku] continue with discv5 and peer manager investigations\n[nwaku] continue investigating issuer forming a stable mesh\n\n\n\n\n\nMilestone - Scale 1:1 chat messages PoC §\n\nRLNv2 in nwaku\n\nachieved:\n\n[research] Published The Waku Simulator book: https://waku-org.github.io/waku-simulator/. It explains how to use waku-simulator to test different scenarios.\n[research] completed RLNv2 test plan, waku-simulator updates\n\n\nnext:\n\n[research] Integrate waku spammer: https://github.com/waku-org/nwaku/pull/2821\n[research] Assist with rlnv2 testing.\n[research] execute RLNv2 test plan\n\n\n\n\n\nOther Work §\nResearch §\n\n[Deliverable] Store Incentivisation (first iteration/POC)\n\n[research] achieved: opened a PR for a PoC incentivization testing: https://github.com/waku-org/nwaku/pull/2816\n[research] next: start outlining a minimal specification for RLN-as-a-service\n\n\n\nReliability §\n\nachieved\n\n[chat] Increase store query pagesize https://github.com/status-im/status-go/pull/5341\n[chat] Fix peer counter for statsu-desktop https://github.com/status-im/status-go/pull/5348\n[chat] Change order of rpc text input https://github.com/status-im/status-desktop/pull/15169\n\n\n"},"waku/updates/2024-07-01":{"title":"2024-07-01 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[chat] set lower max delivery attempts for outgoing messages https://github.com/status-im/status-go/pull/5382\n\n\n\n\n\nDOS protection for req-res protocols and metrics\n\nachieved:\n\n[nwaku] BW metrics per shard: implemented per shard metric collection - https://github.com/waku-org/nwaku/issues/1945\n[nwaku] Added dashboard panels for relay per shard traffic\n[nwaku] Added dashboard panels for non-relay protocols data traffic\n[nwaku] Added dashboard panels for non-relay protocols request rates\n\n\nnext:\n\n[nwaku] Rate limit phase3: Some polishing and test cases needed to finish\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[nwaku] analyse a database blocking issue: https://github.com/waku-org/nwaku/issues/2838\n\n\nnext:\n\n[nwaku] fix database blocking issue with solution detailed in  https://github.com/waku-org/nwaku/issues/2838\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nEnable testing of direct messages\n\nachieved:\n\n[chat] small logging cli issue\n[chat] testing private group chats https://github.com/status-im/status-cli-tests/pull/4\n\n\n\n\n\nReview connection management strategy and back-off and fix long disconnection issues\n\nachieved:\n\n[chat] investigating connectivity and discv5 issues\n[chat] fix peerExchange to filter peers by shard https://github.com/status-im/status-go/pull/5350/\n[chat] filter peers used for circuit-relay based on shards https://github.com/waku-org/go-waku/pull/1130\n[chat] Dogfood lightClient by enabling peerExchange\n\n\nnext:\n\n[chat] missing messages verification https://github.com/status-im/status-go/pull/5281\n[chat] store node query after sleep https://github.com/status-im/status-go/pull/5422\n[chat] investigate further peer connectivity issues by dogfooding\n[chat] refactor peer-manager for lightClient\n[chat] remove limit on connections when using relay\n\n\n\n\n\nTooling: filter and light push protocols\n\nachieved:\n\n[chat] lite-protocol-tester works on waku-simulator\n[chat] configurable stress conditions\n[chat] re-run some critical test for nicer logs for analysis\n[chat] analysed run results\n[chat] waku dogfooding telemetry https://github.com/status-im/telemetry/pull/20\n\n\nnext:\n\n[chat] new run with analysis on Alberto’s log analysis tool\n[chat] run lite-protocol-tester on shards.staging\n\n\n\n\n\nReliability Protocol for Relay\n\nachieved:\n\n[nwaku] started the implementation in nwaku - https://github.com/waku-org/nwaku/issues/2819\n\n\nnext:\n\n[chat] spec the reliability protocol for relay\n\n\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[js-waku] continued with using pool approach for protocols https://github.com/waku-org/js-waku/pull/2047\n[js-waku] store v3 migration https://github.com/waku-org/js-waku/pull/2036\n\n\nnext:\n\n[js-waku] complete ongoing efforts\n[js-waku] get back to offline state handling https://github.com/waku-org/js-waku/issues/2024\n\n\n\n\n\nReview MVDS usage and fail path\n\nachieved:\n\n[chat] Improve MVDS: reset epoch for online users https://github.com/status-im/mvds/pull/5\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\nEnd-to-end reliability protocol - PoC\n\nachieved:\n\n[research] Discovery on e2e reliability and bloom filters. Started working on a POC on a standalone repo.\n\n\nnext:\n\n[research] move to go-waku and continue with the POC\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[nwaku] analyse discv5 performance and possible issues https://github.com/waku-org/nwaku/issues/2810\n[nwaku] fixed issues forming mesh by DST team https://github.com/waku-org/nwaku/issues/2780 https://github.com/waku-org/nwaku/pull/2824\n[nwaku] Added small enhancements to the peer manager https://github.com/waku-org/nwaku/pull/2823, https://github.com/waku-org/nwaku/pull/2831\n[nwaku] Opened PR adding logs requested by DST for discv5 investigation https://github.com/waku-org/nwaku/issues/2841 https://github.com/waku-org/nwaku/pull/2811\n[nwaku] Opened PR adding peer origin information to the /admin/v1/peers REST endpoint https://github.com/waku-org/nwaku/pull/2848\n\n\nnext:\n\n[nwaku] continue with discv5 and peer manager investigations\n[nwaku] Implement a permanent customizable logging solution for nim-libp2p\n[nwaku] deprecate named sharding\n\n\n\n\n\nMilestone - Scale 1:1 chat messages PoC §\n\n\nRLNv2 in nwaku\n\nachieved:\n\n[research] Various debugging and bug fixing, executing https://github.com/waku-org/pm/issues/168\n\n\nnext:\n\n[research] Deliver 0.30.0 with RLNv2 in nwaku\n\n\n\n\n\nMaturing RLN variables/parameters revision\n\nachieved:\n\n[research] RLNv2 debugging, test plan, waku-simulator updates\n\n\nnext:\n\n[research] RLNv2 release candidate testing\n\n\n\n\n\nProvision RLN for light push clients PoC\n\nachieved:\n\n[research] continued testing of merged feature\n\n\nnext:\n\n[research] deploy service to existing fleets and dogfood with js-waku\n\n\n\n\n\nPay for RLN provision first PoC\n\nachieved:\n\n[research] PR for incentivization PoC (without on-chain interaction yet)\n\n\nnext:\n\n[research] add on-chain interaction to the PoC - txid lookup as proof of payment\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[chat] status-go: expose wakuext_enr\n[chat] use UTC format for geth.log timestamp\n[chat] use IP addresses instead of dns to store multiaddresses\n[chat] waku enr decoder tool https://github.com/waku-org/enr-decoder/\n[js-waku] remove relay dependency https://github.com/waku-org/js-waku/pull/2040\n\n\n\nBugs §\n\nachieved:\n\n[chat] do not write tcp port 0 and remove 100 chars length limit for multiaddresses\n[chat] fix ctx not available when starting telemetry client\n[nwaku] Mount Metadata in wakucanary https://github.com/waku-org/nwaku/issues/2720\n[nwaku] duplicate message forwarding to filter client https://github.com/waku-org/nwaku/issues/2320\n\n\nnext:\n\n[nwaku] peer exchanges return nodes that no longer exist. - https://github.com/waku-org/nwaku/issues/2414\n\n\n"},"waku/updates/2024-07-08":{"title":"2024-07-08 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\n\n[research] take up reported bugfixes after afk; continue with service rollout\n[chat] tuning store hash query to shorten the confirmation time of outgoing messages Reset MVDS epoch after peer is online\n\n\nnext:\n\n[research] start with storev3 benchmarking test plan\n\n\n\n\n\nDOS protection for req-res protocols and metrics\n\nachieved:\n\n[Epic: nwaku] Node Bandwidth Management Features\n\nBW metrics per shard: implemented per shard metric collection - feat: Proper bandwidth metrics per shard\nAdded dashboard panels for relay per shard traffic\nAdded dashboard panels for non-relay protocols data traffic\nAdded dashboard panels for non-relay protocols request rates\n\n\n[nwaku] feat: Enforce service specific rate limits\n\nFinalizing last phase of the feature:\n\nAdded per peer filtering of high users\nFilter service specific limits for ping and subscribe per peer\n\n\n\n\n\n\nnext:\n\n[nwaku] [Epic: nwaku] Node Bandwidth Management Features\n\nAdd distinction between gross/net inbound traffic of shards.\n\n\n[nwaku] feat: Enforce service specific rate limits\n\nfinish testing, add more unit tests\n\n\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[nwaku] new issue to create sonda tool, a canary for store services: chore: create sonda tool\n\n\nnext:\n\n[nwaku] start implementation of sonda tool\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nReview connection management strategy and back-off and fix long disconnection issues\n\nachieved:\n\n[chat] feat: filter peers stored in cache by cluster-id in peer-exchange\n[chat] feat: expose router and mesh peers to obtain list of peers in mesh\n[chat] improve relay peer connectivity and refactor peerManager to support lightMode feat: modify peer-manager to consider relay target peers\n[chat] enable peerExchange in relay for better peer discovery chore: enable pxClient in relay and increase relay peer connections\n[chat] fix peerExchange peer source and enable peerExchange in lightClient fix: enable pxclient and filter peerExchange peers returned\n[chat] query store node when back from sleep: missing communityRequestToJoin message\n[chat] IMO of what to do regarding receive reliability: Receive message reliability for Status desktop\n\n\nnext:\n\n[chat] expose rpc methods to obtain list of peers by topic, and list of peers in mesh\n[chat] lightClient topic health reporting and peer connectivity improvements\n[chat] when back online only request from store node since last time not 24 hours\n[chat] investigate connection management for outgoing messages\n\n\n\n\n\nTooling: filter and light push protocols\n\nachieved:\n\n[chat] optimize filter subscriptions by aggregating them feat: optimize filter subs and feat: aggregate filter subscriptions to do bulk subs with peer\n[nwaku] stress test on waku-simulator\n\n\nnext:\n\n[nwaku] add rln support\n[nwaku] run lite-protocol-tester on shards.staging\n\n\n\n\n\nReliability Protocol for Relay\n\nachieved:\n\n[chat] draft reliability for relay protocol spec feat: reliability for relay protocol\n[nwaku] carry on with the implementation in nwaku - feat: enhance reliability thanks to StoreV3\n\n\nnext:\n\n[chat] continue with the reliability protocol\n[nwaku] submit first PR in nwaku - feat: enhance reliability thanks to StoreV3\n\n\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[nwaku] Accepted new lightpush protocol definition with detailed fail case support - Enhance light push protocol\n[js-waku] filter uses dynamic peer management feat(filter): peer/subscription renewal with recurring Filter pings\n[js-waku] reliability with renewals due to offline state feat!: improve offline state handling for Filter subscription\n[js-waku] reliability RFC Add “req-res protocol reliability” spec\n\n\nnext:\n\n[nwaku] Implement: feat: Enhance lightpush protocol error handlingwaku-org/nwaku/issues/2722\n[js-waku] reliability RFC Add “req-res protocol reliability” spec\n[js-waku] reliability with renewals due to offline state feat!: improve offline state handling for Filter subscription\n\n\n\n\n\nUser apps for large scale dogfooding\n\nachieved:\n\n[js-waku] minor improvements to feat: add first version of dogfooding app and getting unblocked with latest nwaku release\n\n\n\n\n\nReview MVDS usage and fail path\n\nachieved:\n\n[chat] reset MVDS epoch after peer is back online Reset MVDS epoch after peer is online\n\n\nnext:\n\n[chat] continue mvds review\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\nEnd-to-end reliability protocol - PoC\n\nachieved:\n\n[research] started exploring POC in go-waku as an example application\n[research] researched Vac’s de-MLS protocol for possible integration\n\n\nnext:\n\n[research] continue with the POC starting with a minimal working version first\n\n\nblockers:\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[nwaku] added origin of peers in admin rest endpoint as per request, to debug and further understand discovery performance chore: adding origin to peers admin endpoint\n[nwaku] discussed with nim-libp2p team and tested a version of logging errors on publish to understand how often messages are not sent without returning errors\n\n\n\n\n\nMilestone - Scale 1:1 chat messages PoC §\n\n\nRLNv2 in nwaku\n\nachieved:\n\n[research] RLNv2 config for the Waku Network: chore: add TWN parameters for RLNv2\n[research] bug fix in RLN, vulnerability: fix(rln): nullifierlog vulnerability\n\n\nnext:\n\n[research] assist to deploy 0.30.0 release and integrate it in The Waku Network\n\n\n\n\n\nMaturing RLN variables/parameters revision\n\nachieved:\n\n[research] continuing the execution of RLN in resource-restricted network: [Epic: Dogfooding] Deliver RLN v2 + RLN in resource-restricted to The Waku Network\n[research] simulations using the waku simulator for different purposes\n[research] expanded RLNv2 testing, assisted with simulating and debugging vulnerabilities\n\n\nnext:\n\n[research] assist to deploy 0.30.0 release and integrate it in The Waku Network\n[research] complete execution of RLNv2 test scenarios\n\n\n\n\n\nPay for RLN provision first PoC\n\nachieved:\n\n[research] added chain interaction to incentivization POC\n\n\nnext:\n\n[research] draft a specification for RLN mainnet deployment\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[nwaku] deployment of release v0.30.1, which adds RLNv2\n[js-waku] prepare for next release\n\n\nnext:\n\n[js-waku] release last reliability improvements\n\n\n\nBugs §\n\nachieved:\n\n[chat] fix: panic due to enr having more than 300 bytes\n[chat] fix: ignore ws from circuit relay addresses, and allow non multiaddresses in multiaddrs ENR key\n[chat] fix failing wakuv2 tests\n[nwaku] bug: build error on new AMD cpu’s\n[nwaku] Various bug fixes:\n\nFrom chat team:\n\nbug: timestamp should be set to 0 if not provided in REST API\nbug: Store REST API returns invalid digest\n\n\nFrom Vac-QA:\n\nbug: Some PeerStore metadata is not filled in\nbug: PeerInfo instance affects listed protocols\nbug: Lightpush’s publish type error\nbug: Relay publish returns Failed to publish: timedout when a peer filter node is disconnected\nbug: Test failure on test_all\nhandle rln_msg_limit issue\n\n\nNim 2.0 readiness:\n\n[nwaku] bug: incorrect import paths pointing outside the repository\n\n\n\n\n\n\nnext:\n\n[nwaku] peer exchange returns nodes that no longer exist\n\n\n"},"waku/updates/2024-07-15":{"title":"2024-07-15 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\n\n[research] improved migration script &amp; migration tests\n\n\nnext:\n\n[research] storev3 benchmark test plan\n\n\n\n\n\nDOS protection for req-res protocols and metrics\n\nachieved:\n\n[nwaku] BW metrics per shard: implemented per shard metric collection feat: Proper bandwidth metrics per shard\n[nwaku] Added dashboard panels for relay per shard traffic\n[nwaku] Added dashboard panels for non-relay protocols data traffic\n[nwaku] Added dashboard panels for non-relay protocols request rates\n[nwaku] Finished and under review: feat: DOS protection of non relay protocols - rate limit phase3\n[nwaku] Added per peer filtering of high users\n[nwaku] Load balancing compensation applied to token replenish\n[nwaku] Filter service specific limits for ping and subscribe per peer\n\n\nnext:\n\n[nwaku] Separate add distinction between gross/net inbound traffic of shards.\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[nwaku] Designed and implemented the first version of the Sonda tool chore: create sonda tool, which is about to open for review.\n[nwaku] Better partition creation approach to avoid database AccessExclusiveLock - fix: postgres_driver - better partition creation without exclusive access\n\n\nnext:\n\n[nwaku] Get Sonda reviewed and implement feedback\n[nwaku] Tackle the following so that the cursor bug is fulfilled chore(archive): archive and drivers refactor\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nEnable testing of direct messages\n\nachieved:\n\n[chat] chore: allow cli to run on a different fleet\n\n\n\n\n\nReview connection management strategy and back-off and fix long disconnection issues\n\nachieved:\n\n[chat] refactor: ping a subset of connected peers, feat: bump go-waku to introduce new keep alive interval\n[chat] feat: wakuext_relayPeersByTopic\n[chat] fix: missing messages delay should be substracted\n[chat] feat: use mesh peers instead of all peers for determining topic health\n\n\n\n\n\nReliability Protocol for Relay\n\nachieved:\n\n[chat] refactor and merge the spec for relay reliability feat: reliability for relay protocol\n\n\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[js-waku] RFC clarifications Add “req-res protocol reliability” spec\n[js-waku] peer cycling complete feat: peer management for protocols (with disconnection management)\n\n\nnext:\n\n[nwaku] Implement: feat: Enhance lightpush protocol error handling\n\n\n\n\n\nUser apps for large scale dogfooding\n\nblockers:\n\n[js-waku] waiting for release of nwaku 0.30.2\n\n\n\n\n\nReview MVDS usage and fail path\n\nachieved:\n\n[chat] summarize the message types that are using MVDS\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\nEnd-to-end reliability protocol - PoC\n\nachieved:\n\n[research] raised a draft PR for e2e reliability POC in go-waku with new message structure, lamport timestamp, bloom filter, buffer and sync\n\n\nnext:\n\n[research] ACK handling, request missing messages, resend message\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[nwaku] investigating connectivity issues. Decreased connectivity loop interval chore: setting connectivity loop interval to 30 seconds\n[nwaku] final checks and deprecating named sharding chore: deprecating named sharding\n\n\nnext:\n\n[nwaku] Refactor code now that named sharding is removed, and deprecate pubsub-topic configuration\n\n\n\n\n\nMilestone - Scale 1:1 chat messages PoC §\n\n\nRLNv2 in nwaku\n\nachieved:\n\n[research] Completed milestone shipping RLNv2 and stateless light clients: [Epic: Dogfooding] Deliver RLN v2 + RLN in resource-restricted to The Waku Network\n\n\n\n\n\nMaturing RLN variables/parameters revision\n\nachieved:\n\n[research] Blog post announcing the new feature: Post RLN-V2 + Stateless Light Clients\n[research] completed RLNv2 e2e testing\n\n\nnext:\n\n[research] Some work with go-waku-light to showcase stateless light clients in The Waku Network\n[research] Conference presenting Waku poster\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[nwaku] bumped vendor dependencies for v0.31.0. Start using Nim 2.0.8 - chore: Bump dependencies for v0.31.0\n[chat] refactor:  remove namedsharding usage in status-go refactor: only use shards\n[chat] fix : filter uninstall and reinstall issue in status-go fix: don’t resubscribe filters unless there is a change in shard for community\n\n\n\nBugs §\n\nachieved:\n\n[nwaku] bug: peer exchange returns nodes that no longer exist\n\n\nnext:\n\n[nwaku] bug: failed to retrieve peer info via peer exchange protocol\n\n\n"},"waku/updates/2024-07-22":{"title":"2024-07-22 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\n\n[research] Proof of concept of store testing with waku-simulator\n\n\nnext:\n\n[research] Storev3 test plan and integrating tools for testing\n\n\nblockers:\n\n[research] Some complexities around merging/testing, currently handled by nwaku team\n\n\n\n\n\nDOS protection for req-res protocols and metrics\n\nachieved:\n\n[nwaku] BW metrics per shard: implemented per shard metric collection feat: Proper bandwidth metrics per shard\n[nwaku] Added dashboard panels for relay per shard traffic\n[nwaku] Added dashboard panels for non-relay protocols data traffic\n[nwaku] Added dashboard panels for non-relay protocols request rates\n[nwaku] Released feat: Enforce service specific rate limits\n\nAdded per peer filtering of high users\nLoad balancing compensation applied to token replenish\nFilter service specific limits for ping and subscribe per peer\n\n\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[nwaku] Improved and merged Sonda - canary service to check liveness of store nodes\n[nwaku] Merged store-v3 cursor fix chore(archive): archive and drivers refactor\n\n\nnext:\n\n[nwaku] PostgreSQL query optimizations chore: query performance in PostgreSQL by avoiding ordering in queries\n[nwaku] PostgreSQL enhance retention policy: bug: retention policy does not work when postgres db is over loaded\n[nwaku] PostgreSQL enhance query performance chore: improve postgres query performance\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nReview connection management strategy and back-off and fix long disconnection issues\n\nachieved:\n\n[chat] feat: flag to enable/disable missing message verification\n\n\n\n\n\nTooling: filter and light push protocols\n\nachieved:\n\n[chat] added support for 2 lightpush peers to be used for better reliability feat: support for lightpush to use more than 1 peer\n[chat] fix metadata protocol from disconnecting light-clients and only use clusterID and accept connections from lightclients fix: for light node do not check for matching shards but only clusterID\n\n\nnext:\n\n[nwaku] Little enhancement for network connectivity, use bootstrap enr’s to connect to any kind of network and detect shardings\n[nwaku] Auto select service peers and use them randomly for testing on both sides.\n[nwaku] run lite-protocol-tester on shards.staging\n\n\n\n\n\nReliability Protocol for Relay\n\nachieved:\n\n[nwaku] started local sqlite registry implementation feat: enhance reliability thanks to StoreV3\n[chat] config to enable/disable storev3 confirmations for sent messages feat: flag to enable/disable sent message store query confirmations\n\n\nnext:\n\n[nwaku] carry on with implementation feat: enhance reliability thanks to StoreV3\n\n\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[js-waku] improved renewal of peers for Filter feat(filter): peer/subscription renewal with recurring Filter pings\n[js-waku] check for missing messages from Filter subscriptions feat: validate messages for individual filter nodes &amp; perform renewals\n[js-waku] peer renewal and keep alive improvements feat: fix peer renewal, change Filter keep alive\n\n\nnext:\n\n[nwaku] Implementing: feat: Enhance lightpush protocol error handling\n\n\n\n\n\nReview MVDS usage and fail path\n\nachieved:\n\n[chat] status messages need for e2e reliability collected\n[chat] fix_: delivered message should not send envelope sent signal\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\nEnd-to-end reliability protocol - PoC\n\nachieved:\n\n[research] implemented ACK handling, request missing messages, resend message\n\n\nnext:\n\n[research] comprehensive tests for the poc\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[research] review of discv5 both spec and nim implementation\n[research] compiled audit of discovery status quo and potential future strategies\n[nwaku] Creating versions for DST team to test discv5 and message reliability\n[nwaku] Proposing new solution to log received message info from nim-libp2p. Created custom version for DST team to use chore: creating branch to test Waku’s received messages\n[nwaku] Started investigating and implementing improvements for connection management of bootstrap only nodes bug: Node accepts connections when configured for just discovery\n[nwaku] Improved logging chore: improving logging under debugDiscv5 flag, chore: logging content topic of spam messages\n[nwaku] Investigated at depth discv5’s implementation bug: discv5 not returning enough peers\n\n\nnext:\n\n[research] review other discovery methods and state of implementation in nim\n[research] review metrics collected and add more if needed\n[research] implement identified discv5 improvement strategies\n[nwaku] Get feedback on nim-libp2p’s logging solution\n[nwaku] Refactor code now that named shading is removed, and deprecate pubsub-topic configuration\n[nwaku] Continue discussing and analyzing discv5’s performance and possible improvements\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[chat] chore: rename shards.staging to status.staging\n[chat] chore: rename shards.staging to status.staging\n[chat] chore: bump go-libp2p\n[chat] enable metadata protocol regardless of cluster-ID used\n[js-waku] chore: enforce access modifiers\n[js-waku] chore: bump @waku peer dependencies\n[js-waku] improve network options handling chore: throw if more than one network config is passed\n\n\nnext:\n\n[nwaku] deploy release v0.31.0 Prepare release 0.31.0\n\n\n\nBugs §\n\nachieved:\n\n[chat] investigation of slowness to retrieve messages in storenode message counter\n[nwaku] Build nwaku image for Windows - feature: support Windows 11\n\n\nnext:\n\n[nwaku] Manage stale peers dynamically with better reliability fix: peer-exchange issue\n[nwaku] bug: failed to retrieve peer info via peer exchange protocol\n\n\n"},"waku/updates/2024-07-29":{"title":"2024-07-29 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\n\n[research] completed first draft of storev3 benchmark test plan\n\n\nnext:\n\n[research] implementing test tools, finalising test plan\n\n\nblockers:\n\n[research] not clear on HW setup on which benchmarking should be done\n\n\n\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[research] last online timestamp periodically saved to new sqlite db, store client query for last messages, tests\n\n\nnext:\n\n[research] reviews, hand-off to nwaku team for merging\n\n\n\n\n\nDOS protection for req-res protocols and metrics\n\nachieved:\n\n[nwaku] Node Bandwidth Management Features\n[nwaku] Enforce service specific rate limits\n[nwaku] Separate add distinction between gross/net inbound traffic of shards. chore: Distinction between gross/net trafic in bandwidth per shard metric\n\n\nnext:\n\n[nwaku] dogfooding\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[nwaku] Improved Sonda’s Grafana dashboard chore: show relative metrics instead of absolute in Sonda\n[nwaku] Improved Sonda’s logging chore: including UTC time in Sonda logs\n[nwaku] Analysed that messages_lookup is a good approach chore: improve postgres query performance\n\n\nnext:\n\n[nwaku] Implement messages_lookup to enhance hashes-only queries chore: improve postgres query performance\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nReview connection management strategy and back-off and fix long disconnection issues\n\nachieved:\n\n[chat] Rate limit message publishing\n[chat] Disconnect all peers if ping to randomly choosen peers fails twice, chore: disconnect on subsequent ping failures\n[chat] improve lightclient connectivity by publishing their shard info in metadata fix: lightclient enr shards and fix: check for lightclient only if req doesn’t contain shards\n[chat] record connection failures for req/resp protocols\n\n\n\n\n\nTooling: filter and light push protocols\n\nachieved:\n\n[chat] Lightpush and Filter bandwidth metrics, feat: store filter and lightpush stats\n[nwaku] Little enhancement for network connectivity, use bootstrap enr’s to connect to any kind of network and detect shardings\n[nwaku] Auto-select service peers and use them randomly for testing on both sides.\n[nwaku] Run lite-protocol-tester on shards.staging\n\n\n\n\n\nTelemetry: direct message reliability\n\nachieved:\n\n[chat] Fix concurrent RW on map in telemetry server: fix: concurrent rw on map\n[chat] Improve storednode message counter dashboard: storenode-message-counter\n\n\n\n\n\nReliability Protocol for Relay\n\nnext:\n\n[nwaku] ongoing implementation in nwaku: feat: Enhance lightpush protocol error handling\n\n\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[chat] lightclient error handling\n[js-waku] health state of nodes feat: node and protocols health\n[js-waku] improve continuous peer discovery feat(peer-exchange): support continuous peer information updates\n\n\nnext:\n\n[js-waku] complete review for health state of node and continuous peer discovery\n\n\n\n\n\nUser apps for large scale dogfooding\n\nachieved:\n\n[js-waku] dogfooding app is up and running https://lab.waku.org/dogfooding/\n\n\nnext:\n\n[js-waku] need to fix HTTP headers on the serving site, build basic dashboard\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\nEnd-to-end reliability protocol - PoC\n\nachieved:\n\n[research] added comprehensive tests for the e2e reliability POC\n\n\nnext:\n\n[research] fixes arising from tests, some cleanup and prepare for dogfooding\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[research] adding metrics, manual testing\n[nwaku] Creating versions for DST team to test discv5 and message reliability\n[nwaku] improved nim-libp2p PR with custom logging observer chore: creating branch to test Waku’s received messages\n[nwaku] Opened issue and investigated the phenomenon of some nodes getting stuck and missing messages in DST simulations bug: node getting stuck and missing messages\n\n\nnext:\n\n[nwaku] Continue with the implementation of the bootstrap nodes connection limiting\n[nwaku] Refactor code now that named shading is removed, and deprecate pubsub-topic configuration\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[nwaku] Revised nwaku nodes’ logging and moved added PRs in nwaku and nim-libp2p to downgrade particularly spammy logs chore: reduce loglevel to some too frequent or unnecessary logs\n[nwaku] Added a CI job verifying that new code is properly linted chore: adding lint job to the CI\n[nwaku] Started going over failed interop tests bug: nwaku &lt;&gt; js-waku interop tests failing\n[nwaku] Release candidate v0.31.0 looks nice from Status-QA PoV Prepare release 0.31.0\n[nwaku] Have the interop tests fixed and a working CI\n[nwaku] Little enhancement on tooling, now single file build/test-run available right from make\n[js-waku] better linting for classes chore: enforce access modifiers\n[js-waku] fix peer exchange tests chore(peer-exchange): use an event listener to gauge if the service is mounted\n[js-waku] remove a bit of tech debt chore: remove content_topic specific API\n\n\nnext:\n\n[nwaku] Perform release v0.31.0\n[js-waku] Release\n\n\n\nBugs §\n\nachieved:\n\n[nwaku] bug: RLN_RELAY_MSG_LIMIT handling\n[nwaku] feature: support Windows 11 made little progress on this it’s ongoing.\n[nwaku] bug: peer exchange returns nodes that no longer exist\n\n\nnext:\n\n[nwaku] bug: failed to retrieve peer info via peer exchange protocol\n[nwaku] building test-peer exchange app on top of the network to analyze peer-exchange behaviour again cache refresh rate.\n\n\n"},"waku/updates/2024-08-05":{"title":"2024-08-05 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\n\n[research] implemented basic testing tools for storev3 benchmarking\n\n\nnext:\n\n[research] run some tests against status.prod to get an idea of query times and bottlenecks, expand testing from there\n\n\n\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[research] store resume PR updates\n\n\nnext:\n\n[research] merge store resume PR\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[nwaku] Simplification of store legacy code to prevent wrong partition creation - chore: Simplification of store legacy code\n[nwaku] Validate the need for bigger database servers because they were swapping too much\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nTelemetry: direct message reliability\n\nachieved:\n\n[chat] report peer id and number of connection failures to telemetry feat(telemetry)_: send connection failure metric, feat: handle metric for peer connection failure\n\n\nnext:\n\n[chat] update dial function in go-waku to propagate dial failures to status-go\n\n\nblockers:\n\n\n\nReliability Protocol for Relay\n\nachieved:\n\n[nwaku] Simplify implementation and start using callbacks for API clients feat: enhance reliability thanks to StoreV3\n\n\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[js-waku] validating filter messages, and performing renewals feat: validate messages for individual filter nodes &amp; perform renewals\n[js-waku] health metric for node and protocols: feat: node and protocols health\n\n\nnext:\n\n[nwaku] ongoing implementation feat: Enhance lightpush protocol error handling\n[js-waku] message send retries for lightpush: feat(lightpush): add retries to failing peers\n\n\nblockers:\n\n[js-waku] store v3 blocked by nwaku 0.32 release: feat!: store v3\n\n\n\n\n\nUser apps for large scale dogfooding\n\nachieved:\n\n[js-waku] add light push error metric and generic metric to dogfooding app feat: add light push error and generic waku metric, feat: record light push errors in dogfooding\n\n\nnext:\n\n[js-waku] remove metric from queue on duplicate key error dogfooding: remove metric from queue on duplicate key error\n\n\n\n\n\nReview MVDS usage and fail path\n\nachieved:\n\n[chat] bump mvds for clearing old states chore_: bump mvds\n\n\nnext:\n\n[chat] move message hash query for outgoing messages to go-waku\n[chat] continue the request to join community test\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[nwaku] Investigated bug: node getting stuck and missing messages. Created images for DST team to run and analyzed the resulting logs\n[research]  added new metric and grafana dashboard focused on discovery, PR adding cluster filtering to Waku peer exchange\n\n\nnext:\n\n[nwaku] Continue investigating the issue, now trying to understand how async futures are handled by the dispatcher\n\n\n\n\n\nMilestone - Scale 1:1 chat messages PoC §\n\nProvision RLN for light push clients PoC\n\nnext:\n\n[research] Investigate how to use Paymasters aka gasless transactions for users, paid by a smart contract. Goal, PoC with go-waku-light\n\n\n\n\n\nMilestone - Scale up number of Communities §\n\nUsage of Rendezvous\n\nnext:\n\n[research] rendez-vous discovery\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[nwaku] Fixed failing js-waku interop tests and got CI to work again chore: changing default pubsub topic to its static sharding version\n[nwaku] Improving docs chore: updating doc reference to https rpc, switching RPC provider instructions from websocket to https, updating readme\n[nwaku] Bumped dependency for gcc 14 support chore: bumping nim-bearssl\n[nwaku] Deploy v0.31.0 in waku.prod and status.prod\n[chat] refactor: move rate limiter and priority queue from status-go to API package\n[chat] refactor: move missing messages logic from status-go to go-waku, \n[chat] remove unused code from wakuv2 refactor: extract missing messages logic to go-waku\n\n\nnext:\n\n[js-waku] peers used by different protocols to be different from one-another to increase footprint: feat: peer selection for protocols\n[js-waku] filter API to be simple (reliability user story): feat: use decoder as a seed for subscription\n\n\n\nBugs §\n\nachieved:\n\n[nwaku] building testing tools to analyze peer-exchange protocol and its behavior test: peer exchange testing tool\n[js-waku] continuous discovery updates for node information chore(peer-exchange): support updates of previously discovered peer’s addresses\n[chat] fix: missing wakuv2 fields in createAccountRequest toJson func fix: missing wakuv2 fields in createAccountRequest toJson func\n[chat] fix: storenode multiaddresses\n[chat] fix: handle scenario where the node’s ENR has no shard (due to shard update)\n\n\nnext:\n\n[nwaku] bug: failed to retrieve peer info via peer exchange protocol\n[chat] verify missing messages to determine if storenode sync was executed\n\n\n"},"waku/updates/2024-08-12":{"title":"2024-08-12 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\n\n[js-waku] feat!: store v3\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[nwaku] PR almost merged with optimizations in messageHash queries through lookup table chore: Optimize hash queries with lookup table\n[nwaku] submitted PR in infra-status to fine-tune the Postgres settings after having increased the hw specs store-db add more appropriate db settings for current db hw\n\n\n\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[nwaku] PR review WIP to add Waku Sync feat: Nwaku Sync\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nTooling: filter and light push protocols\n\nachieved:\n\n[nwaku] Started using liteprotocoltester tool to send lightpush msgs from a node located in Frankfurt and receiving through waku-filter in a node located in Sydney. Both are connected to one node in status.prod fleet.\n[nwaku] liteprotocoltester tool helped to discover duplicated messages problem\n\n\nnext:\n\n[nwaku] carry on with duplicated messages issue\n\n\n\n\n\nTelemetry: direct message reliability\n\nachieved:\n\n[chat] report peer id and number of connection failures to telemetry feat(telemetry)_: send connection failure metric, feat: handle metric for peer connection failure\n\n\n\n\n\nReliability Protocol for Relay\n\nachieved:\n\n[nwaku] Development of subscription awareness for delivery_monitor module feat: enhance reliability thanks to StoreV3\n\n\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[nwaku] ongoing implementation in nwaku feat: Enhance lightpush protocol error handling\n[js-waku] filter API refactor for ease and DX: feat(filter)!: new simpler filter API\n\n\n\n\n\nReview MVDS usage and fail path\n\nachieved:\n\n[chat] bump mvds for clearing old states chore_: bump mvds\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\nEnd-to-end reliability protocol - PoC\n\nachieved:\n\n[research] peer retrieval of missing messages, reconnect capability for tests, conflict resolution; and raised a final PR for POC\n\n\nnext:\n\n[research] address review comments, dogfooding\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[nwaku] Continued investigating bug: node getting stuck and missing messages\n[nwaku] Found “Futures” leak in yamux and confirmed that it doesn’t happen on mplex. Opened an issue in nim-libp2p bug: yamux Futures leak and a PR in nwaku switching back to mplex chore: using mplex instead of yamux\n[nwaku] Got feedback from Nimbus and new potential ways to debug bug: node getting stuck and missing messages\n[nwaku] Completed bug: Node accepts connections when configured for just discovery, optimizing the connection management of discv5-only nodes\n[research] libp2p rendezvous wrapper impl. at the waku layer\n\n\nnext:\n\n[nwaku] Try the recommended debugging techniques\n[research] namespace definition, discovery strategy\n\n\n\n\n\nMilestone - Scale 1:1 chat messages PoC §\n\n\nMaturing RLN variables/parameters revision\n\nachieved:\n\n[research] raw spec PR for RLN contract mainnet deployment: Add WAKU2-RLN-CONTRACT spec for mainnet deployment\n\n\nnext:\n\n[research] continue the discussion around the PR, finalize the initial version of the spec\n\n\n\n\n\nPay for RLN provision first PoC\n\nachieved:\n\n[research] PoC with a paymaster in zksync, written in golang\n\n\nnext:\n\n[research] continue work with paymaster to sponsor tx fees in zksync\n\n\nblockers:\n\n[research] lots of issues deploying rln to zksync\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[nwaku] upgraded the peer exchange mounting procedure - chore: upgrade peer exchange mounting](https://github.com/waku-org/nwaku/pull/2953)\n[nwaku] Successfully reproduced the PR exchange issue - bug: failed to retrieve peer info via peer exchange protocol\n[nwaku] Made progress on testing tools - test: peer exchange testing tool\n[chat] refactor: move rate limiter and priority queue from status-go to API package refactor: move rate limiter and priority queue from status-go to api package\n[chat] refactor: move missing messages logic from status-go to go-waku, refactor: extract missing messages logic to go-waku\n[chat] refactor: remove unused code from wakuv2\n\n\nnext:\n\n[nwaku] Resolve the PR exchange issue bug: failed to retrieve peer info via peer exchange protocol\n[nwaku] Complete peer exchange testing tools test: peer exchange testing tool\n\n\n\nBugs §\n\nachieved:\n\n[nwaku] fix: missing wakuv2 fields in createAccountRequest toJson func\n[chat] fix: storenode multiaddresses\n[chat] fix: handle scenario where the node’s ENR has no shard (due to shard update)\n\n\n"},"waku/updates/2024-08-19":{"title":"2024-08-19 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\n\n[research] Refined testing tools and query criteria for benchmark tests\n[research] Obtained insightful data from store queries on the status.prod system\n\n\nnext:\n\n[research] run some more queries and discuss findings\n[research] run benchmark tests on isolated system and summarise findings\n\n\n\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[nwaku] PR merged to add Waku Sync Nwaku Sync\n\n\nnext:\n\n[nwaku] Deploy an image with Waku Sync into status.staging to start the dogfooding\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[nwaku] Deployed a version in status.prod with hash query optimized Optimize hash queries with lookup table\n[nwaku] Endurance of partition deletion faster retention policy when error and use of detach finalize when needed\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nReview connection management strategy and back-off and fix long disconnection issues\n\nachieved:\n\n[chat] limit the maximum number of message hashes by query hash\n[chat] limit the maximum number of message hashes to request per query\n\n\n\n\n\nReliability Protocol for Relay\n\nachieved:\n\n[nwaku] Almost completed implementation for filter enhance reliability thanks to StoreV3\n\n\nnext:\n\n[nwaku] Carry on with filter and lightpush reliability-store awareness\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\nEnd-to-end reliability protocol - PoC\n\nachieved:\n\n[research]  PR approved and addressed review comments. POC dogfooding in progress. Identified and fixed a certain deadlock issue with new node joining the network.\n\n\nnext:\n\n[research] share dogfooding doc, start exploring status-go for API spec\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[nwaku] Tested different profilers to help us find the root cause of node getting stuck and missing messages\n[nwaku] Supported nim-libp2p team with yamux Futures leak\n\n\nnext:\n\n[nwaku] analyze results after DST runs their simulations with profiling tools\n\n\n\n\n\nMilestone - Scale 1:1 chat messages PoC §\n\nMaturing RLN variables/parameters revision\n\nachieved:\n\n[research] RLN contract mainnet spec ready for review Add WAKU2-RLN-CONTRACT spec for mainnet deployment\n\n\nnext:\n\n[research] continue the discussion around the PR, present at Status-Waku and Tokenomics calls\n\n\n\n\n\nMilestone - Scale up number of Communities §\n\nUsage of Rendezvous\n\nachieved:\n\n[research] namespace, wrapper update\n\n\nnext:\n\n[research] waku rendezvous spec\n\n\nblockers:\n\n[research] libp2p rendezvous limit what can be done at waku layer\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[chat] move outgoing message check from status-go to go-waku, extract message hash query for outgoing messages to go-waku\n[chat] add sender api for publish messages with additional check chore: refactor sender api\n[chat] move filter manager from status-go to go-waku, move filter mgr to go-waku\n[chat] rebase gossipsub from libp2p update rebased gossipsub from libp2p, rebase from libp2p\n[chat] chore: bump go-waku on status-go release branch to fix crashes: bump go-waku\n[chat] refactor: remove status-im/rendezvous refactor: remove status-im/rendezvous\n[nwaku] reviewed max-relay-peers configuration, added and tested a fix improving the connection management pruning excess in relay connections and closed review max-relay-peers config attribute in wakunode2\n[nwaku] updated dependencies for release v0.32.0\n[nwaku] Building a functional application to analyze the peer_exchange protocol on a remote node.\n[nwaku] Encountered issues with [switch ↔ node] connections, so transitioning to a [node ↔ node] setup for the same functionality (learning point.)\n\n\nnext:\n\n[nwaku] Resolve the PR exchange issue. failed to retrieve peer info via peer exchange protocol\n\n\n\nBugs §\n\nachieved:\n\n[chat] fix issue that causes log flooding in mobile where DNS is not resolvable add ticker to check peers and update connection status, add ticker to check peers and update connection status\n[chat] fix for crash wrt peer count use corrected connected peer count and add check to avoid crash\n[chat] ping interval related fixes ping interval fixes, ping interval\n[chat] fix proper reporting of connection change to filter manager reporting connection change to filter manager\n[chat] return on insert error\n[chat] fix: panic on MessageQueue.Push, keep channels open\n[chat] fix: memory leak while waiting for storenode available signal tmp remove subscription to mailserver available signal to avoid mem leak, wait for mailserver available signal to change missing messages criteria\n[nwaku] bug cleaning: discussed action items and started implementing them for RLNv2 in dynamic mode imposed rate limit after the first message while and RLNv2 rate limit imposed sooner than expected\n\n\n"},"waku/updates/2024-08-26":{"title":"2024-08-26 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\n\n[research] run benchmark tests on isolated store DB\n\n\nnext:\n\n[research] summarise findings\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[nwaku] Run “ANALYZE messages” more regularly chore: ANALYZE messages query should be performed regularly\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nReliability Protocol for Relay\n\nachieved:\n\n[nwaku] new PR with reliability approach chore: delivery monitor for store v3 reliability protocol\n[chat] create sender api for publishing messages and sent check chore: refactor sender api\n\n\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[js-waku] Filter API improvements feat(filter)!: new simpler filter API\n[js-waku] browser network state handling leftover feat: offline state recovery for Filter subscription\n\n\nnext:\n\n[js-waku] in progress on fixes for filter subscriptions bug: filter sdk does not dial newly added peers\n[js-waku] in progress on improvements for peer selection feat: peer selection for protocols\n[js-waku] in progress on missing messages verification feat: message verification and retry\n\n\nblockers:\n\n[js-waku] light push improvements, waiting for nwaku feat: migrate to latest LightPush version\n\n\n\n\n\nUser apps for large scale dogfooding\n\nachieved:\n\n[js-waku] debugged and minor fixes, collected data\n\n\nnext:\n\n[js-waku] setup basic dashboards\n[js-waku] improve data collection\n\n\n\n\n\nReview MVDS usage and fail path\n\nachieved:\n\n[chat] spec mvds usage in status feat: status mvds usage\n[chat] mvds usage in request to join community message feat_: request to join community message use mvds\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\nEnd-to-end reliability protocol - PoC\n\nachieved:\n\n[research] merged and launched e2e reliability POC dogfooding\n\n\nnext:\n\n[research] document and address POC dogfooding findings, start planning for Status integration\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[nwaku] Renamed NsPubsubTopic to RelayShard as a step towards switching from pubsub topics to shards chore: rename NsPubsubTopic\n[nwaku] Deprecated protected topics and added the feature of protected shards as a replacement chore: deprecating protected topics in favor of protected shards\n[chat] shard aware peer store pruning feat: shard aware pruning of peer store\n[chat] filter peer exchange peers served feat: shard based filtering in peer exchange\n\n\n\n\n\nMilestone - Scale 1:1 chat messages PoC §\n\n\nMaturing RLN variables/parameters revision\n\nachieved:\n\n[research] RLN contract mainnet spec merged Add WAKU2-RLN-CONTRACT spec for mainnet deployment\n\n\nnext:\n\n[research] draft Vac research forum post on implementation steps for incentivization; discuss RLN mainnet contract development to iterate on the spec\n\n\n\n\n\nProvision RLN for light push clients PoC\n\nachieved:\n\n[research] go-waku-light now integrated end to end with TWN: Update TWN Sepolia contract + chat\n\n\nnext:\n\n[research] Start planning rlnv2 itegration in 1on1 chats\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[js-waku] make static and auto sharding default feat!: deprecate named pubsub topics and use static/auto sharding\n[js-waku] improve timestamp compatibility chore(message-hash): use timestamp in nanoseconds instead of milliseconds\n[js-waku] working on unit test coverage for core implementation feat: unit testing @waku/core\n[nwaku] Fixed duplicate logging key bug fix: avoid using the msg key in chronicles\n[nwaku] Updated dependencies for release v0.32.0 chore: updating dependencies for release 0.32.0\n[nwaku] Improved logging needed for DST simulations by using the new nim-libp2p feature of onValidated observers chore: logging received message info via onValidated observer\n[nwaku] libwaku retrieves ENR chore: libwaku retrieve my enr and adapt golang example\n\n\n\nBugs §\n\nachieved:\n\n[chat] fix use UTC time in logs chore: use utc time in logs to avoid user location getting disclosed\n[chat] status-go: fix flaky waku2 test chore: fix TestBasicWakuV2\n\n\n"},"waku/updates/2024-09-02":{"title":"2024-09-02 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\n\n[research] Refined testing tools and query criteria for benchmark tests\n\n\nnext:\n\n[research] run some more queries and discuss findings\n\n\n\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[nwaku] Submitted PRs to enable store-sync in fleets: store node enable store-sync protocol, node enable store-sync protocol\n\n\nnext:\n\n[research/nwaku] start store-sync dogfood\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[research] executed more benchmark test scenarios\n\n\nnext:\n\n[research] figure out why some test setups get bad response after 5s\n[research] write test report\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nTooling: filter and light push protocols\n\nachieved:\n\n[nwalu] Grafana dashboard is available for monitoring test performance and message delivery issues: chore: add dashboard for liteprotocoltester runs chore: Added metrics to liteprotocoltester\n\n\n\n\n\nReliability Protocol for Relay\n\nachieved:\n\n[nwaku] PR merged chore: delivery monitor for store v3 reliability protocol\n\n\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[js-waku] implement missing messages monitor feat(filter): reliability monitor as a separate class to handle reliability logic\n[js-waku] match RFC with having 2 peers used chore: change amount of used peers to 2\n[js-waku] complete offline Filter recovery feat: offline state recovery for Filter subscription\n[js-waku] improve peer selection feat: sort peers for protocol by least active connections\n[js-waku] prioritize connected peers chore: choose peers from the connected pool, instead of dialing unconnected peers\n\n\nnext:\n\n[js-waku] improve peer selection feat: sort peers for protocol by least active connections\n[js-waku] prioritize connected peers chore: choose peers from the connected pool, instead of dialing unconnected peers\n\n\n\n\n\nReview MVDS usage and fail path\n\nachieved:\n\n[chat] spec mvds usage in status feat: status mvds usage\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\n\nEnd-to-end reliability protocol - PoC\n\nnext:\n\n[research]  incorporate better logging and other suggestions from dogfooding for POC\n\n\n\n\n\nEnd-to-end reliability protocol - Status integration\n\nachieved:\n\n[research] research on status-go to assess suitable approach for API with e2e reliability\n\n\nnext:\n\n[research] start documenting findings for Status API\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[nwaku] Implemented most of the pubsub topic config deprecation chore: deprecating pubsub topic\n[chat] shard aware peer store pruning feat: shard aware pruning of peer store\n[chat] filter peer exchange peers served feat: shard based filtering in peer exchange\n\n\nnext:\n\n[nwaku] finish and merge chore: deprecating pubsub topic\n\n\n\n\n\nMilestone - Scale 1:1 chat messages PoC §\n\n\nMaturing RLN variables/parameters revision\n\nachieved:\n\n[research] first version of implementation roadmap for RLN on mainnet RLN on mainnet - Implementation Roadmap\n\n\nnext:\n\n[research] discuss implementation roadmap\n\n\n\n\n\nProvision RLN for light push clients PoC\n\nachieved:\n\n[research] drafting forum post on service incentivization (WIP)\n\n\nnext:\n\n[research] forum post work cont’d\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[nwaku] Prepared and validated release candidate for v0.32.0\n[nwaku] Fixed bug importing Negentropy fix: libnegentropy integration which made fleet deployments fail\n[nwaku] Started nwaku integration in status-go. The nwaku node can run from within the status-cli (very initial phase.)\n[nwaku] Revisit nwaku for Windows 11 issue feature: support Windows 11\n[nwaku] Utilized peer exchange (PX) tools to analyze optimal refresh rates for PX response health update PR fix: peer-exchange issue\n[nwaku] litprotocoltester tool helped to discover duplicated messages problem\n[nwaku] Issue reproduced with the latest release in local simulation with liteprotocoltester and waku-sim: bug: duplicate messages on the network logs are gathered and started to analyze\n[nwaku] print WakuMessageHash as hex strings to make logs more readable chore: print WakuMessageHash as hex strings\n[chat] create sender api for publishing messages and sent check chore: refactor sender api\n[chat] remove satus.test fleet chore_: remove status.test fleet\n[chat] refactor - use concrete datatypes instead of string refactor_: use concrete datatypes instead of string\n[js-waku] improve devex by enabling insecure web sockets chore: enable back filterAll if set by consumer\n[js-waku] move to Node.js LTS chore: upgrade node to LTS 20\n[js-waku] return better error codes and improve error handling feat(lightpush)!: return new error messages\n\n\nnext:\n\n[nwaku] Perform the release\n[nwaku] Carry on analyzing the logs to track the duplicate msg issues in light protocols.\n\n\n\nBugs §\n\nachieved:\n\n[chat] fix flaky waku2 test chore: fix TestBasicWakuV2\n[chat] fix use UTC time in logs chore: use utc time in logs to avoid user location getting disclosed\n[js-waku] fix imports that were crushing the node fix: import of base_protocol and networkConfig type guard\n\n\n"},"waku/updates/2024-09-09":{"title":"2024-09-09 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\n\n[research] Refined testing tools and query criteria for benchmark tests\n\n\nnext:\n\n[research] run some more queries and discuss findings\n\n\n\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[research]: remove archive queries 100 hashes limit to allow bigger sync\n\n\nnext:\n\n[research]: continue to monitor deployment in fleet, spec update\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[nwaku] Enhance libpq response management and new libp2p store metric chore: enhance libpq management\n[nwaku] started the implementation of new metrics to measure queries’ times chore: create grafana panel to show max, min, mean, median stats of query times\n[nwaku] investigate issue chore: store queries for content topics take longer with cursor\n[research] completed main benchmark test scenarios\n\n\nnext:\n\n[research] write up of benchmark test findings\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nReview connection management strategy and back-off and fix long disconnection issues\n\nachieved:\n\n[chat] bug: requesting always 24h from store node: fix_: store query lastrequest\n\n\n\n\n\nTooling: filter and light push protocols\n\nachieved:\n\n[chat] go-waku: reduce filter loop to 300ms fix_: reduce filter loop to 300ms\n\n\n\n\n\nReliability Protocol for Relay\n\nachieved:\n\n[chat] fix empty subscription when publish message with relay, fix: check subscription when relay publish message, feat: join community request with mvds\n\n\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[js-waku] fix missing messages from Filter and align with RFC fix: filter missing messages\n[js-waku] improve bootstrapping of the node fix: improve node bootstrapping\n\n\n\n\n\nReview MVDS usage and fail path\n\nachieved:\n\n[chat] dogfooding community join request with mvds feat: join community request with mvds\n[chat] accept community join request with mvds feat_: accept community join request with mvds\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\n\nEnd-to-end reliability protocol - PoC\n\nachieved:\n\n[research] POC - added better logging and other suggestions from dogfooding\n\n\n\n\n\nEnd-to-end reliability protocol - Status integration\n\nachieved:\n\n[research]: started a post on sdk/library idea for status integration\n\n\nnext:\n\n[research]: continue working on post, gather feedback and iterate\n\n\n\n\n\nMilestone - Scale 1:1 chat messages PoC §\n\n\nMaturing RLN variables/parameters revision\n\nachieved:\n\n[research]: discussed RLN contract implementation, suggested spec improvements Refinements of RLN on mainnet spec\n\n\n\n\n\nProvision RLN for light push clients PoC\n\nachieved:\n\n[research]: drafted a forum post on service incentivization\n\n\nnext:\n\n[research]: finalize and discuss the forum post\n\n\n\n\n\nMilestone - Scale up number of Communities §\n\nUsage of Rendezvous\n\nachieved:\n\n[research]: modified nim-libp2p to allow waku rdv strategy, updated nwaku PR to reflect libp2p changes\n\n\nnext:\n\n[research]: PR feedback and update cycle, spec update\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[nwaku] Reproduction of gossip-level message duplication in stressed conditions.\n\nSucceed in reproducing and collecting logs from a controlled simulation env.\nAnalysed logs to verify possible hypotheses.\nRe-run tests with different setup and configuration.\n\n\n[nwaku] NWaku in Windows - Successfully built the nim compiler in isolation with an automated system detail fetching process.\n[chat] go-waku: bump go-libp2p and go-libp2p-pubsub chore: bump go-libp2p and go-libp2p-pubsub\n[js-waku] chore: release master, chore: release master\n[js-waku] remove extra dependencies from sdk package chore: remove relay from sdk package\n\n\nnext:\n\n[js-waku] work on improvements for release processes chore: up release-please\n\n\n\nBugs §\n\nachieved:\n\n[chat] status-go: retry dnsdisc on failure \n[chat] go-waku: stop creating goroutines if context is already canceled fix: stop creating goroutines if context is already canceled\n[js-waku] fix installation and remove broken dependencies fix: temporarily remove peer cross dependencies\n\n\n\nBD: Demonstrate Product-Market Fit §\n\nachieved:\n\nDefined customer interview questions\nHad first rehearsal with a prospect where some of the questions were asked\nInvited first 3 projects to interview\n\n\nnext:\n\nEnroll more projects into the Interviews+Codesign initiative\nRework validation tracking board\n\n\n\nBD: Acquire first 10 Customers §\n\nachieved:\n\nNew project using Waku in the payments vertical, referred by a prospect\n\n\nnext:\n\nanother prospect call this week\nProspecting in Singapore\n\n\n"},"waku/updates/2024-09-16":{"title":"2024-09-16 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[research] Store Sync spec first draft\n\n\nnext:\n\n[research] continue dogfooding Store Sync\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[research] Completed test report for Storev3 benchmark testing\n\n\nnext:\n\n[research] Investigate some store query duration anomalies, test plan for store sync\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\nReliability Protocol for Resource-Restricted Clients\n\nnext:\n\n[nwaku] Lightpush v2: ongoing implementation in nwaku and libp2p\n\n\n\n\nReview MVDS usage and fail path\n\nachieved:\n\n[chat] dogfooding the community join response with mvds feat_: accept community join request with mvds\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\nEnd-to-end reliability protocol - PoC\n\nnext:\n\n[research] organise sync dogfooding session for PoC\n\n\n\n\nEnd-to-end reliability protocol - Status integration\n\nachieved:\n\n[research] finalized the API spec post for status-go integration\n\n\nnext:\n\n[research] gather feedback on the API spec proposal\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[chat] fix issue of periodic peer disconnections fix: use correct ticker for all peers ping\n[chat] investigate message drop issue at gossipsub layer and validate possible fix feat: increase outbound q size for pubsub\n\n\n\n\n\nMilestone - Scale 1:1 chat messages PoC §\n\n\nRLNv2 in nwaku\n\nachieved:\n\n[chat] waku-rlnv2-contract: membership feat: membership\n\n\n\n\n\nMaturing RLN variables/parameters revision\n\nnext:\n\n[research] review memberships PR for RLN on mainnet (https://github.com/waku-org/waku-rlnv2-contract/pull/13)\n\n\n\n\n\nMilestone - Scale up number of Communities §\n\n\nUsage of Rendezvous\n\nnext:\n\n[research] awaiting nim-lib2p PR review\n\n\n\n\n\nDoS protection for req-res protocols and metrics (go-waku as service node)\n\nachieved:\n\n[nwaku] dashboard for fleets are live\n\n\n\n\n\nMilestone: Nwaku in Status Desktop §\n\nNwaku on Windows\n\nachieved:\n\n[nwaku] Added windows support for the negentropy submodule chore: update makefile to give support major os\n[nwaku] will modify the nimbus-build-system to integrate Windows.\n[nwaku] Raised an initial PR to build wakunode2 on Windows feat: windows support\n\n\nnext:\n\n[nwaku] Continuing to work on additional builds, including libwaku and cwaku_example.\n\n\n\n\n\nMilestone: Incentivise running a Waku infrastructure node §\n\n\nRLN Relay Incentivisation - Distribute RLN fees PoC\n\nachieved:\n\n[research] Draft proposal: RLN Fees distribution to operators with root voting\n\n\nnext:\n\n[research] gather feedback and think about next steps.\n\n\n\n\n\nService Incentivisation - Pay for RLN provision PoC\n\nachieved:\n\n[research] finalized the blog post on service incentivization: Incentivized Lightpush: A Roadmap to Waku Service Incentivization\n\n\nnext:\n\n[research] continue discussion around service incentivizaiton forum post;\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[nwaku] chore: use submodule nph in CI to check lint\n[nwaku] chore: lightpush - error metric less variable by only setting a fixed string\n[nwaku] fix: get back health check for postgres legacy\n\n\n\nBugs §\n\nachieved:\n\n[chat] go-waku: make the envelope priority queue safe for concurrent access fix: make the envelope priority queue safe for concurrent access\n[chat] status-go: make mailserver availability subscriptions concurrency safe fix: make mailserver availability subscriptions concurrency safe\n\n\n"},"waku/updates/2024-09-23":{"title":"2024-09-23 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[research] Waku sync 2.0 research post first draft.\n[nwaku] bug: libnegentropy.so is missing during link or false linked static linkage for libnegentropy - helps easier deployment chore: Switch libnegentropy library build from shared to static linkage\n\n\nnext:\n\n[research] Write a basic test plan for store sync\n[research] finalize Waku sync 2.0 research post\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[research] Investigated some store query duration test cases\n[nwaku] Submitted PR - chore: extending store metrics\n\n\nnext:\n\n[research] Run a few more tests and summarise the test results\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\n\nEnd-to-end reliability protocol - PoC\n\nachieved:\n\n[research] dogfooding session for POC\n\n\n\n\n\nEnd-to-end reliability protocol - Status integration\n\nachieved:\n\n[research] published API spec proposal for status-go integration to Vac forum: Vac API Specification for End-to-end Reliability\n\n\nnext:\n\n[research] discussion and iterate on API spec; detailed review of points of integration\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[nwaku] made the connectivity loop interval dynamic depending on the current number of peers and targets \n[nwaku] investigated impact nodes advertised with localhost addresses chore: don’t propagate peers with 127.0.0.1 multiaddresses via Discv5\n[nwaku] implemented feedback and merged pubsub topic deprecation chore: deprecating pubsub topic\n\n\n\n\n\nEnable testing of custom shard implementation for Communities\n\nachieved:\n\n[chat] add cli test with own shard community feat: add the first community in own shard\n\n\n\n\n\nMilestone - Scale 1:1 chat messages PoC §\n\n\nRLNv2 in nwaku\n\nachieved:\n\n[nwaku] RLN Membership Contract - feat: membership\n\n\n\n\n\nMaturing RLN variables/parameters revision\n\nachieved:\n\n[research] review RLN on mainnet PR\n\n\n\n\n\nMilestone - Scale up number of Communities §\n\n\nUsage of Rendezvous\n\nblockers:\n\n[research] awaiting nim-libp2p PR review\n\n\n\n\n\nDoS protection for req-res protocols and metrics (go-waku as service node)\n\nachieved:\n\n[nwaku] PeerExchange protocol with rate limit check.\n\nchore: rate limit peer exchange protocol, enhanced response status in RPC\nUpdated protocol\nNew CLI for configure rate limiting. Allows fine tune rate limits to one needs.\n\n\n[nwaku] Deliverable is ready on nwaku.\n\n\n\n\n\nMilestone: Nwaku in Status Desktop §\n\n\nNwaku in Status Desktop\n\nachieved:\n\n[nwaku] start working on it more actively feat: nwaku in status-go (discv5 and dnsdiscovery)\n[nwaku] chore: libwaku reduce repetitive code by adding a template handling resp returns\n\n\n\n\n\nNwaku on Windows\n\nachieved:\n\n[nwaku] Worked on resolving external library linking issues. feat: windows support\n[nwaku] Started refactoring the peer manager.  Improvement: manage stale peer in peer_manager\n\n\nnext:\n\n[nwaku] Wrapping up Windows support with automation &amp;  then focusing on peer manager refactoring after that.\n\n\n\n\n\nMilestone: Incentivise running a Waku infrastructure node §\n\n\nRLN Relay Incentivisation - Distribute RLN fees PoC\n\nachieved:\n\n[research] Got feedback for the initial proposal: RLN Fees distribution to operators with root voting\n\n\nnext:\n\n[research] Refine and explore open problems: challenge for lazy node, analyze if assumptios hold valid, consensus problem when no 2/3 are archieved, etc.\n\n\n\n\n\nService Incentivisation - Pay for RLN provision PoC\n\nachieved:\n\n[research] discussed the Vac forum post on service incentivization\n\n\nnext:\n\n[research] finalize forum post discussion; amend incentivization spec\n\n\n\n\n\nMilestone: Bandwidth optimization and protocol review §\n\n\nStatus usage of Waku scaling and bandwidth optimization recommendation\n\nachieved:\n\n[chat] draft the spec about some bandwidth issues feat: bandwidth optimize spec\n\n\n\n\n\nReview usage of content topics in Status Chat and Communities protocol\n\nachieved:\n\n[chat] analysis of current content-topic usage in status communities Status Message Types - Content Topics\n\n\n\n\n\nMilestone: Demonstrate Product-Market Fit §\n\nachieved:\n\nfound new projects interested in interviewing and co-designing (see milestone 2)\n\n\nnext:\n\nbook interviews and enroll for co-design\n\n\n\nMilestone: Acquire first 10 Customers §\n\nachieved:\n\nattended Singapore Blockchain Week (token2049):\n\nprojects interested in partnering:\n\nSports prediction market;\nprivate social protocol;\nNetwork state/pop up city;\nIntents protocols;\nInbound leads have been coming to us on discord, a good sign despite marketing activity wind down;\n\n\n\n\n\n\n\nOther Work §\nMaintenance §\n\nachieved:\n\n[nwaku] added version migration instructions to the docs feat: add migration instructions\n\n\n\nBugs §\n\nachieved:\n\n[nwaku] investigated failed interop tests and found solutions. Fixed config bug fix: setting up node with modified config\n\n\n"},"waku/updates/2024-09-30":{"title":"2024-09-30 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3-beta - Message Hashes\n\nachieved:\n\n[chat] go-waku: ratelimit store queries and add options to Next to allow customization of cursor queries feat: ratelimit store queries and add options to Next\n[chat] go-waku: storenode cycle feat: storenode cycle\n[chat] status-go: extract storenode cycle to go-waku api feat_: extract storenode cycle to go-waku api\n[chat] storenode cycle add tests on go-waku\n\n\n\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[research] finish Waku sync 2.0 research issue\n[research] Test plan still WIP\n[nwaku] fix: static linking negentropy in ARM based mac\n[nwaku] chore: Switch libnegentropy library build from shared to static linkage\n\n\nnext:\n\n[research] updates from feedback\n[research] Complete test plan and start with basic tests\n\n\n\n\n\nDOS protection for req-res protocols and metrics\n\nachieved:\n\n[nwaku] chore: rate limit peer exchange protocol, enhanced response status in RPC\n[nwaku] chore: DOS protection of non-relay req/resp protocols new cli argument description\n[nwaku] chore: Adjusted peer-exchange to the latest changes made due to rate limit DOS protection\n[nwaku] nwaku is feature ready for DOS protection for req-res protocols and metrics\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[research] Completed more benchmark testing scenarios\n[nwaku] chore: extending store metrics\n\n\nnext:\n\n[nwaku] chore: store queries for content topics take longer with cursor\n[research] Write a quick reference summary of test findings\n[nwaku] chore: store queries for content topics take longer with cursor\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[nwaku] chore: test peer connection management\n\n\nnext:\n\n[nwaku] added an abstraction for libp2p to make the code easier to manage in the future. refactor: peermanager for stale peers management\n\n\n\n\n\nMilestone - RLN Mainnet §\n\n\nRLNv2 in nwaku\n\nachieved:\n\n[chat] waku-rlnv2-contract: do not keep track of membership registration order refactor: do not keep track of membership registration order\n\n\n\n\n\nImplement RLN smart contract for paid, multilevel memberships\n\nachieved:\n\n[research] started review of RLN memberships PR\n\n\nnext:\n\n[research] review / improve the membership PR for RLN on mainnet\n\n\n\n\n\nPublic dogfooding RLNaaS web app\n\nachieved:\n\n[nwaku] chore: append current version in agentString which is used by the identify protocol\n\n\n\n\n\nMilestone - Scale up number of Communities §\n\nUsage of Rendezvous\n\nachieved:\n\n[research] nim-libp2p PR update from feedback\n\n\nnext:\n\n[research] more updates on PR and or merge\n\n\n\n\n\nMilestone: Nwaku in Status Desktop §\n\n\nNwaku in Status Desktop\n\nachieved:\n\n[nwaku] disabled metrics in libwaku until proper support is implemented chore: disabling metrics for libwaku\n\n\nnext:\n\n[nwaku] feat: nwaku in status-go (discv5 and dnsdiscovery)\n\n\n\n\n\nNwaku on Windows\n\nnext:\n\n[nwaku] Windows support was put on hold due to a recurring error. We’ll revisit it after a break.\n\n\n\n\n\nMilestone: Incentivise running a Waku infrastructure node §\n\nService Incentivisation - Pay for RLN provision PoC\n\nachieved:\n\n[research] updated the Vac forum post on service incentivization\n\n\n\n\n\nMilestone: Bandwidth optimization and protocol review §\n\n\nStatus usage of Waku scaling and bandwidth optimization recommendation\n\nachieved:\n\n[chat] review and document status community flow Status Community Flow\n\n\n\n\n\nReview usage of content topics in Status Chat and Communities protocol\n\nachieved:\n\n[research + chat] forum-post proposal for content-topic usage in status communities Status Communities : Review and proposed usage of Waku content-topics\n\n\nnext:\n\n[research] POC to showcase proposed usage of content-topic in communities\n\n\n\n\n\nBugs and Maintenance §\n\nachieved:\n\n[nwaku] chore: sharding - reduce log level for a too spammy message\n[nwaku] Release v0.33 preparation and validation\n[nwaku] chore: updating upload and download artifact actions to v4\n[nwaku] fix: px protocol decode - do not treat missing response field as error\n[nwaku] fix: PeerExchange rpc decode in order not to take response’s status_code mandatory - for support old protocol implementation\n[chat] status-go fix_: remove unreachable code error message\n[chat] go-waku, fix push notifications not working in mobile in develop branch fix: filter batch duration opt was not propagated correctly\n\n\n\nMilestone: Demonstrate product-market fit §\n\n\nDefine potential USPs\n\nachieved:\n\nFranck redone validation matrix and we defined how to approach prospects to validate our USPs\n\n\nnext:\n\nactively seek validation or invalidation of these USPs in next contacts with customers in a structured manner\n\n\n\n\n\nDefine target customers\n\nachieved:\n\nwe have gained knowledge since last GTM plan iteration to further specify our target customers and segments\n\n\nnext:\n\nIterating on GTM plan with new info\n\n\nblockers:\n\ndoing some interviews and validating USPs\n\n\n\n\n\nCustomer Interviews\n\nachieved:\n\nDefined questions and validation Matrix and lined up first couple of leads\n\n\nblockers:\n\nsome of the contacts went to Bali and other places after token2049 and it’s hard to get a hold of them\n\n\n\n\n\nCo-design sessions\n\nachieved:\n\nA couple projects interested in participating\n\n\nnext:\n\ndefining scope of co design with potential partners\n\n\nblockers:\n\nneed more details and conducting some interviews before extending formal invitations\n\n\n\n\n\nMilestone: Acquire first 10 customers §\n\n\n5-10 Highly qualified leads\n\nachieved:\n\n4 deals in Solution Engineering stage with others joining soon\n\n\nnext:\n\nadvancing\n\n\nblockers:\n\nmostly on customer side apart from some fixes needed in some of our products like js-waku\n\n\n\n\n\nReview current integrations\n\nachieved:\n\nrounded up deals and logged dependencies in CRM and agreed on roadmap priorities according to existing customers\n\n\nnext:\n\nlooking into deals that were lost and figuring out how to revive with new milestones being hit\n\n\n\n\n"},"waku/updates/2024-10-07":{"title":"2024-10-07 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[research] simple sync storage POC\n[research] gathered info on store sync and implemented testing tools\n\n\nnext:\n\n[test] finishing protocol POC\n[test] store sync testing plan\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[research] ongoing benchmark test with latest improvement\n[nwaku] chore: Optimize store\n[nwaku] chore: store queries for content topics take longer with cursor\n\n\nnext:\n\n[research] ongoing benchmark test with latest improvement\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\n\nTooling: filter and light push protocols\n\nnext:\n\n[nwaku] chore: add dashboard for liteprotocoltester runs\n\nAdded PeerExchange service node discovery\nAdded Peer connection testing and metrics\nAdded flexible service peer switch capability to ensure smooth testingAll are monitored via metrics.\nPrepare integration LiteProtocolTester with monitoring to infra.\n\n\n\n\n\n\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[js-waku] refined stream management to prevent spamming and higher reliability rate fix: peer renewal connection drop &amp; stream management\n[js-waku] investigation of peer management and connection management for core protocols\n\n\nnext:\n\n[js-waku] enhanced peer and connection management for better reliability of Filter feat: enhancing protocol management with mutex locks\n[js-waku] refine LightPush implementation for better testability and reliability\n[js-waku] continue with Filter subscriptions investigation bug: Filter subscriptions are not stable and missing messages\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\nEnd-to-end reliability protocol - Status integration\n\nachieved:\n\n[research] Discussion on forum post and some updates based on feedback\n\n\nnext:\n\n[research] Implementation of the API in nim\n\n\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\n\nTelemetry: Measure Bandwidth\n\nachieved:\n\n[chat] go-waku: added bandwidth in/out metrics: test: bandwidth totals\n\n\n\n\n\nSharding peer management and discovery hardening\n\nachieved:\n\n[nwaku] Fixed having excess in connections fix: rejecting excess relay connections\n[nwaku] Fixed out connections leak fix: out connections leak\n[nwaku] Implemented abstract peer store interface using WakuPeerStore. refactor: wrap peer store\n\n\nnext:\n\n[nwaku] Restructure functions based on the peer manager’s responsibilities. refactor: re-arrange function based on responsibility of peer-manager\n\n\n\n\n\nMilestone - RLN Mainnet §\nImplement RLN smart contract for paid, multilevel memberships\n\nachieved:\n\n[research] review and improve the RLN mainnet contract and spec\n\n\nnext:\n\n[research] finalize RLN on mainnet PR\n\n\n\nMilestone: Nwaku in Status Desktop §\n\nNwaku in Status Desktop\n\nachieved:\n\n[nwaku] logging errors in libwaku Compare changes\n[nwaku] indicate to the compiler that negentropy.h will be a precompiled header fix: indicate to the compiler that negentropy.h will be a precompiled header\n[nwaku] build nwaku with nix and use build tags to choose between go-waku and nwaku feat_: build nwaku with nix and use build tags to choose between go-waku and nwaku\n\n\nnext:\n\n[nwaku] Include nwaku in status-desktop App\n\n\n\n\n\nMilestone: Incentivise running a Waku infrastructure node §\n\n\nRLN Relay Incentivisation - Distribute RLN fees PoC\n\nachieved:\n\n[research] Addressed the open problems and ready for a second round of feedback: RLN Fees distribution to operators with root voting\n\n\nnext:\n\n[research] Second round of feedback and decide next steps\n\n\n\n\n\nService Incentivisation - Pay for RLN provision PoC\n\nnext:\n\n[research] start service incentivization implementation and spec changes\n\n\n\n\n\nMilestone: Bandwidth optimization and protocol review §\n\n\nStatus usage of Waku scaling and bandwidth optimization recommendation\n\nachieved:\n\n[chat] proposed and discuss about the bandwidth improvement post, Use Waku in a Bandwidth Efficient Way\n\n\n\n\n\nReview usage of content topics in Status Chat and Communities protocol\n\nachieved:\n\n[chat] able to interop test between single content-topic community code and 2.30 code using relay and lightclient feat_: poc to use single content-topic for all community chats\n\n\n\n\n\nMilestone: Demonstrate product-market fit §\n\n\nDefine potential USPs\n\nachieved: Cleaned up validation matrix. Used to lay out the validation that are needed and capture learnings.\n\n\n\nDefine target customers\n\nachieved:\n\nwe can consider payments/relayers/state channels a go-to use case\n\n\nnext:\n\nfinding out more of these\n\n\n\n\n\nCustomer Interviews\n\nachieved:\n\n3 projects to interview and had a call where we touched upon most of the topics\n\n\nnext:\n\nadd more\n\n\n\n\n\nCo-design sessions\n\nachieved:\n\n2 committments\n\n\nnext:\n\nadd more\n\n\n\n\n\nOther Work §\nEnhancements §\n\nachieved:\n\n[js-waku] dogfooding app dashboard for better overview of TWN from client PoV\n[chat] go-waku: added unit tests to feat: storenode cycle\n[chat] go-waku: use byte array to decode ENRs waku2 field: fix: use byte array to decode ENRs uint8 fields\n\n\nnext:\n\n[js-waku] refined API for connecting to the network chore: make waitForRemotePeer part of the waku interface\n[js-waku] improve telemetry gathering and metric display\n\n\n\nMaintenance §\n\nachieved:\n\n[nwaku] chore: append current version in agentString which is used by the identify protocol\n[nwaku] Finished validating and released v0.33.0\n\n\n"},"waku/updates/2024-10-14":{"title":"2024-10-14 Waku Weekly","links":[],"tags":["waku-updates"],"content":"Milestone - Store Service Upgrade §\n\n\nStore v3 - store synchronisation\n\nachieved:\n\n[research] progress on Waku Sync 2.0 POC\n[research] Received input on store sync test goals and made progress on a test plan\n[nwaku] Enhance error response instead of ambiguous numerical in waku_sync. We need two pull requests, one for negentropy and another one for nwaku.  \n\n\nnext:\n\n[research] finishing Waku Sync 2.0 POC\n[research] get store sync enabled again on status.staging and implement docker-compose to run multiple store sync nodes with their own DB for simulations\n\n\n\n\n\nPostgreSQL Maintenance\n\nachieved:\n\n[nwaku] chore: store queries for content topics take longer with cursor\n[nwaku] chore: optimize store v3 queries\n\n\nnext:\n\n[research] run benchmark tests to get comparison of duration before and after optimisation\n[nwaku] Reach a conclusion on whether we need time-sortable msgHash chore: make the msg hash time-sortable\n\n\n\n\n\nMilestone - Direct Message Reliability §\n\nReliability Protocol for Resource-Restricted Clients\n\nachieved:\n\n[js-waku] refined LightPush implementation for better testability and reliability \n[chat] add backoff strategy for filter subscriptions in case of recurring failures \n\n\nnext:\n\n[js-waku] enhanced peer and connection management for better reliability of Filter feat: enhancing protocol management with mutex locks\n[js-waku] investigate and fix problematic points in reliability manager that breaks Filter subscriptions sometimes feat(lightPush): improve peer usage and improve readability\n[js-waku] limit max amount of open connections to prevent spamming of TWN feat: maintain max open connection &amp; prune unhealthy connections from peer store\n\n\n\n\n\nMilestone - End-to-end reliability protocol §\n\nEnd-to-end reliability protocol - Status integration\n\nachieved: [research] progress on implementation of the API in nim\nnext: [research] finish implementing the core reliability API functions\n\n\n\nMilestone - Static Sharding - dedicated shards §\n\nEnable testing of custom shard implementation for Communities\n\nachieved: [chat] add mvds to cli logs to pick them up with the tests: chore_: check mvds for tests\n\n\n\nMilestone - RLN Mainnet §\n\nImplement RLN smart contract for paid, multilevel memberships\n\nachieved:\n\n[chat] waku-rlnv2-contract: setup linea deployment - feat: deploy to Linea\n[chat] waku-rlnv2-contract: refactor to keep contract Owned and not Owned2Step - feat: Ownable2StepUpgradeable to OwnableUpgradeable\n\n\n\n\n\nMilestone - Scale up number of Communities §\n\nUsage of Rendezvous\n\nblockers: [research] wait for new nim-libp2p version\n\n\n\nMilestone: Nwaku in Status Desktop §\n\n\nNwaku in Status Desktop\n\nachieved:\n\n[nwaku] chore: adding missing error handling in libwaku\n[nwaku] fix: remove quotes from libwaku’s returned enr string\n[nwaku] fix: changing libwaku’s error handling format\n[nwaku] Adding fixes to status-go nwaku basic test, getting DNS discovery to work\n\n\n\n\n\nNwaku on Windows\n\nachieved: [nwaku] compile libwaku and some examples\nnext: [nwaku] Run wakunode2, cwaku_example, and tests on Windows\n\n\n\nMilestone: Incentivise running a Waku infrastructure node §\n\nService Incentivisation - Service incentivisation roadmap &amp; spec\n\nachieved: [research] review some RLN on mainnet contract PRs\nnext: [research] service incentivization spec update\n\n\n\nMilestone: Demonstrate product-market fit §\n\n\nDefine potential USPs\n\nachieved:\n\nRestructured and abbreviated the validation matrix;\nPopulated the matrix with information gathered in recent prospect calls;\n\n\nnext: Continue populating and analyse the findings;\n\n\n\nDefine target customers\n\nachieved:\n\n3 segments identified for customer interviews;\nWe have 2 projects from a non-core segment also interested;\n\n\n\n\n\nCustomer Interviews\n\nachieved: Did the first interview with a ZKid\nnext:\n\ninterview projects mentioned above\nInvite others in pipeline for interview\n\n\n\n\n\nCo-design sessions\n\nachieved: Soft commitments from 3 projects for co-design sessions;\nnext: Schedule the sessions for Devcon or afterwards;\n\n\n\nMilestone: Acquire first 10 customers §\n\n5-10 Highly qualified leads\n\nachieved:\n\nQualified 2 more projects.\nOne in the payments vertical (private state channels);\nOne in the zkID vertical;\n\n\nnext: Propose co-designing\n\n\n\nOther Work §\nMaintenance §\n\nachieved:\n\n[nwaku] Released v0.33.1\n[nwaku] Remove spammy log fix: remove spammy log\n[nwaku] Temporarily skip flaky test chore: improving and temporarily skipping flaky rln test\n[nwaku] Analyzed perf logs of nodes getting stuck. Progressed with the investigation and seem close to a resolution, asked DST for some extra information bug: node getting stuck and missing messages\n[js-waku] refined API for connecting to the network chore: make waitForRemotePeer part of the waku interface\n[js-waku] improved gathering of metrics for frequently occurring events\n[js-waku] expose peerId and protocols from main object for better API feat: expose peerId and protocols from WakuNode\n[js-waku] improve API for awaiting peers in the network by enabling it on the main object feat: replace waitForRemotePeers() with waku.waitForPeer() method\n[js-waku] enable unit testing in waku/sdk and add unit tests for awaiting for peers API feat: add mocha tests to @waku/sdk and cover waitForRemotePeer\n[js-waku] speed up and optimize awaiting for new peers functionality feat: confirm metadata and protocols needed in waitForRemotePeer\n[js-waku] ease naming of some interfaces chore: rename IProtocolSDK interfaces to IProtocol naming convention\n[chat] add clusterId and shards config for c-bindings feat: add clusterID and shards config to c-bindings\n\n\nnext:\n\n[nwaku] prepare Rust app for devcon workshop\n[js-waku] release critical bug fixes for Filter and LightPush\n[js-waku] refine Connection Manager for better reliability and testability feat: refactor ConnectionManager for maintainability\n[js-waku] update CI to use latest nwaku release and adjust interop pipeline for master chore: upgrade nwaku to 0.33.0 and check interop tests\n\n\n\nBugs §\n\nachieved:\n\n[chat] status-go: investigate and fix builds not working when bumping go-waku. Fixed in PR which keeps generated files in vendor folder - fix_: don’t ignore generated files in vendor/\n[chat] status-go: bandwidth counter should be reset each time it is retrieved otherwise it behaves like an accumulator - fix_: bandwidthCounter should be reset each time it is retrieved otherwise it behaves like an accumulator\n\n\n"},"waku/waku-milestones":{"title":"Waku Milestones","links":["waku/milestones/open/2024-static-sharding-dedicated-shards","waku/milestones/open/2024-bandwidth-optimization-and-protocol-review","waku/milestones/open/2024-scale-number-of-communities","waku/milestones/open/2024-nwaku-in-status-desktop","waku/milestones/open/2024-rln-mainnet","waku/milestones/open/2024-incentivise-running-infra-node","waku/milestones/open/2024-store-service-upgrade","waku/milestones/open/2024-direct-msg-reliability","waku/milestones/open/2024-e2e-reliability-protocol","waku/milestones/open/2024-acquire-first-10-customers","waku/milestones/open/2024-demonstrate-product-market-fit","waku/milestones/closed/2023-quality-assurance-processes","waku/milestones/closed/2023-support-1-million-users","waku/milestones/closed/2023-support-many-platforms","content/waku/milestones/closed/2023-waku-network-gen-0"],"tags":[],"content":"Started in H2 2024 §\n\nStatic Sharding - dedicated shards\nBandwidth optimization and protocol review\nScale up number of Communities\nNwaku in Status Desktop (Relay mode)\nRLN Mainnet\nIncentivise running a Waku infrastructure node\n\nStarted in H1 2024 §\n\nStore Service Upgrade\nDirect Message Reliability\nEnd-to-end reliability protocol\nAcquire first 10 Customers\nDesmonstrate Product Market-Fit\n\nClosed §\n\nQuality Assurance processes are in place\nSupport 1 Million Users\nSupport Many Platforms\nWaku Network Gen 0\n"},"what-is-a-milestone":{"title":"What's in a Milestone","links":[],"tags":[],"content":"Rationale and Reasoning §\nA project’s goals and priorities are described at its top level by a list of Milestones. The list of these milestones should serve as a guidepost to anyone who is interested in what the project is working on, what the deliverables are of that work, and how that work is going.\n\n\n                  \n                  If you don&#039;t like &quot;Milestone&quot;, call it whatever you want as long as it&#039;s in line with this description. \n                  \n                \n\nThis document is an outline of how you should think about creating milestones for your project, and what information should be included in them such that the IFT Grant Process can be completed and everyone stays on the same page.\nProjects work to produce things for people, and a milestone describes, plans, and tracks those things. To that end, the deliverables are the key components to reason around what a milestone is for your project. Who are you building for, what are you building for them, and why do they care? A small group of deliverables and the justified impact they have towards their targeted audience should be enough to help someone understand what a project is doing.\nIn effect, a given milestone is a declaration of:\n\nHere’s what we want to happen\nThis is why this needs to happen\nHere’s how we’re going to make that happen\nThis is what we need to do it\nHere’s how you can watch\nThis is how confident we are that we can get it done (in time)\n\nThe scope of a given milestone is such that the total amount of work you plan for the year equates to ~4-5 individual milestones. For a small project, that’s focused and tight. For a large project, that’s cross-functional and broad. It is expected that larger projects have the appropriate project management resources to sub-divide their milestones in to sub-milestones, epics, and issues as appropriate.\nWe ask that the structure of the milestone is somewhat standardized across the IFT, as we have a lot of derivative and automation tasks to perform.\nHere’s a list of the sections that need to be included in each milestone:\n\nMilestone Title §\nA short name of the milestone that succinctly describes its aim and scope.\nEstimated Delivery Date §\nA timeline in which the work is expected to be delivered\nDescription §\nMore detail as to what you’re aiming to accomplish with this milestone and the justification for its inclusion to the project. This is the human readable encapsulation of the milestone. Someone reading it should be able to understand the general scope of the entire thing, with all other sections adding context and detail.\nResources Required §\n\nroles and % application to it\nexternal services consumed (Vac/IFT)\ninfrastructure\n\nThis information here, in combination with the IFT Finance team, should be enough to yield the required budget for the milestone. This allows for private financial information to stay appropriately separated while still allowing us to publish and broadcast the roadmaps (and their progress) to the broader communities.\nDeliverables §\nWhat are the tangible items that are the result of this milestone’s work, and who is the targeted audience for those items?\nIt is important to note that we’ve included the intended audience here. Is this a research PoC to be delivered to the Engineering team? Is this a mainnet launch that we need wide community broadcasting on? Is this an SDK being delivered to another IFT project? The appropriate communication of the deliverable should be considered here.\nTracking Metrics §\nHow we track progress on a given milestone is dependent upon what the goal of the milestone is and deliverables it aims to accomplish. As per Jarrad’s Strategy Document and mantra from previous talks, metrics around User Acquisition and Revenue Generation should be included wherever possibly appropriate. If it isn’t directly aimed at these two, its impact on how it facilitates it should be understood.\nNOTE: The IFT Insights team will closely monitor all of these and provide dashboards to relevant stakeholders such that progress and status can be monitored and acted upon.\nWork Breakdown §\nSince this is the highest level of “work package” that is considered throughout the org, a description of the way this is going to be broken up and managed should be itemized here. This section is a process of showing “this is explicitly how we plan to deliver this milestone.”\nNOTE: It is recommended that the broken down work is structured similarly so it can be understood and tracked, e.g. Milestone -&gt; Epics -&gt; Issues by the IFT Insights team, with each layer more narrowed in scope and explicit in detail. Each project has a significant level of autonomy on how they deliver on the agreed upon milestones and the associated project management and organization that entails it.\nPerceived Risks §\nEach milestone should include a section of what dependencies/assumptions/potential market changes there are that add risk to its completion. What factors come into play that can potentially affect the project delivery date, and how do each of them affect its delivery?"}}